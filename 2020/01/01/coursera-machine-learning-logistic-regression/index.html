<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.58.3" />


<title>Coursera Machine Learning Logistic Regression and Regularization - Dilettanting Data Science</title>
<meta property="og:title" content="Coursera Machine Learning Logistic Regression and Regularization - Dilettanting Data Science">



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/turner.jpg"
         width="200"
         height="200"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://www.kaggle.com/davidsalazarv95">Kaggle</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir?lang=en">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">10 min read</span>
    

    <h1 class="article-title">Coursera Machine Learning Logistic Regression and Regularization</h1>

    
    <span class="article-date">2020/01/01</span>
    
    

    <div class="article-content">
      

<div id="TOC">
<ul>
<li><a href="#classification-problems">Classification Problems</a><ul>
<li><a href="#linear-regression">Linear Regression?</a></li>
<li><a href="#logistic-regression">Logistic Regression</a></li>
<li><a href="#decision-boundaries">Decision Boundaries</a></li>
<li><a href="#cost-function">Cost Function</a><ul>
<li><a href="#cross-entropy">Cross Entropy</a></li>
<li><a href="#a-maximum-likelihood-derivation">A maximum likelihood derivation</a></li>
<li><a href="#vectorised-implementation">Vectorised implementation</a></li>
</ul></li>
<li><a href="#multi-classification-problem">Multi Classification Problem</a></li>
<li><a href="#regularization">Regularization</a><ul>
<li><a href="#solutions-to-overfitting">Solutions to overfitting:</a></li>
<li><a href="#cost-function-1">Cost function</a></li>
</ul></li>
<li><a href="#moving-towards-neural-networks">Moving towards neural networks</a></li>
</ul></li>
</ul>
</div>

<div id="classification-problems" class="section level1">
<h1>Classification Problems</h1>
<blockquote>
<p>In all of these problems the variable that we’re trying to predict is a variable <span class="math inline">\(y\)</span> that we can think of as taking on two values either zero or one, either spam or not spam, fraudulent or not fraudulent, related malignant or benign.</p>
</blockquote>
<p>In these type of problems, the variable we are trying to predict take only two values: <span class="math inline">\(Y \in {0, 1}\)</span>. Thus, we want to use our knowledge of the training data, <span class="math inline">\((X, Y)\)</span>. But to predict what? One logical way would be to predict the conditional probability <span class="math inline">\(P(Y| X)\)</span>.</p>
<div id="linear-regression" class="section level2">
<h2>Linear Regression?</h2>
<p>We could use a linear probability model, where:</p>
<p><span class="math display">\[ P(Y | X; \beta) = x \cdot \beta \]</span></p>
<p>Given that we are assuming constant marginal effects, <span class="math inline">\(\frac{\partial P(Y | X)}{\partial x_i} = \beta_i\)</span> , regardless of the starting point, it’s possible to have probability predictions outside the interval <span class="math inline">\({0, 1}\)</span> for observations with extreme values. Thus, awkward and unreliable for prediction. Notice that outliers will have a similar effect: they can easily shift the regression line, and thus shift our predictions in an unwaranted fashion.</p>
<blockquote>
<p>So, applying linear regression to a classification problem often isn’t a great idea.</p>
</blockquote>
<p>Also, if we assume that the observations are i.i.d. Bernoulli’s, the regression will have heteroskedasticity.</p>
</div>
<div id="logistic-regression" class="section level2">
<h2>Logistic Regression</h2>
<p>A more logical way, then, is to model <span class="math inline">\(P(Y| X; \beta)\)</span> with a function that will be bounded between 0 and 1. That is, we will use a different ML algorithm that will posit a different hypothesis space. In particular, it will search for our function as a sigmoid function:</p>
<p><span class="math display">\[ P(Y| X; \beta) = \frac{1}{1+e^{-x \cdot \beta}} \]</span></p>
<p>Notice that this function will always output a value between zero and one.</p>
</div>
<div id="decision-boundaries" class="section level2">
<h2>Decision Boundaries</h2>
<p>Instead of analyzing our predictions, and our instantiated hypothesis as functions, a more helpful way is to see them as decision boundaries: hyperplanes that divide our training space into a collection of regions labelled according to the classification. To see what I mean, let’s create the following prediction criteria:</p>
<p><span class="math display">\[ \hat{Y} = 1 \to P(Y | X) &gt; 0.5 \]</span></p>
<p>Which in turn becomes:</p>
<p><span class="math display">\[ \frac{1}{1+e^{-x \cdot \beta}} &gt; 0.5\]</span>
&gt; To summarize what we just worked out, we saw that if we decide to predict whether y=1 or y=0 depending on whether the estimated probability is greater than or equal to 0.5, or whether less than 0.5, then that’s the same as saying that when we predict y=1 whenever theta transpose x is greater than or equal to 0.</p>
<p>Which itself becomes:</p>
<p><span class="math display">\[ e^{-x \cdot \beta} &lt; 1  \]</span></p>
<p><span class="math display">\[ - x \cdot \beta &lt; ln(1) \]</span></p>
<p><span class="math display">\[ x \cdot \beta &gt; 0 \]</span></p>
<p>That is, given some <span class="math inline">\(\beta\)</span>, our ML algorithm will classify our training space into two sections: the one where <span class="math inline">\(x \cdot \beta &gt; 0\)</span> and the one where $ x &lt; 0$. That is, we will have a decision boundary given by the hyperplane <span class="math inline">\(\{x | x \cdot \beta = 0 \}\)</span> .Thus, we can represent our logistic regression as creating a linear decision boundary in our training space. Our training thus, will fit this decision boundary to be optimal in terms of our training data and our loss function.</p>
<p><strong>Note, however, that we can augment our training space by creating polynomial features. In that augmented space, we will fit a linear decision boundary; however, in the original space, the decision boundary does not need to be linear.</strong></p>
<p><em>The decision boundary is defined by the parameters of our function, not by the training set</em></p>
</div>
<div id="cost-function" class="section level2">
<h2>Cost Function</h2>
<p>Thus, we have learned that the fact that we use a cutoff to predict from a real-valued function implies the creation of a decision boundary within our training space. However, how can we choose the parameters that create the best decision boundary possible? First, we must define what it means to predict well. To do so, let’s create a loss function.</p>
<p>We could use the squared error:</p>
<p><span class="math display">\[ \ell (x, y; f(x)) = (y - f(x))^2  \]</span>
However, if as <span class="math inline">\(f(x)\)</span> we use the sigmoid function, our loss function won’t be convex and thus won’t have a global minimum that we can reach with the help of gradient descent.</p>
<div id="cross-entropy" class="section level3">
<h3>Cross Entropy</h3>
<p>We want a loss function that satisfies the following properties:</p>
<ul>
<li>When <span class="math inline">\(y =1, f(x) = 1\)</span>, <span class="math inline">\(\ell (x, y; f(x)) \to 0\)</span>.</li>
<li>When <span class="math inline">\(y =1, f(x) = 0\)</span>, <span class="math inline">\(\ell (x, y; f(x)) \to \infty\)</span>.
-When <span class="math inline">\(y =0, f(x) = 0\)</span>, <span class="math inline">\(\ell (x, y; f(x)) \to 0\)</span></li>
<li>When <span class="math inline">\(y =0, f(x) = 1\)</span>, <span class="math inline">\(\ell (x, y; f(x)) \to \infty\)</span></li>
</ul>
<p>Thus, our loss function incentivizes <span class="math inline">\(f(x)\)</span> to get as close as possible to the observed value. The following cost function satisfies these properties:</p>
<p><span class="math display">\[ \sum_M y log(p(w, b; x)) + (1 - y) log (1 - p(w, b; x)) \]</span></p>
<p>Which has the following derivative:</p>
<p><span class="math display">\[ \frac{\partial C}{\partial x_i} = \frac{1}{m}  \sum^M (h(x; \beta) -  y_i) x_i \]</span></p>
</div>
<div id="a-maximum-likelihood-derivation" class="section level3">
<h3>A maximum likelihood derivation</h3>
<p>Positing that the data comes from a bernoulli:</p>
<p>Thus, the PMF is as follows:</p>
<p><span class="math display">\[ p(y) =  (p)^y (1 - p)^{(1 - y)} \]</span></p>
<p>If the data comes from an <span class="math inline">\(i.i.d\)</span>, the joint probability is simply a multiplication of the respective PMFs of the <span class="math inline">\(x^{i}\)</span>. The log of that expression, then, will be the following sum:</p>
<p><span class="math display">\[ \sum_M log((p)^y (1 - p)^{(1 - y))} \]</span>
Applying simple logarithm rules:</p>
<p><span class="math display">\[ \sum_M y log(p) + (1 - y) log (1 - p)  \]</span></p>
<p>Then, as we switch the function to treat <span class="math inline">\(y, x\)</span> as given, and <span class="math inline">\(w, b\)</span> as parameters, we arrive at:</p>
<p><span class="math display">\[ \sum_M y log(p(w, b; x)) + (1 - y) log (1 - p(w, b; x)) \]</span></p>
<p>Then, in the maximum likelihood paradigm, we would maximize this quantity. However, we can just put a negative sign in front of it and minimize it. We would then, model <span class="math inline">\(p\)</span> with a logistic function depending on the parameters <span class="math inline">\(w, b\)</span>. And voila! we arrive at the aforementioned cost function.</p>
</div>
<div id="vectorised-implementation" class="section level3">
<h3>Vectorised implementation</h3>
<p>Vectorised implementation of sigmoid: simply do the linear combination in one step, <span class="math inline">\(X\beta\)</span>, and then apply the sigmoid to each component.</p>
<p>Vectorised cost function:</p>
<p><span class="math display">\[ C(X, Y, h(X)) = \frac{1}{m} \cdot (-y&#39;log(h(X; \beta)) + (1 - y)&#39;(log(1 - h(X; \beta)))) \]</span></p>
<p>A vectorised derivative, thus:</p>
<p><span class="math display">\[ X&#39;(h(X; \beta) - Y) \]</span>
## Advanced optimization</p>
<p>“Conjugate gradient”, “BFGS”, and “L-BFGS” are more sophisticated, faster ways to optimize θ that can be used instead of gradient descent.</p>
</div>
</div>
<div id="multi-classification-problem" class="section level2">
<h2>Multi Classification Problem</h2>
<p>What if $y {1, 2, 3, …. k} $. How can we use logistic regression to predict <span class="math inline">\(y\)</span>? Use one vs. all method. We create <span class="math inline">\(k\)</span> logistic regressions with <span class="math inline">\(k\)</span> different <span class="math inline">\(y&#39;s\)</span>: one for each unique value that <span class="math inline">\(y\)</span> can take. For each unique value, all the other classes but the one at hand are lumped together into a new category: thus, <span class="math inline">\(y_i \in \{0, 1 \}\)</span>. Then, for each observation, we have a vector of estimates $P(y_i = 1 | X), …., P(y_i = k| X) $. We simply choose, for each observation, the one category for which we predict the greatest probability.</p>
</div>
<div id="regularization" class="section level2">
<h2>Regularization</h2>
<p>There’s a function that generalizes well with both the training set and the unseen data. With a ML algorithm, we would like to approximate to this function. However, there’s no guarantee any ML algorithm will be able to do it.</p>
<p>For example, this goal function may not be contained in the hypothesis space that the ML algorithm is considering. For example, the function may be not linear in the parameters and we are using linear regression. <strong>Then, linear regression would suffer from bias</strong></p>
<blockquote>
<p>as high bias. Both of these roughly mean that it’s just not even fitting the training data very well. The term is kind of a historical or technical one, but the idea is that if a fitting a straight line to the data, then, it’s as if the algorithm has a very strong preconception, or a very strong bias that housing prices are going to vary linearly with their size and despite the data to the contrary. Despite the evidence of the contrary is preconceptions still are bias, still closes it to fit a straight line and this ends up being a poor fit to the data.</p>
</blockquote>
<p>On the other hand, if our hypothesis space is too large, we many not have enough data to distinguish among the possible instantiations of the function: the ones that are truly good, and the ones that just reproduce all the noise present in the data set. That is, small changes in our data may create big changes in our output function: that is, our algorithm will be susceptible to the noise present in our training set. Thus, our ML algorithm is too variable to the training noise to outpuet the best function it can to generalize for our data, as we cannot recognize it.</p>
<blockquote>
<p>But, the intuition is that, if we’re fitting such a high order polynomial, then, the hypothesis can fit, you know, it’s almost as if it can fit almost any function and this face of possible hypothesis is just too large, it’s too variable. And we don’t have enough data to constrain it to give us a good hypothesis so that’s called overfitting.</p>
</blockquote>
<p>Let’s introduce some terminology: the best function is the one that classifies with the true probability of an observation belonging to a class: Bayes’ classifier. Our function may deviate from it for any of the two reasons: bias or variance.</p>
<p>The problem? There’s a trade-off between these two types of error, the bias-
variance trade-off. The bias refers to the mistake of not being close to bayes; the variance that some algorithms won’t yield the same function but will change constantly with the
sample at hand. The largest the space considered, the best we can approximate our best
function to the bayes’, but the more variable will be our function.</p>
<div id="solutions-to-overfitting" class="section level3">
<h3>Solutions to overfitting:</h3>
<ol style="list-style-type: decimal">
<li>Reducing the number of features.</li>
</ol>
<ul>
<li>Manually select which features to keep.</li>
<li>Use a model selection algorithm (studied later in the course).</li>
</ul>
<p>That is, our algorithm is overlearning the noise present in the training set. Let’s eliminate the variables that contain part of this noise such that it won’t learn it.</p>
<ol style="list-style-type: decimal">
<li>Regularization.</li>
</ol>
<ul>
<li>Keep all the features, but reduce the magnitude of parameters <span class="math inline">\(\theta\)</span>.</li>
<li>Regularization works well when we have a lot of slightly useful features.</li>
</ul>
</div>
<div id="cost-function-1" class="section level3">
<h3>Cost function</h3>
<p>Ideally, we would like to keep a high capacity hypothesis space but we would like to search more carefully among the possible instantiations, such that we will be able to differentiate between good functions and functions that reproduce the noise in the training set. The key is to understand that the noise is propagated through the overuse of some training features. Then, we will instruct our algorithm to only the variables if they reduce our training error but we will penalize for their size. That is, we will have a budget for training variables size: the algorithm will allocate these budget to the most important features, and thus relegating the ones that only contribute through noise.</p>
<p>Regularizing. High capacity hypothesis function, but be skeptical of using variables. To do so, we can add a <strong>complexity penalizing term to our cost function</strong>: the sum of the squared parameters.</p>
<p><span class="math display">\[ Cost = Cost + \lambda \sum \theta^2\]</span></p>
<p>Where <span class="math inline">\(\lambda\)</span> controls the degree of complexity penalization. The higher the <span class="math inline">\(\lambda\)</span>, the more the cost function will guide our algorithm towards less complex functions.</p>
<p>The model fitting will be the same as before: initialize parameters, calculate the cost function and its gradient (this step will involve different calculations, given the new parameters) and repeat for the number of epochs in our gradient descent.</p>
<blockquote>
<p>So using regularization also takes care of any non-invertibility issues of the X transpose X matrix as well.</p>
</blockquote>
</div>
</div>
<div id="moving-towards-neural-networks" class="section level2">
<h2>Moving towards neural networks</h2>
<blockquote>
<p>So whereas linear regression, logistic regression, you know, you can form polynomial terms, but it turns out that there are much more powerful nonlinear quantifiers that can then sort of polynomial regression. And in the next set of videos after this one, I’ll start telling you about them.</p>
</blockquote>
</div>
</div>

    </div>
  

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


  
  </article>

</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

