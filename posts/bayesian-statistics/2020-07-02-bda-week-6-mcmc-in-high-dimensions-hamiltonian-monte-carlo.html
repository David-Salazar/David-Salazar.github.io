<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.262">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="">
<meta name="dcterms.date" content="2020-07-02">

<title>David Salazar - BDA Week 6: MCMC in High Dimensions, Hamiltonian Monte Carlo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">David Salazar</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html">
 <span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/David-Salazar"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/DavidSalazarVir"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">BDA Week 6: MCMC in High Dimensions, Hamiltonian Monte Carlo</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 2, 2020</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#metropolis-algorithm" id="toc-metropolis-algorithm" class="nav-link active" data-scroll-target="#metropolis-algorithm">Metropolis Algorithm</a></li>
  <li><a href="#an-expectation-in-low-dimensions" id="toc-an-expectation-in-low-dimensions" class="nav-link" data-scroll-target="#an-expectation-in-low-dimensions">An Expectation in low dimensions</a></li>
  <li><a href="#an-expectation-in-high-dimensions" id="toc-an-expectation-in-high-dimensions" class="nav-link" data-scroll-target="#an-expectation-in-high-dimensions">An Expectation in high dimensions</a>
  <ul class="collapse">
  <li><a href="#corner-madness" id="toc-corner-madness" class="nav-link" data-scroll-target="#corner-madness">Corner Madness</a></li>
  <li><a href="#all-that-matters-the-typical-set" id="toc-all-that-matters-the-typical-set" class="nav-link" data-scroll-target="#all-that-matters-the-typical-set">All that matters: the typical set</a></li>
  <li><a href="#a-surface-concentrating-away-from-the-mode" id="toc-a-surface-concentrating-away-from-the-mode" class="nav-link" data-scroll-target="#a-surface-concentrating-away-from-the-mode">A surface concentrating away from the mode</a></li>
  </ul></li>
  <li><a href="#metropolis-and-the-typical-set" id="toc-metropolis-and-the-typical-set" class="nav-link" data-scroll-target="#metropolis-and-the-typical-set">Metropolis and the typical set</a></li>
  <li><a href="#hamiltonian-monte-carlo" id="toc-hamiltonian-monte-carlo" class="nav-link" data-scroll-target="#hamiltonian-monte-carlo">Hamiltonian Monte-Carlo</a>
  <ul class="collapse">
  <li><a href="#crafting-a-proposal-distribution-for-the-typical-set" id="toc-crafting-a-proposal-distribution-for-the-typical-set" class="nav-link" data-scroll-target="#crafting-a-proposal-distribution-for-the-typical-set">Crafting a proposal distribution for the typical set</a>
  <ul class="collapse">
  <li><a href="#augmenting-with-the-momenta" id="toc-augmenting-with-the-momenta" class="nav-link" data-scroll-target="#augmenting-with-the-momenta">Augmenting with the momenta</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#therefore" id="toc-therefore" class="nav-link" data-scroll-target="#therefore">Therefore:</a>
  <ul class="collapse">
  <li><a href="#stages-to-generate-a-proposal-distribution" id="toc-stages-to-generate-a-proposal-distribution" class="nav-link" data-scroll-target="#stages-to-generate-a-proposal-distribution">3 stages to generate a proposal distribution</a></li>
  </ul></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"><img src="../../images/hmc.gif" class="img-fluid"></a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>In the last couple of weeks, We’ve seen how the most difficult part of Bayesian Statistics is computing the posterior distribution. In particular, in the last week, we’ve studied the <a href="https://david-salazar.github.io/2020/06/29/bayesian-data-analysis-week-5-metropolis/">Metropolis Algorithm</a>. In this blogpost, I’ll study why Metropolis <strong>does not scale well enough to high dimensions</strong> and give an <em>intuitive explanation</em> of our best alternative: <strong>Hamiltonian Monte Carlo</strong> (HMC).</p>
<p>This blogpost is my personal digestion of the excellent content that Michael Betancourt has put out there to explain HMC. I particularly enjoyed his <a href="https://www.youtube.com/watch?v=jUSZboSq1zg&amp;t=1638s">YouTube lecture</a> and his blogpost about <a href="https://betanalpha.github.io/assets/case_studies/probabilistic_computation.html">Probabilistic computation</a>.</p>
<section id="metropolis-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="metropolis-algorithm">Metropolis Algorithm</h2>
<p>As we’ve seen, the Metropolis algorithm is just a random walk through parameter space where the proposed jumps are corrected by a comparison of posterior densities to determine whether to move or not. That is, we can see the Metropolis algorithm as:</p>
<blockquote class="blockquote">
<p>A stochastic version of a stepwise mode-finding algorithm, always accepting steps that increase the density until it finds the mode and then only sometimes accepting steps that decrease the posterior density.</p>
</blockquote>
<p>Thus, as long as the algorithm has run long enough to find the posterior mode, <strong>and the area around the mode is a good representation of the overall posterior</strong>, the Metropolis Algorithm will work. Sadly, this assumption only holds for lower dimensions</p>
</section>
<section id="an-expectation-in-low-dimensions" class="level2">
<h2 class="anchored" data-anchor-id="an-expectation-in-low-dimensions">An Expectation in low dimensions</h2>
<p>Fundamentally, we sample from the posterior in order to compute Monte-Carlo estimators. That is, we want to approximate expectations:</p>
<p><span class="math display">\[
\mathbb{E}_{\pi}[f]=\int_{Q} \mathrm{d} q \pi(q) f(q)
\]</span></p>
<p>With the Metropolis algorithm, we are saying that we can approximate these expectation by computing at values near the mode of <span class="math inline">\(\pi(q)\)</span> and occasionally exploring lower density parts. Which is a pretty good approximation of most unimodal low dimensional probability distributions. However, this entirely ignores the contribution of <span class="math inline">\(\mathrm{d} q\)</span>, the differential volume, to the integral.</p>
</section>
<section id="an-expectation-in-high-dimensions" class="level2">
<h2 class="anchored" data-anchor-id="an-expectation-in-high-dimensions">An Expectation in high dimensions</h2>
<p>However, as the number of dimensions grows, so does the importance of <span class="math inline">\(\mathrm{d} q\)</span>, the differential volume, to the integral. Therefore, in higher dimensions, ignoring the differential volume when computing the expectation guarantees biased samples. Why does this happen? This is due to a phenomenon called <strong>concentration of measure</strong>.</p>
<p>Intuitively, an integral is nothing more than a weighted sum of parts of the distribution with height equal to function heights. However, as dimensions grows, <strong>the contribution of any single part of the distribution to the integral decreases very rapidly</strong>. Why? Because, the relative differential volume of this single part of the distribution decreases as we increase the number of dimensions. Michael’s Betancourt box-experiment is very illuminating.</p>
<section id="corner-madness" class="level3">
<h3 class="anchored" data-anchor-id="corner-madness">Corner Madness</h3>
<blockquote class="blockquote">
<p>Let’s begin with a simple example - a square box representing the ambient space. In each dimension we will partition the box into three smaller boxes, with the central box corresponding to the neighborhood around the mode and the outer two side boxes corresponding to the rest of the space.</p>
</blockquote>
<p>In one dimension, the central box encapsulates one third of the total volume. In two dimensions, there are nine boxes, thus the central box represents only 1/9 of the volume. In three dimensions, we must fill the corners of the corners with more boxes, thus creating 27 boxes. The central box now only represents 1/27 of the total volume. We can keep increasing dimensions with the aid of Monte-Carlo samples.</p>
<blockquote class="blockquote">
<p>The relative importance of the central box is its probability with respect to a uniform distribution over the enclosing box, which we can estimate by sampling from that uniform distribution and computing the Monte Carlo estimator of the expectation value of the corresponding inclusion function</p>
</blockquote>
<p><span class="math display">\[
P(CentralBox) \approx \dfrac{N_{centralBox}}{N}
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>Ds <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>prob_means <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="sc">*</span> Ds</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (D <span class="cf">in</span> Ds) {</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  is_central_samples <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, N)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample a new point one dimension at a time</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (d <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>D) {</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>      q_d <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If the sampled component is not contained </span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># within the central interval then set the </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># inclusion function to zero</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (<span class="sc">-</span><span class="dv">1</span> <span class="sc">&gt;</span> q_d <span class="sc">||</span> q_d <span class="sc">&gt;</span> <span class="dv">1</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        is_central_samples[n] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Estimate the relative volume as a probability</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  prob_means[D] <span class="ot">&lt;-</span> <span class="fu">mean</span>(is_central_samples)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">dimensions =</span> Ds, <span class="at">prob_central_box =</span> prob_means) <span class="sc">%&gt;%</span> </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(dimensions, prob_central_box)) <span class="sc">+</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_step</span>(<span class="at">color =</span> <span class="st">"dodgerblue4"</span>) <span class="sc">+</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>percent) <span class="sc">+</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">+</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"Probability of central box"</span>,</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"As dimensions grow, volume of a single box decreases rapidly"</span>,</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Central Box Volume in high dimensions"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="2020-07-02-bda-week-6-mcmc-in-high-dimensions-hamiltonian-monte-carlo_files/figure-html/box-1.png" class="img-fluid" width="768"></p>
</div>
</div>
</section>
<section id="all-that-matters-the-typical-set" class="level3">
<h3 class="anchored" data-anchor-id="all-that-matters-the-typical-set">All that matters: the typical set</h3>
<p>Thus, the volume of a single neighborhood of the distribution decreases very rapidly as the number of dimensions grow. In our expectation, thus, the mode of the density <span class="math inline">\(\pi(q)\)</span> represents a neighborhood of the distribution with less and less volume and thus less and less probability mass. Indeed, in higher dimensions, our earlier <strong>intuition of a a probability distribution as concentrating around the mode and quickly decreasing is terribly wrong.</strong></p>
<p>Indeed, the probability of mass of any neighborhood of the distribution really depends on the interplay between its volume and the density. Without both of them, the probability mass at that neighborhood the distribution vanishes. Indeed, Michael Betancourt’s has a great plot showing where the volume and the target density interact to create large probability mass:</p>
<p><img src="../../images/typicalset.PNG" class="img-fluid"></p>
<blockquote class="blockquote">
<p>The neighborhood immediately around the mode features large densities, but in more than a few dimensions the small volume of that neighborhood prevents it from having much contribution to any expectation. On the other hand, the complimentary neighborhood far away from the mode features a much larger volume, but the vanishing densities lead to similarly negligible contributions expectations. The only significant contributions come from the neighborhood between these two extremes known as the typical set</p>
</blockquote>
<p>Therefore, to calculate an expectation <strong>it suffices to sample from the typical set</strong> instead of the <em>entire</em> parameter space. The question, then, is what is exactly the shape of this typical set?</p>
</section>
<section id="a-surface-concentrating-away-from-the-mode" class="level3">
<h3 class="anchored" data-anchor-id="a-surface-concentrating-away-from-the-mode">A surface concentrating away from the mode</h3>
<p>As the number of dimensions grows and grows, the increasing tension between probability density and volume yields a worse compromise, and those compromises are found at points further and further from the mode. <strong>This is known as concentration of measure</strong>. Thus:</p>
<blockquote class="blockquote">
<p>The repulsion of the typical set away from the mode implies that the relative breadth of the typical set, how far its fuzziness diffuses, shrinks with increasing dimension. As we consider higher-dimensional spaces the typical set becomes ever more thin and gossamer, and all the harder to find and explore.</p>
</blockquote>
<p>Thus, the typical set, as the number of dimensions grow, becomes a narrow ridge of probability that becomes very difficult to explore with guess and check algorithms like the Metropolis algorithm.</p>
</section>
</section>
<section id="metropolis-and-the-typical-set" class="level2">
<h2 class="anchored" data-anchor-id="metropolis-and-the-typical-set">Metropolis and the typical set</h2>
<p>The Metropolis Algorithm is not equipped to sample from the typical set. As we’ve seen, it’s a mode finding algorithm that explores the neighborhood around it. However, this neighborhood, as we’ve just seen, has barely any volume in high dimensions and thus have barely any probability mass. Indeed, given the narrowness of the typical set, almost all proposed jumps of the random walk will be outside the typical set and thus will be rejected.</p>
<p>Therefore, <strong>the Metropolis Algorithm in high dimensions results in inaction</strong>: the Metropolis algorithm will end up without moving at all for a long time. Thus, being a waste of our computational resources.</p>
<p>In two dimensions, we can visualize a typical set as a thin donut: at any point within it, there’s only a narrow ridge of points next to it that also belong to the typical set. <strong>Any ad-hoc proposal distribution that guesses in which direction we should move will be biased to propose points outside the typical set that will be rejected once we compare the Metropolis acceptance probability</strong>.</p>
<p>Chi Feng <a href="https://chi-feng.github.io/mcmc-demo/">has awesome interactive visualizations</a> that represent exactly this conundrum:</p>
<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD <img src="../../images/metropolis.gif" class="img-fluid"> ======= <img src="../../images/metropolis.GIF" class="img-fluid"> &gt;&gt;&gt;&gt;&gt;&gt;&gt; abe09e3cd313dfc12630c3063c969959af729a6a</p>
</section>
<section id="hamiltonian-monte-carlo" class="level1">
<h1>Hamiltonian Monte-Carlo</h1>
<p>So far, we’ve identified the fundamental problem with the random walk in the Metropolis algorithm: <em>in higher dimensions</em>, its <strong>adhoc proposal distribution guesses too many dumb jumps that take us out of the narrow ridge of high probability mass that is the typical set</strong>. How to fix this? Create a proposal distribution that takes into account the geometry of the typical set and makes intelligent proposal?</p>
<p>An intelligent proposal should make proposals within the typical set AND make proposals that are far away from where we currently are. Thus, we will explore the typical set as efficiently as possible. Hamiltonian Monte-Carlo algorithms, when well tuned, satisfy both conditions.</p>
<section id="crafting-a-proposal-distribution-for-the-typical-set" class="level2">
<h2 class="anchored" data-anchor-id="crafting-a-proposal-distribution-for-the-typical-set">Crafting a proposal distribution for the typical set</h2>
<p>We’ve identified that an intelligent proposal distribution will encode the geometry of the typical set. A natural way of encoding this geometry is with a <em>vector field</em> <strong>aligned with the typical set</strong>. Thus, instead of taking a random-walk through parameter space, we will simply follow the vector field for some time. Therefore:</p>
<blockquote class="blockquote">
<p>Continuing this process traces out a coherent trajectory through the typical set that efficiently moves us far away from the initial point to new, unexplored regions of the typical set as quickly as possible.</p>
</blockquote>
<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD The question, then, is how to create these vector field? A first approximation is to exploit the differential structure of the posterior through the gradient. However, following the gradient pulls us away from the typical set and into the mode of the posterior. Here comes Physics to the rescue. This is an equivalent problem to the problem of placing a satellite in a stable orbit around a hypothetical planet. ======= The question, then, is how to create these vector field? A first approximation is to exploit the differential structure of the posterior thoruhg the gradient. However, following the gradient pulls us away from the typical set and into the mode of the posterior. Here comes Physics to the rescue. This is an equivalent problem to the problem of placing a satellite in a stable orbit around a hypothetical planet. &gt;&gt;&gt;&gt;&gt;&gt;&gt; abe09e3cd313dfc12630c3063c969959af729a6a</p>
<p>The key to do it is to endow our walk through the typical set by with enough momentum (<span class="math inline">\(p\)</span>) to counteract the gravitation attraction of the mode. Therefore:</p>
<blockquote class="blockquote">
<p>We can <em>twist</em> the gradient vector field into a vector field aligned with the typical set if we expand our original probabilistic system with the introduction of auxiliary momentum parameters.</p>
</blockquote>
<section id="augmenting-with-the-momenta" class="level3">
<h3 class="anchored" data-anchor-id="augmenting-with-the-momenta">Augmenting with the momenta</h3>
<p>We augment our probabilistic system with the momenta <span class="math inline">\(p\)</span> thus:</p>
<p><span class="math display">\[
\pi(q, p)=\pi(p \mid q) \pi(q)
\]</span></p>
<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Which allows us to ignore the momenta when necessary by marginalizing it. The joint density <span class="math inline">\(\pi(q, p)\)</span> defines a Hamiltonian</p>
<p><span class="math display">\[
H(p, q) = - log \pi(p,\theta)
\]</span></p>
<p>Thus, given some point in the phase space <span class="math inline">\((q_0, p_0)\)</span> that is in the typical set, the Hamiltonian defines how to generate a new sample such that we stay in the typical set.</p>
</section>
</section>
</section>
<section id="therefore" class="level1">
<h1>Therefore:</h1>
<p>Which allows us to ignore the momenta when necessary by marginalizing it. The joint density <span class="math inline">\(\pi(q, p)\)</span> is constructed following Hamiltonian dynamics. Therefore: &gt;&gt;&gt;&gt;&gt;&gt;&gt; abe09e3cd313dfc12630c3063c969959af729a6a</p>
<blockquote class="blockquote">
<p>Following the Hamiltonian vector field for some time, ( t ), generates trajectories, ( _{t}(q, p), ) that rapidly move through phase <span class="math inline">\((q_n, p_n)\)</span> space while being constrained to the typical set. Projecting these trajectories back down onto the target parameter space finally yields the efficient exploration of the target typical set for which we are searching.</p>
</blockquote>
<section id="stages-to-generate-a-proposal-distribution" class="level3">
<h3 class="anchored" data-anchor-id="stages-to-generate-a-proposal-distribution">3 stages to generate a proposal distribution</h3>
<p>Suppose you are at <span class="math inline">\(q_0\)</span>. How to generate a new proposal?</p>
<ol type="1">
<li>We start by sampling a momentum from <span class="math inline">\(p_0\)</span> from:</li>
</ol>
<p><span class="math display">\[
p_0 \sim \pi(p | q)
\]</span></p>
<p>We know are in the phase space <span class="math inline">\((q_0, p_0)\)</span>.</p>
<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD 2. If we follow the vector field by following Hamilton’s equations that we have created ( <em>{t}(q_0, p_0) = q^<em>, p^</em>, ) by integrating for some time <span class="math inline">\(t\)</span>, we coherently push the Markov transition away from the initial point while staying confined to the joint typical set. This movement through the field space is done via discrete <span class="math inline">\(L\)</span> <em>‘leapfrog steps’</em> with discretization time <span class="math inline">\(\epsilon\)</span>. Stan’s implementation of HMC automatically chooses both of these values. ======= 2. If we follow the vector field that we have created ( </em>{t}(q_0, p_0) = q^<em>, p^</em>, ) by integrating for some time <span class="math inline">\(t\)</span>, we coherently push the Markov transition away from the initial point while staying confined to the joint typical set. This movement through the field space is done via discrete <span class="math inline">\(L\)</span> <em>‘leapfrog steps’</em>. Stan’s implementation of HMC automatically chooses the leapfrog steps and their respective length. &gt;&gt;&gt;&gt;&gt;&gt;&gt; abe09e3cd313dfc12630c3063c969959af729a6a</p>
<ol start="3" type="1">
<li>If we marginalize the momenta, we project it away and go back to the parameter space with a proposal <span class="math inline">\(q^*\)</span>.</li>
</ol>
<p>Because we have followed the vector field in phase space and projected the momenta away, if we started in the typical set, our proposal is guaranteed to be on the typical set, too. <strong>Thus, allowing extremely efficient exploration of the typical set.</strong></p>
<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Finally, we will accept or reject our proposed jump with a Metropolis ratio.</p>
<p><span class="math display">\[
r = \min \left(1, \exp \left(H(p_0, \theta_0)-H\left(p^{*}, \theta^{*}\right)\right)\right)
\]</span></p>
<p>Thus, with probability <span class="math inline">\(r\)</span>, we set <span class="math inline">\(\theta_1 = \theta^*\)</span>. Otherwise, <span class="math inline">\(\theta_1 = \theta_0\)</span>.</p>
<p>We can visualize the incredible efficiency that Hamiltonian Monte Carlo can deliver. In the exact same example as with the donut we just saw with Metropolis, HMC samples much more efficiently.</p>
</section>
</section>
<section id="section" class="level1">
<h1><img src="../../images/hmc.gif" class="img-fluid"></h1>
<p>Finally, we will accept or reject our proposed jump with a Metropolis-Hastings ratio.</p>
<p>We can visualize the incredible efficiency that Hamiltonian Monte Carlo can deliver. In the exact same example as with the donut we just saw with Metropolis, HMC samples much more efficiently.</p>
<p><img src="../../images/hmc.GIF" class="img-fluid"></p>
<blockquote class="blockquote">
<blockquote class="blockquote">
<blockquote class="blockquote">
<blockquote class="blockquote">
<blockquote class="blockquote">
<blockquote class="blockquote">
<blockquote class="blockquote">
<p>abe09e3cd313dfc12630c3063c969959af729a6a</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>High dimensional probability distributions are difficult to understand. Instead of piling much of the probability mass around the mode, the probability mass lies at the intersection of the neighborhoods where there is volume and there is target density. <strong>This area of probability mass is a narrow surface that lies far from the mode and is called the typical set.</strong> Random walk algorithms, like Metropolis, are fundamentally ill-suited to explore such narrow surfaces: their ad-hoc proposal distributions are biased to propose jumps that lie outside the typical set and thus the jumps are rejected. The end result, the chains explore the typical set very inefficiently.</p>
<p>On the other hand, <strong>Hamiltonian Monte Carlo (HMC) algorithms are precisely constructed to exploit the geometry of the typical set</strong> and make intelligent proposals. By borrowing Hamiltonian dynamics from physics, we create proposals that follow a vector-field that is aligned with the typical set. Thus, our proposals will lie on the typical set and will be much more likely to be accepted than the proposals of a random walk like those of Metropolis. Therefore, HMC allows us to efficiently explore the typical set.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>