<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.91.2" />


<title>Causality: Bayesian Networks and Probability Distributions - David Salazar&#39;s blog</title>
<meta property="og:title" content="Causality: Bayesian Networks and Probability Distributions - David Salazar&#39;s blog">


  <link href='https://david-salazar.github.io/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/booglee.jpeg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">10 min read</span>
    

    <h1 class="article-title">Causality: Bayesian Networks and Probability Distributions</h1>

    
    <span class="article-date">2020-07-18</span>
    

    <div class="article-content">
      


<div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>Stats people know that <strong>correlation coefficients do not imply causal effects</strong>. Yet, very often, <em>partial correlation</em> coefficients from <strong>regressions with an ever growing set of ‘control variables’</strong> are unequivocally interpreted as a step in the <em>right direction</em> toward estimating a <strong>causal effect</strong>. This mistaken intuition was aptly named by Richard McElreath, in his fantastic <a href="https://xcelab.net/rm/statistical-rethinking/">Stats course</a>, as <em>Causal Salad</em>: people toss a bunch of control variables and hope to get a casual effect out of it.</p>
<p>In his fantastic course, Richard offers a clear and intuitive <em>antidote</em> for the Causal Salad: <strong>Graph Models for Causality</strong>. In these series of blogposts, I’ll explore the work of <a href="http://bayes.cs.ucla.edu/jp_home.html">Judea Pearl</a>, the father of the Graphical approach toward Causality. In particular, I’ll share what I learn from his book <a href="http://bayes.cs.ucla.edu/jp_home.html">Causality: Models, Reasoning and Inference</a></p>
<p>In this blogpost, I’ll explore Bayesian Networks: the simplest of probability networks to represent a joint distribution and how we can derive testable implications from them using the <strong>d-separation</strong> criterion. Thorough the blopost, I’ll be using the excellent packages <code>dagitty</code> and <code>ggdag</code>.</p>
</div>
<div id="bayesian-networks" class="section level2">
<h2>Bayesian Networks</h2>
<p><em>Joint probability distributions</em> are tricky objects to represent: both in our heads and in our computers. They can imply an unworldly number of relationships. Probability theory gives us in the chain rule of probability a tool to <strong>decompose</strong> a joint probability distribution.</p>
<p>Suppose we have a distribution <span class="math inline">\(P\)</span> defined on <span class="math inline">\(n\)</span> discrete variables, which we may <strong>order</strong> arbitrarily as <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n} .\)</span> The chain rule of probability calculus always permits us to decompose <span class="math inline">\(P\)</span> as a product of <span class="math inline">\(n\)</span> <strong>conditional distributions</strong>:</p>
<p><span class="math display">\[
P\left(x_{1}, \ldots, x_{n}\right)=\prod_{j} P\left(x_{j} \mid x_{1}, \ldots, x_{j-1}\right)
\]</span></p>
<p>Given <em>structural knowledge</em> about the problem at hand, we can <em>simplify this decomposition</em> given the <strong>conditional independence</strong> we posit in our model of the joint distribution. That is, it is not always necessary to condition on all the other variables: it <em>suffices</em> to control in a minimal set of variables to render <strong>other predecessor variables independent</strong>. For a given variable <span class="math inline">\(x_j\)</span> let’s name this set of variables <span class="math inline">\(pa_j\)</span>: the parents of the variable <span class="math inline">\(x_j\)</span>.</p>
<p>We can then start constructing a graph (a Bayesian Network): each node will be a random variable; for any node, the arrows that enter into it represent the fact that <em>conditional on its parents</em>, <strong>the variable is conditionally independent of all other preceding variables</strong>. That is, at the <span class="math inline">\(j\)</span>th stage of construction, we only draw an incoming arrow into <span class="math inline">\(x_j\)</span> from its parents; conditional on its parents, all other predecessors are independent. Therefore, a <strong>missing arrow</strong> between any two nodes means that they are independent, once we know the values of their parents.</p>
<div id="an-example" class="section level3">
<h3>An example</h3>
<p>Let’s say we’re looking at the relationship between smoking and cardiac arrest. We might assume that smoking causes changes in cholesterol, which causes cardiac arrest. We start assuming that unhealthy lifestyle is the only <strong>‘Parent’</strong> for both smoking and weight:</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/first-1.png" width="672" /></p>
<p>Then, we assume that the <strong>‘Parents’</strong> of cholesterol are Smoking and Weight:</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/second-1.png" width="672" /></p>
<p>Finally, we assume that Cholesterol is the only <em>‘Parent’</em> of Cardiac Arrest</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/third-1.png" width="672" /></p>
<p>Therefore, the arrows, by specifying what are the conditional independencies that hold in our model, tell us that what is the <em>recursive decomposition</em> of the joint probability distribution implied by the model. In this case, thus:</p>
<p><span class="math display">\[
P\left(x_{1}, x_2, x_3, x_4, x_{5}\right) = p(x_1) p(x_2 | x_1) p (x_3 | x_1) p(x_4| x_2, x_3) p (x_5 | x_4) 
\]</span></p>
</div>
<div id="probability-connections-markov-compatibility" class="section level3">
<h3>Probability connections: Markov Compatibility</h3>
<p>Whenever a joint probability distribution <span class="math inline">\(P\)</span> admits the decomposition posited by our graphical model <span class="math inline">\(G\)</span>, we say that <span class="math inline">\(P\)</span> is Markov Relative to <span class="math inline">\(G\)</span>. That is, it means that <span class="math inline">\(G\)</span> can explain the generation of the data represented by <span class="math inline">\(P\)</span>.</p>
<p>Once we know the probabilistic connection between our Graph and a probability distribution, we may be interested in deriving the <strong>testable implications</strong> of our graphical model <span class="math inline">\(G\)</span>. What other conditions does it imply about the probability distribution P?</p>
<p>In particular, in deriving which variables are independent and dependent, both marginally and conditional on other variables. Thanks to our graphical representation, we can derive an algorithm that returns all <em>implied independencies</em> that the model expects that will hold in the <em>data</em>: <strong>the d-separation criterion</strong>.</p>
</div>
</div>
<div id="d-separation-blocking-the-information-flows" class="section level2">
<h2>d-separation: blocking the information flows</h2>
<p>Deriving testable implications from our assumptions is not as easy as it looks. Take the following example:</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/example-1.png" width="672" /></p>
<p>Can we make <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> conditionally dependent? The answer is not evident. To answer this question, we must understand how the <strong>statistical information moves</strong> through our graph.</p>
</div>
<div id="open-paths" class="section level2">
<h2>Open paths</h2>
<p>In our Graph <span class="math inline">\(G\)</span>, the information moves across variables <em>regardless</em> of the direction of the arrows. If there is an open path between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, then, the information will flow and thus make the two variables dependent. The question, then, is what is an open path? The d-criterion answers precisely this question:</p>
<p><span class="math inline">\(A\)</span> path <span class="math inline">\(p\)</span> is said to be blocked (or <span class="math inline">\(d\)</span> -separated) by a set of nodes <span class="math inline">\(Z\)</span> if and only if any of the following conditions hold:</p>
<ol style="list-style-type: decimal">
<li><p>if <span class="math inline">\(p\)</span> contains a chain <span class="math inline">\(i \rightarrow m \rightarrow j\)</span> or a fork <span class="math inline">\(i \leftarrow m \rightarrow j\)</span> such that the middle node <span class="math inline">\(m\)</span> is in <span class="math inline">\(Z\)</span>.</p></li>
<li><p>if <span class="math inline">\(p\)</span> contains a collider <span class="math inline">\(i \rightarrow m \leftarrow j\)</span> such that the middle node <span class="math inline">\(m\)</span> is not in <span class="math inline">\(Z\)</span> and
such that no descendant of <span class="math inline">\(m\)</span> is in <span class="math inline">\(Z\)</span>.</p></li>
</ol>
<p>Let’s examine why is that both conditions guarantee that the path is closed.</p>
<div id="of-chains-and-forks" class="section level3">
<h3>Of chains and forks</h3>
<p>In both chains and forks, <em>the extreme variables</em> are <strong>marginally dependent</strong>. However, once we <em>adjust by the middle variable</em> they become <strong>marginally independent</strong>. That is, the information between the extreme variables that was previously flowing stops flowing altogether. Why?</p>
</div>
<div id="chains" class="section level3">
<h3>Chains</h3>
<p>Let’s look at an example of the chain where addictive behavior causes the person to smoke which causes Cancer. If we don’t adjust by any variable, the information flows freely: knowing whether some has an addictive behavior can tell us whether they smoke, and thus tells us something about the probability that they have cancer.</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/mediation-1.png" width="672" /></p>
<p>However, if we adjust by a particular level of smoking (as in the above figure), knowing the addictive behavior of someone tells us nothing about the probability that they have cancer: the level of smoking says it all already. Thus, addictive behavior and cancer are d-separated by smoking.</p>
</div>
<div id="forks" class="section level3">
<h3>Forks</h3>
<p>With forks, the story is extremely similar: the middle variable is a common cause for both of the extreme variables. Thus, they are marginally dependent. For example, let’s say that addictive behavior causes both smoking and drinking coffee.</p>
<p>If we don’t know whether someone has an addictive behavior or not, the fact that they drink lots of coffee tells us that they are likely to have an addicting behavior and thus are more likely to smoke.</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/fork,%20coffee-1.png" width="672" /></p>
<p>However, once we adjust by a specific value of addictive behavior (as in the above figure), drinking coffee does not say anything about smoking, the value of addictive behavior has said it all already: <strong>they are independent conditional on addictive behavior</strong>.</p>
<p>It is only in the absence of knowing addictive behavior that they capture information from one another. That is, they are only dependent when we don’t adjust by addictive behavior.</p>
<p>Therefore, whenever a <strong>path has either a fork or a chain, we can block that path by conditioning on the middle variable</strong>.</p>
</div>
<div id="of-colliders" class="section level3">
<h3>Of Colliders</h3>
<p>Whereas before we spoke of open paths that were closed once we adjust, a collider starts being a closed path an only is opened once we adjust by the middle variable. The middle variable is a common consequence of two marginally independent causes: if we adjust by the consequence, we render the common causes dependent.</p>
<p>Take the following example: being a hollywood actor results from either being attractive or being talented. Being attractive and being talented are independent; however, once we know whether someone is a hollywood actor, knowing one of the characteristics tells us about the other. e.g., if the actor is not talented, it tells us that the actor, to be in hollywood, then must be attractive.</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/collider-1.png" width="672" /></p>
<p>Therefore, if a path has a collider it will remained closed unless we adjust by the middle variable or one of its descendants.</p>
</div>
<div id="the-probabilistic-implications-of-the-d-separation-criterion" class="section level3">
<h3>The probabilistic implications of the d-separation criterion</h3>
<p>Once we have understood our d-separation criterion, we can connect this graphical analysis with a counterpart probability implication:</p>
<p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <span class="math inline">\(d\)</span> -separated by <span class="math inline">\(Z\)</span> in a DAG
<span class="math inline">\(G,\)</span> then <span class="math inline">\(X\)</span> is independent of <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\(Z\)</span> in every distribution compatible with <span class="math inline">\(G\)</span>. Conversely, if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not <span class="math inline">\(d\)</span> -separated by <span class="math inline">\(Z\)</span> in a DAG <span class="math inline">\(G\)</span>, then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are dependent conditional on <span class="math inline">\(Z\)</span></p>
</div>
<div id="putting-the-d-separation-criterion-to-the-test" class="section level3">
<h3>Putting the d-separation criterion to the test</h3>
<p>Armed with the d-separation criterion, we can ask ourselves, given our earlier that I reproduce below, how can we make <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> conditionally dependent?</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/example-repe-1.png" width="672" /></p>
<p>The answer, of course, is the d-separation criterion: can we open the path from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> by conditioning on some variable? Armed with what we just learned, the answer is now clear: <span class="math inline">\(z_1\)</span> is a collider that lies in the path. To open it, we must condition on it. Therefore, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are dependent conditional on <span class="math inline">\(z_1\)</span>. We can easily check our logic with <code>dagitty::dconnected</code>:</p>
<pre class="r"><code>dconnected(example, &quot;X&quot;, &quot;Y&quot;, &quot;Z1&quot;)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>We can repeat this exercise for <strong>every pair of variables</strong> and check whether they are <em>conditionally (or marginally) independent</em> given some set of controlling variables. The set of variables that are conditionally independent, then, constitute the <strong>set of testable implications</strong> of our model. Therefore, we can check whether our Graphical model is consistent with a given dataset by <em>comparing</em> the <strong>implied conditional independence</strong> with the <strong>observed conditional independence</strong> in our data.</p>
<p>For the above model, then, the implied conditional independencies are:</p>
<pre class="r"><code>impliedConditionalIndependencies(example)</code></pre>
<pre><code>## X _||_ Y
## X _||_ Z2
## X _||_ Z3
## Y _||_ Z1 | Z2
## Y _||_ Z1 | Z3
## Y _||_ Z2 | Z3
## Z1 _||_ Z3 | Z2</code></pre>
</div>
</div>
<div id="can-we-distinguish-models-from-data-alone" class="section level2">
<h2>Can we distinguish models from data alone?</h2>
<p>We finally have an strategy to test whether our model implications are in accordance with our observed values. However, it stands to reason that our model is not unique in this regard: there are other models that imply the same conditional independencies. We say, thus, that the two graphical models <span class="math inline">\(G_1\)</span> and <span class="math inline">\(G_2\)</span> are <strong>observationally equivalent</strong> when they imply the same conditional independencies. The set of all the models with indistinguishable implications is called an equivalence class.</p>
<p>That is, if two models are observationally equivalent, we cannot use data alone to distinguish from them. We must use our structural knowledge about the problem at hand to decide which model is the right one. Therefore, <strong>Observational equivalence</strong> places a <em>limit</em> on our ability to <strong>infer directionality from probabilities alone</strong>.</p>
<p>For <em>simple models</em>, the <strong>limitations are draconian</strong>. Let’s take as an example the fork we just analyzed where addictive behavior is a fork between drinking coffee and smoking:</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/fork-repeated-1.png" width="672" /></p>
<p>Let’s check what are this model’s testable implications:</p>
<pre class="r"><code>impliedConditionalIndependencies(dagify(x ~ f,
       y ~ f,
       labels = c(&quot;x&quot; = &quot;Coffee&quot;, 
                  &quot;y&quot; = &quot;Smoking&quot;, &quot;f&quot; = &quot;Addictive \nBehavior&quot;)))</code></pre>
<pre><code>## x _||_ y | f</code></pre>
<p>Not surprisingly, the only conditional implication implied is that drinking coffee is independent on smoking once we condition on the addictive behavior. That is, <strong>that coffee is d-separated from smoking by addictive behavior</strong>.</p>
</div>
<div id="identifying-models" class="section level2">
<h2>Identifying models</h2>
<p>Suppose for a moment that the arrows in our Graph are now endowed with causal meaning: there’s an arrow from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> if <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>. For the moment, it will suffice your intuitive understanding of what this means.</p>
<p>The Causal Graph will still have all the characteristics of a simple Bayesian Graph. Then, we can ask: What <em>other causal models</em> have only this <strong>testable implication</strong>? That is, with only observational data, can we distinguish between causal (interventional) models?</p>
<p><img src="/post/2020-07-18-causality-bayesian-networks_files/figure-html/equivalent-1.png" width="672" /></p>
<p>Thus, <strong>from data-alone we cannot infer the directionality of any of three posited causal relationships</strong>. That is, data alone cannot settle the issue of whether the appropriate model is a fork or a chain that begins at either coffee or smoking. As Pearl says, <strong>data are fundamentally dumb</strong>: if we rely only in data to inform our models, we are extremely limited on what we can learn from them. Therefore, we must extend our theory beyond <strong>conditional probabilities</strong>.</p>
<p>That is, we cannot predict the consequences of intervening in one of the variables with only observational data. That is, <strong>we cannot gain causal understanding with only observational data</strong>: we must assume a causal model to predict the the consequences of any intervention (i.e., the causal effects).</p>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

