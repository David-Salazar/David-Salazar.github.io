{
  "hash": "47617bb4d81ed09b1bba2123b5fa365a",
  "result": {
    "markdown": "---\ntitle: 'Statistical Rethinking: Week 2'\nauthor: ''\ndate: '2020-04-28'\nslug: statistical-rethinking-week-2\ncategories: []\ntags: []\naliases: \n  - ../../2020/04/28/statistical-rethinking-week-2/\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rethinking)\nlibrary(tidyverse)\nlibrary(ggridges)\nextrafont::loadfonts(device=\"win\") \nset.seed(24)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"Howell1\")\nprecis(Howell1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              mean         sd      5.5%     94.5%     histogram\nheight 138.2635963 27.6024476 81.108550 165.73500 ▁▁▁▁▁▁▁▂▁▇▇▅▁\nweight  35.6106176 14.7191782  9.360721  54.50289 ▁▂▃▂▂▂▂▅▇▇▃▂▁\nage     29.3443934 20.7468882  1.000000  66.13500     ▇▅▅▃▅▂▂▁▁\nmale     0.4724265  0.4996986  0.000000   1.00000    ▇▁▁▁▁▁▁▁▁▇\n```\n:::\n:::\n\n\n# Week 2\n\nWeek 2 has gotten us to start exploring linear regression from a bayesian perspective. I found it the most interesting to propagate uncertainty through the model.\n\n## Homework\n\n> The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% compatibility intervals for each of these individuals. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(individual = seq(1, 5), weight = c(45, 40, 65, 31, 53),\n       expected_height = NA, left_interval = NA, right_interval = NA) -> to_predict\nto_predict\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 5\n  individual weight expected_height left_interval right_interval\n       <int>  <dbl> <lgl>           <lgl>         <lgl>         \n1          1     45 NA              NA            NA            \n2          2     40 NA              NA            NA            \n3          3     65 NA              NA            NA            \n4          4     31 NA              NA            NA            \n5          5     53 NA              NA            NA            \n```\n:::\n:::\n\n\n### The model\n\nWe will fit a linear regression between the weight and the height. Thus, we will predict the aforementioned individuals. The model will have a normal likelihood:\n\n$$ height_i \\sim Normal(\\mu_i, \\sigma) $$\n$$ \\mu_i = \\alpha + \\beta (weight_i - \\bar{weight}) $$\nAnd the following priors:\n\n$$ \\alpha ~ Normal(178, 20) $$\n\n$$ \\beta \\sim LogNormal(0, 1) $$\n\n$$ \\sigma \\sim Uniform(0, 50) $$\n\nWhich translates in code thus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only keep the adults in the sample\ndata <- Howell1 %>% filter(age >= 18)\n\n# mean to later on center weight at 0\nxbar <- mean(data$weight)\n\n# fit the model\nmodel_linear <- quap(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + b*(weight - xbar),\n    a ~ dnorm(178, 20),\n    b ~ dlnorm(0, 1),\n    sigma ~ dunif(0, 50)\n  ),\n  data = data\n)\n```\n:::\n\n\nThe model fitted is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprecis(model_linear)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            mean         sd        5.5%      94.5%\na     154.601367 0.27030759 154.1693633 155.033371\nb       0.903281 0.04192362   0.8362789   0.970283\nsigma   5.071880 0.19115465   4.7663775   5.377382\n```\n:::\n:::\n\n\nThat is, a multivatiate normal with the above means and the following var-cov matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvcov(model_linear)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  a             b         sigma\na      7.306619e-02 -4.243897e-08  6.157797e-05\nb     -4.243897e-08  1.757590e-03 -2.518310e-05\nsigma  6.157797e-05 -2.518310e-05  3.654010e-02\n```\n:::\n:::\n\n\nNow, let's compute the expected height, according to our model, for the aforementioned individuals:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu <- sim(model_linear, data = to_predict, n = 10000)\n```\n:::\n\n\nNow, we have samples from the posterior with all the required parameters ($\\alpha, \\beta, \\sigma$) to predict our model's expected height for each of the individuals. Let's fill the table:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nto_predict$expected_height <- apply(mu, 2, mean)\nwhole_interval <- apply(mu, 2, PI, prob = 0.89)\nto_predict$left_interval <- whole_interval[1,]\nto_predict$right_interval <- whole_interval[2,]\nround(to_predict, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 5\n  individual weight expected_height left_interval right_interval\n       <dbl>  <dbl>           <dbl>         <dbl>          <dbl>\n1          1     45            155.          147.           163.\n2          2     40            150.          142.           158.\n3          3     65            173.          164.           181.\n4          4     31            142.          134.           150.\n5          5     53            162.          154.           170.\n```\n:::\n:::\n\n\nLet's visualize our predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomputed_with_samples <- data.frame(mu, index = seq(1, length(mu))) \ncolnames(computed_with_samples) <- c(45, 40, 65, 31, 53, \"index\")\n\ncomputed_with_samples%>% \n  pivot_longer(-index) %>% \n  rename(\"individual\" = name,\n         \"prediction\" = value) %>% \n  ggplot(aes(y = individual, x = prediction)) +\n    geom_density_ridges(scale = 0.8, fill = \"dodgerblue4\", alpha = 0.6) +\n  scale_y_discrete(expand = c(0, 0)) +     # will generally have to set the `expand` option\n  scale_x_continuous(expand = c(0, 0)) +   # for both axes to remove unneeded padding\n  coord_cartesian(clip = \"off\") + # to avoid clipping of the very top of the top ridgeline\n  hrbrthemes::theme_ipsum_rc(grid = \"x\") +\n  labs(title = \"Predictions averaged over posterior\",\n       subtitle = \"Not suprisingly, we predict higher heights for heavier people\",\n       x = \"Predicted height\",\n       y = \"Weight\")\n```\n\n::: {.cell-output-display}\n![](2020-04-28-statistical-rethinking-week-2_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggsave(\"ridges.png\")\n```\n:::\n\n\n> Model the relationship between height and the natural logarithm of weight using the entire data. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- Howell1\n```\n:::\n\n\nThus, the model we will be working with will be:\n\nWe will fit a linear regression between the weight and the height. Thus, we will predict the aforementioned individuals. The model will have a normal likelihood:\n\n$$ height_i \\sim Normal(\\mu_i, \\sigma) $$\n\n$$ \\mu_i = \\alpha + \\beta (log(weight_i) - log(\\bar{weight_i})) $$\nAnd the following priors:\n\n$$ \\alpha ~ Normal(178, 20) $$\n\n\n$$ \\beta \\sim LogNormal(0, 1) $$\n\n$$ \\sigma \\sim Uniform(0, 50) $$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n  mutate(log_weight = log(weight)) -> data_with_log\n\nx_bar <- mean(data_with_log$log_weight)\n\nlog_model <- quap(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + b*(log_weight ),\n    a ~ dnorm(178, 20),\n    b ~ dlnorm(0, 1),\n    sigma ~ dunif(0, 50)\n  ),\n  data = data_with_log\n)\n```\n:::\n\n\nLet's check the mean of the parameters of the posterior:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprecis(log_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            mean        sd       5.5%      94.5%\na     -22.874419 1.3343063 -25.006898 -20.741940\nb      46.817810 0.3823284  46.206776  47.428845\nsigma   5.137147 0.1558892   4.888006   5.386288\n```\n:::\n:::\n\n\nAnd the var-cov:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvcov(log_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 a            b        sigma\na      1.780373247 -0.503145565  0.008933974\nb     -0.503145565  0.146175019 -0.002528771\nsigma  0.008933974 -0.002528771  0.024301445\n```\n:::\n:::\n\n\nNow, let's plot our predictions for the range of weights that we have.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweights <- log(1:max(data$weight))\n\n\npredictions_from_posterior <- sim(log_model, data.frame(log_weight = weights), 10000)\n\n\nmu <- apply(predictions_from_posterior, 2, mean)\ninterval <- apply(predictions_from_posterior, 2, PI, prob = 0.75)\nleft_interval <- interval[1,]\nright_interval <- interval[2,]\n\n\ntibble(weights = exp(weights),\n       mu,\n       left_interval,\n       right_interval) %>% \n  ggplot(aes(weights, mu)) +\n    geom_line() +\n    geom_ribbon(aes(ymin = left_interval, ymax = right_interval), alpha = 0.3) +\n  geom_point(data = data_with_log, aes( x = weight, y = height), alpha = 0.3,\n             color = \"dodgerblue4\")  +\n  hrbrthemes::theme_ipsum_rc() +\n  labs(title = \"Model predictions in original space\",\n       subtitle = \"Shaded area represents 75% Percentage Interval\",\n       y = \"height\")\n```\n\n::: {.cell-output-display}\n![](2020-04-28-statistical-rethinking-week-2_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n> Plot the prior predictive distribution for the polynomial regression model of height \n\nSo, let's suppose that we are planning to fit the following model to the data. First, we would work with standardize weights. \n\n$$ height_i \\sim Normal(\\mu_i, \\sigma) $$\n\n$$ \\mu_i = \\alpha + \\beta_1 * weight_s + \\beta_2 weight_s^2 $$\nAnd the following priors:\n\n$$ \\alpha ~ Normal(178, 20) $$\n\n\n\n$$ \\beta_1 \\sim LogNormal(0, 1) $$\n\n$$ \\beta_2 \\sim dnorm(0, 1) $$\n\n$$ \\sigma \\sim Uniform(0, 50) $$\n\nWhat predictions do the priors we set are implying? To find out, let's sample from them:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 1000\na <- rnorm(N, 178, 20)\nb1 <- rlnorm(N, 0, 1)\nb2 <- rnorm(N, 0, 1)\n```\n:::\n\n\nNow, let's plot them:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_priors <- function(N, a, b1, b2) {\n  weights <- seq(-2, 2, length.out = 50)\n  data.frame(simulation = seq(1, N), intercept = a, first = b1, second = b2) %>% \n    mutate(prediction = pmap(list(intercept, first, second), function(first, second, third) first[1] + weights*second + weights^2*third)) %>% \n    unnest() %>% \n    mutate(weight = rep(weights, N)) %>% \n    ggplot(aes(x = weight, y = prediction, group = simulation)) +\n      geom_line(alpha = 0.1) +\n      ylim(c(0, 250)) +\n      hrbrthemes::theme_ipsum_rc() +\n    labs(y = \"Predicted height\",\n         title = \"Implied predictions by prior\",\n         x = \"weight z-score\")\n}\nplot_priors(N, a, b1, b2)\n```\n\n::: {.cell-output-display}\n![](2020-04-28-statistical-rethinking-week-2_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nThe curves have hardly any bent at all, which is what we would like to see knowing the polynomial relationship between height and weight. Let's try to put an uniform negative prior on the $b_2$ coefficient:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnegative_b2 <- runif(N, min = -10, max = 0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_priors(N, a, b1, negative_b2)\n```\n\n::: {.cell-output-display}\n![](2020-04-28-statistical-rethinking-week-2_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nHowever, the curves start to bend down to quickly. Let's change the prior on $b_1$ too:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb1_larger <- rlnorm(N, 4, 0.5)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_priors(N, a, b1_larger, negative_b2) +\n  ylim(c(0, 300)) +\n  labs(subtitle = \"Bend the implied predictions\")\n```\n\n::: {.cell-output-display}\n![](2020-04-28-statistical-rethinking-week-2_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggsave(\"prior.png\")\n```\n:::\n\n\nWe bent them! However, we created a prior that implies impossible predictions. This is very hard to set as the parameters should be set jointly. However, we are not considering any correlation between the samples.\n\n\n\n\n",
    "supporting": [
      "2020-04-28-statistical-rethinking-week-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}