<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.58.3" />


<title>Statistical Rethinking: Week 3 - Dilettanting Data Science</title>
<meta property="og:title" content="Statistical Rethinking: Week 3 - Dilettanting Data Science">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/turner.jpg"
         width="200"
         height="200"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://www.kaggle.com/davidsalazarv95">Kaggle</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir?lang=en">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">10 min read</span>
    

    <h1 class="article-title">Statistical Rethinking: Week 3</h1>

    
    <span class="article-date">2020/05/03</span>
    
    

    <div class="article-content">
      


<div id="statistical-rethinking-week-3" class="section level1">
<h1>Statistical Rethinking: Week 3</h1>
<p>Week 3 gave the most interesting discussion of multiple regression. Why isn’t it enough with univariate regression? It allows us to disentagle two types of mistakes:</p>
<ul>
<li>Spurious correlation between the predictor and independent variable.</li>
<li>A masking relationship between two explanatory variables.</li>
</ul>
<p>It also started to introduce DAGs and how they are an incredible tool for thinking before fitting. Specially, it managed to convince me the frequent strategy of tossing everything into a multiple regression and hoping for the ebst is a recipe for disaster.</p>
<div id="problems-chapter-5" class="section level2">
<h2>Problems Chapter 5</h2>
<div id="medium" class="section level3">
<h3>Medium</h3>
<blockquote>
<p>Invent your own example of a spurious correlation.</p>
</blockquote>
<pre class="r"><code>x_real &lt;- rnorm(1000)
# spurious is correlated with real
x_spur &lt;- rnorm(1000, x_real)
# outcome variable is only correlated with x_real
y &lt;- rnorm(1000, x_real)
data &lt;- data.frame(y, x_real, x_spur)</code></pre>
<p>Thus, when we analyze the relationship between <code>x_spur</code> and <code>y</code>, it may seem as if there is a relationship.</p>
<pre class="r"><code># fit the model
model_spurious &lt;- quap(
  alist(
    y ~ dnorm(mu, sigma),
    mu &lt;- a + b* x_spur,
    a ~ dnorm(0, 1),
    b ~ dnorm(0, 1),
    sigma ~ dunif(0, 2)
  ),
  data = data
)

# sample from posterior
samples_spurious &lt;- extract.samples(model_spurious)
# get samples for slope
coefficient_spurious &lt;- samples_spurious$b

precis(model_spurious)</code></pre>
<pre><code>##              mean         sd        5.5%     94.5%
## a     -0.01397705 0.03926831 -0.07673539 0.0487813
## b      0.48773043 0.02780489  0.44329284 0.5321680
## sigma  1.24242979 0.02778322  1.19802684 1.2868328</code></pre>
<p>Whereas when we fit a multiple regression with both coefficients, the relationship should dissapear:</p>
<pre class="r"><code># fit the model
model_with_real &lt;- quap(
  alist(
    y ~ dnorm(mu, sigma),
    mu &lt;- a + b* x_spur + c* x_real ,
    a ~ dnorm(0, 1),
    b ~ dnorm(0, 1),
    c ~ dnorm(0, 1),
    sigma ~ dunif(0, 2)
  ),
  data = data
)

# sample from posterior
samples_with_real &lt;- extract.samples(model_with_real)

# get samples for slope
coefficient_with_real &lt;- samples_with_real$b

precis(model_with_real)</code></pre>
<pre><code>##               mean         sd        5.5%      94.5%
## a     -0.003852203 0.03252227 -0.05582908 0.04812467
## b     -0.017186891 0.03297004 -0.06987938 0.03550560
## c      0.994250135 0.04646359  0.91999235 1.06850792
## sigma  1.028634063 0.02299992  0.99187575 1.06539238</code></pre>
<p>To make the comparison more obvious, let’s plot a <code>ggridge</code> with the samples from the different models.</p>
<pre class="r"><code>data.frame(controlling_by_real = coefficient_with_real,
           not_controlling = coefficient_spurious,
           sample = seq(1, 10000)) %&gt;% 
  pivot_longer(-sample) %&gt;% 
  ggplot(aes(x = value, fill = name)) +
    geom_histogram(color = &quot;black&quot;, alpha = 0.7,
                   binwidth = 0.01) +
    hrbrthemes::theme_ipsum_rc(grid = &quot;X&quot;) +
    theme(legend.position = &quot;bottom&quot;) +
    scale_fill_viridis_d() +
    labs(fill = &quot;&quot;,
         title = &quot;Multiple regression identifies spurious correlation&quot;,
         subtitle = &quot;Controlling and not controlling for real relationship&quot;,
         x = &quot;Slope&#39;s value&quot;,
         caption = &quot;Samples from the posterior for 2 different models. &quot;)</code></pre>
<p><img src="/post/2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<blockquote>
<p>Invent your own example of a masked relationship</p>
</blockquote>
<p>First, let’s simulate the data such that:</p>
<ul>
<li>The outcome is correlated with both variables, but in opposite directions.</li>
<li>Both predictors are correlated.</li>
</ul>
<pre class="r"><code>set.seed(42)
x_one &lt;- rnorm(1000)
# relation between explanatory variables
x_two &lt;- rnorm(1000, x_one)
# outcome is related to both
# but in opposite directions
y &lt;- rnorm(1000, x_one - x_two)
data &lt;- data.frame(y, x_one, x_two)</code></pre>
<p>Now, let’s fit two univariate models.</p>
<pre class="r"><code># fit the model that masks x_one
model_mask_one &lt;- quap(
  alist(
    y ~ dnorm(mu, sigma),
    mu &lt;- a + one* x_one,
    a ~ dnorm(0, 1),
    one ~ dnorm(0, 1),
    sigma ~ dunif(0, 2)
  ),
  data = data
)
# fit the model that masks x_two
model_mask_two &lt;- quap(
  alist(
    y ~ dnorm(mu, sigma),
    mu &lt;- a + two* x_two,
    a ~ dnorm(0, 1),
    two ~ dnorm(0, 1),
    sigma ~ dunif(0, 2)
  ),
  data = data
)</code></pre>
<p>Then, we can fit the multivariate model:</p>
<pre class="r"><code>model_unmasking &lt;- quap(
  alist(
    y ~ dnorm(mu, sigma),
    mu &lt;- a + one* x_one + two*x_two,
    a ~ dnorm(0, 1),
    one ~ dnorm(0, 1),
    two ~ dnorm(0, 1),
    sigma ~ dunif(0, 2)
  ),
  data = data
)</code></pre>
<p>Let’s visualize how our estimates have changed once we have included both variables:</p>
<pre class="r"><code>one_masked &lt;- extract.samples(model_mask_one)$one
one_unmasked &lt;- extract.samples(model_unmasking)$one

data.frame(sample = 1:10000,
           one_masked, 
           one_unmasked) %&gt;% 
  pivot_longer(-sample) %&gt;% 
  ggplot(aes(x = value, fill = name)) +
    geom_histogram(color = &quot;black&quot;, alpha = 0.7,
                   binwidth = 0.01) +
    hrbrthemes::theme_ipsum_rc(grid = &quot;X&quot;) +
    theme(legend.position = &quot;bottom&quot;) +
    scale_fill_viridis_d() +
  labs(fill = &quot;&quot;,
       title = &quot;Multiple regression unmasks true relationship&quot;,
       caption = &quot;Samples from the posterior of different models.&quot;,
       x = &quot;Slope&quot;)</code></pre>
<p><img src="/post/2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Whereas the univariate regression, due to the unobserved variable’s effect, cannot reliably estimate the coefficient, multiple regression does the unmasking. Once we control for the correlation between the explanatory variables, the positive relationship between the first and the outcome variable is revealed.</p>
<p>For the other variable, that is negatively correlated with the outcome, we expect the opposite effect:</p>
<pre class="r"><code>two_masked &lt;- extract.samples(model_mask_two)$two
two_unmasked &lt;- extract.samples(model_unmasking)$two

data.frame(sample = 1:10000,
           two_masked, 
           two_unmasked) %&gt;% 
  pivot_longer(-sample) %&gt;% 
  ggplot(aes(x = value, fill = name)) +
    geom_histogram(color = &quot;black&quot;, alpha = 0.7,
                   binwidth = 0.01) +
    hrbrthemes::theme_ipsum_rc(grid = &quot;X&quot;) +
    theme(legend.position = &quot;bottom&quot;) +
    scale_fill_viridis_d() +
  labs(fill = &quot;&quot;,
       title = &quot;Multiple regression unmasks true relationship&quot;,
       caption = &quot;Samples from the posterior of different models.&quot;,
       x = &quot;Slope&quot;)</code></pre>
<p><img src="/post/2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Just as expected, multiple regression helps us unmask the true relationship. Before, due to the correlation between one and two, we were underestimating the magnitude of the relationship. Once we include one in the regression, we can estimate the true effect.</p>
</div>
</div>
</div>
<div id="homework-week-3" class="section level1">
<h1>Homework Week 3</h1>
<p>The foxes data. Let’s start working with the proposed DAG:</p>
<pre class="r"><code>data(&quot;foxes&quot;)

foxes %&gt;% 
  mutate(avgfood = (avgfood - mean(avgfood))/ sd(avgfood),
         groupsize = (groupsize - mean(groupsize)) / sd(groupsize),
         area = (area - mean(area)) / sd(area),
         weight = (weight - mean(weight)) / sd(weight)) -&gt; foxes_scaled

dag_foxes &lt;- dagitty(&quot;dag {
                     area -&gt; avgfood
                     avgfood -&gt; groupsize
                     avgfood -&gt; weight
                     groupsize -&gt; weight
}&quot;)

drawdag(dag_foxes)</code></pre>
<p><img src="/post/2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<blockquote>
<p>Use a model to infer the total causal influence of area on weight.</p>
</blockquote>
<p>Given the DAG, we only need to <em>run an unviariate regression to infer the causal effect of area on weight</em>. Why? Because that there are only two connections from area to weight and none of them are backdoor connections. Thus, were we to condition on avgfood, we would “block” the pipe that leads towards weight, thus nullyfing the effect that area has on weight. Likewise with groupisze. That is, we would be incurring on <strong>post-treatment bias</strong>.</p>
<p>We could confirm that we do not need to control for any other variable with the <code>dagitty</code> package.</p>
<pre class="r"><code>adjustmentSets(dag_foxes, exposure = &quot;area&quot;, outcome = &quot;weight&quot;)</code></pre>
<pre><code>##  {}</code></pre>
<p>Once we have thought over our model, let’s posit it.</p>
<p><span class="math display">\[ weight_i \sim Normal(\mu_i, \sigma)\]</span>
<span class="math display">\[\mu_i = \alpha + area_i \beta_{area} \]</span></p>
<p><span class="math display">\[ alpha \sim Normal(0, 0.2) \]</span>
<span class="math display">\[ \beta_{area} \sim Normal(0, 0.5) \]</span>
<span class="math display">\[ \sigma \sim Uniform(0, 1) \]</span></p>
<pre class="r"><code>model_area_weight &lt;- quap(
  alist(
    weight ~ dnorm(mu, sigma),
    mu &lt;- alpha + beta_area * area,
    alpha ~ dnorm(0, 0.2),
    beta_area ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = foxes_scaled
)</code></pre>
<p>Let’s do some prior predictive checks before we continue:</p>
<pre class="r"><code>prior_area_weight &lt;- extract.prior(model_area_weight, n = 100)

prior_data &lt;- data.frame(sim = 1:100, intercept = prior_area_weight$alpha, slope = prior_area_weight$beta_area)

ggplot() +
  scale_y_continuous(limits=c(-2,2)) +
  scale_x_continuous(limits = c(-2, 2)) +
  geom_abline(data = prior_data, aes(slope = slope, intercept = intercept, group = sim),
              alpha = 0.2) +
   hrbrthemes::theme_ipsum_rc() +
  labs(x = &quot;z-score area&quot;,
       y = &quot;z-score weight&quot;,
       title = &quot;Prior predictive check&quot;)</code></pre>
<p><img src="/post/2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Now, let’s analyze our posterior</p>
<pre class="r"><code>precis(model_area_weight)</code></pre>
<pre><code>##                    mean         sd       5.5%     94.5%
## alpha     -7.202898e-06 0.08360131 -0.1336182 0.1336038
## beta_area  1.883496e-02 0.09088645 -0.1264191 0.1640891
## sigma      9.911604e-01 0.06464929  0.8878383 1.0944824</code></pre>
<p>According to our DAG and our statistical fitting, there is no causal relationship between area and weight.</p>
<pre class="r"><code>posterior_area_weight_slope &lt;- link(model_area_weight, data = data.frame(area = seq(-2.5, 2.5, length.out = 100)))

mu &lt;- apply(posterior_area_weight_slope, 2, mean)
posterior_area_weight &lt;- sim(model_area_weight, data = data.frame(area = seq(-2.5, 2.5, length.out = 100)))
interval &lt;- apply(posterior_area_weight, 2, PI, prob = 0.75)
left_interval &lt;- interval[1,]
right_interval &lt;- interval[2,]

data.frame(mu, interval, left_interval, right_interval,
           area = seq(-2.5, 2.5, length.out = 100)) %&gt;% 
  ggplot(aes(area, mu)) +
  geom_line() +
  geom_ribbon(aes(ymin = left_interval,
                  ymax = right_interval),
              alpha = 0.1) +
  geom_point(data = foxes_scaled,
             mapping = aes(x = area, y = weight),
             alpha = 0.8, color = &quot;dodgerblue4&quot;) +
  hrbrthemes::theme_ipsum_rc() +
  labs(x = &quot;area&quot;,
       y = &quot;weight&quot;,
       title = &quot;Posterior predictive checking&quot;)</code></pre>
<p><img src="/post/2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Accordingly, our fit to the data is terrible. Thus, we conclude that increasing the area available to each fox won’t make them heavier.</p>
<blockquote>
<p>Now infer the causal impact of adding food to a territory. Would this make foxes heavier? Which covariate do you need to adjust for to estimate the total causal influence of food?</p>
</blockquote>
<p>Given our DAG, there are two paths from avgfood to weight. However, none of them are a backdoor. Thus, we do not need to adjust for any other variable to identify the causal effect of avgfood on weight.</p>
<p>We can confirm this using <code>dagitty</code>:</p>
<pre class="r"><code>adjustmentSets(dag_foxes, exposure = &quot;avgfood&quot;, outcome = &quot;weight&quot;)</code></pre>
<pre><code>##  {}</code></pre>
<p>Once we have thought over our model, let’s posit it.</p>
<p><span class="math display">\[ weight_i \sim Normal(\mu_i, \sigma)\]</span>
<span class="math display">\[ \mu_i = \alpha + avgfood_i \beta_{avgfood} \]</span></p>
<p><span class="math display">\[ alpha \sim Normal(0, 0.2) \]</span>
<span class="math display">\[ \beta_{avgfood} \sim Normal(0, 0.5) \]</span>
<span class="math display">\[ \sigma \sim Uniform(0, 1) \]</span>
Let’s fit our model</p>
<pre class="r"><code>model_food_weight &lt;- quap(
  alist(weight ~ dnorm(mu, sigma),
        mu &lt;- alpha + avgfood * beta_avgfood,
        alpha ~ dnorm(0, 0.1),
        beta_avgfood ~ dnorm(0, 0.5),
        sigma ~ dexp(1)),
  data = foxes_scaled
)
precis(model_food_weight)</code></pre>
<pre><code>##                       mean         sd       5.5%     94.5%
## alpha        -3.116427e-06 0.06771658 -0.1082273 0.1082211
## beta_avgfood -2.421115e-02 0.09088693 -0.1694660 0.1210437
## sigma         9.911655e-01 0.06466209  0.8878230 1.0945081</code></pre>
<p>Just as before, given our DAG, our statistical analysis and our data, there is no causal effect of avgfood on weight. Thus, increasing the avgfood won’t lead to heavier foxes.</p>
<p>Let’s plot our predictions</p>
<pre class="r"><code>food_data &lt;- data.frame(avgfood = seq(min(foxes_scaled$avgfood),
                                      max(foxes_scaled$avgfood),
                                      length.out = 1000))
sim_mu &lt;- link(model_food_weight, data = food_data)

mu &lt;- apply(sim_mu, 2, mean)

sim_interval &lt;- sim(model_food_weight, data = food_data)

interval &lt;- apply(sim_interval, 2, PI, prob = 0.75)

left_interval &lt;- interval[1,]
right_interval &lt;- interval[2,]

cbind(food_data, data.frame(mu),
      left_interval, right_interval) %&gt;% 
  ggplot(aes(avgfood, mu)) +
  geom_line() +
  geom_ribbon(aes(ymin = left_interval,
                  ymax = right_interval), 
              alpha = 0.1) +
  geom_point(data = foxes_scaled,
             aes(x = avgfood, y = weight),
             color = &quot;dodgerblue4&quot;) +
  hrbrthemes::theme_ipsum_rc() +
  labs(x = &quot;avgfood&quot;,
       y = &quot;weight&quot;,
       title = &quot;Posterior predictive checking&quot;) </code></pre>
<p><img src="/post/2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Accordingly, our fit is terrible.</p>
<blockquote>
<p>Now infer the causal impact of group size. Which covariates do you need to adjust for? Looking at the posterior distribution of the resulting model, what do you think explains these data? That is, can you explain the estimates for all three problems? How do they go together?</p>
</blockquote>
<p>Given our DAG, there are two paths from groupsize to weight. And of them has a backdoor through which our estimates will be confounded. That is, given that in our bayesian network the information flows freely, if we run an univariate regression, the coefficient for groupsize will pick up the effect of avgfood on weight too. Therefore, we need to control for avgfood to close this backdoor. Let’s confirm this with <code>dagitty</code></p>
<pre class="r"><code>adjustmentSets(dag_foxes, exposure = &quot;groupsize&quot;, outcome = &quot;weight&quot;)</code></pre>
<pre><code>##  { avgfood }</code></pre>
<p>Let’s formulate our model:</p>
<p><span class="math display">\[ weight_i \sim Normal(\mu_i, \sigma)\]</span>
<span class="math display">\[ \mu_i = \alpha + avgfood_i \beta_{avgfood} + groupsize_i \beta_{groupsize} \]</span></p>
<p><span class="math display">\[ alpha \sim Normal(0, 0.2) \]</span>
<span class="math display">\[ \beta_{avgfood} \sim Normal(0, 0.5) \]</span>
<span class="math display">\[ \beta_{groupsize} \sim Normal(0, 0.5) \]</span></p>
<p><span class="math display">\[ \sigma \sim Uniform(0, 1) \]</span></p>
<pre class="r"><code>model_gropusize_weight &lt;- quap(
  alist(
    weight ~ dnorm(mu, sigma),
    mu &lt;- alpha + beta_avgfood * avgfood + beta_groupsize * groupsize,
    alpha ~ dnorm(0, 0.1),
    beta_avgfood ~ dnorm(0, 0.5),
    beta_groupsize ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = foxes_scaled
)
precis(model_gropusize_weight)</code></pre>
<pre><code>##                         mean         sd       5.5%      94.5%
## alpha           1.503414e-06 0.06583598 -0.1052171  0.1052201
## beta_avgfood    4.772644e-01 0.17912227  0.1909924  0.7635364
## beta_groupsize -5.735414e-01 0.17914071 -0.8598429 -0.2872400
## sigma           9.420381e-01 0.06175160  0.8433471  1.0407291</code></pre>
<p>Given our DAG, statistical analysis and data, we conclude that:</p>
<ul>
<li>Conditioning on groupsize, the average food available increases the weight of the foxes</li>
<li>The larger the groupsize, adjusting for avgfood, the lower the weight of the foxes.</li>
<li>Avgfood and area have two causal channels through which it influences the foxes’ weight. It increases the food available to them, which helps them get heavier. But it also increases the groupsize. Thus, they get thinner. These effects in opposite directions end up cancelling the overall causal effect of area or avgdfood on weight.</li>
</ul>
<p>**If one were to intervene to increase the foxes’ weight, one would need to increase the avgfood available to them while maintaining the groupsize constant.</p>
</div>

    </div>
  

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


  
  </article>

</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/python.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

