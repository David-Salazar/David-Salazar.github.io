{
  "hash": "8dc441267073f9d347bd3331ef3a6ae4",
  "result": {
    "markdown": "---\ntitle: Gini Index under Fat-Tails\nauthor: ''\ndate: '2020-06-26'\nslug: gini-index-under-fat-tails\ncategories: []\ntags: []\naliases: \n  - ../../2020/06/26/gini-index-under-fat-tails/\n---\n\n\n\n\nI have recently been exploring Nassim Taleb's latest [technical book: Statistical Consequences of Fat Tails](https://www.researchers.one/media/documents/260-m-Technical%20Incerto%20Vol%201.pdf). In this blogpost, I'll follow Taleb's exposition of the Gini Index under fat-tails in Chapter 13 of his book. \n\nIntuitively, if we use the \"empirical distribution\" to estimate the Gini Index, under fat-tails, we underestimate the tail of the distribution and thus underestimate the Gini index. This is [yet another example](https://david-salazar.github.io/2020/06/11/how-to-not-get-fooled-by-the-empirical-distribution/) of how we *fool* ourselves when we are using the \"empirical\" distribution. Instead, Taleb recommends first understanding the tail behavior of the \"Gini Index\" [by estimating the tail index of the distribution with Maxmimum Likelihood](https://david-salazar.github.io/2020/06/11/how-to-not-get-fooled-by-the-empirical-distribution/) and *then* using the **functional form** of the maximum likelihood estimator for the Gini Index. \n\n## What is the Gini Index?\n\nThe Gini index is a measure of concentration commonly used in the income and wealth inequalities discussions. The stochastic representation of the Gini $g$ is:\n\n$$\ng=\\frac{1}{2} \\frac{\\mathbb{E}\\left(\\left|X^{\\prime}-X^{\\prime \\prime}\\right|\\right)}{\\mu} \\in[0,1]\n$$\n\nwhere \\( X^{\\prime} \\) and \\( X^{\\prime \\prime} \\) are i.i.d. copies of a random variable \\( X \\) with c.d.f. \\( F(x) \\in[c, \\infty) \\) \\( c>0, \\) and with finite mean \\( \\mathbb{E}(X)=\\mu . \\) \n\nIntuitively, then:\n\n> The Gini Index of a random variable X is the mean expected deviation between any two independent realizations of X, scaled twice by the mean\n\n## Non-Parametric estimator\n\nUsing the empirical distribution, then, we can estimate the Gini Index $g$:\n\n$$\nG^{N P}\\left(X_{n}\\right)=\\frac{\\sum_{1 \\leq i<j \\leq n}\\left|X_{i}-X_{j}\\right|}{(n-1) \\sum_{i=1}^{n} X_{i}}\n$$\n\nWe will examine the behavior of this estimator both under thin-tailed distributions and under fat-tailed distributions. \n\n### Finite variance, asymptotic normality for the non parametric estimator\n\nUnder the hypothesis of finite variance for the data-generating process of $X$, the estimator is asymptotically normal. We can check this condition with Monte-Carlo simulations. I'll perform $10^4$ Monte-Carlo experiments: in each of them, I'll generate a 1000 samples from a lognormal with underlying standard deviation of 0.2, which behaves like a Gaussian. Then, I'll calculate the Gini estimate using the non-parametric estimator. \n\nGiven this lognormal, the \"true\" Gini is thus:\n\n$$\nG=2 \\Phi\\left(\\frac{\\sigma}{\\sqrt{2}}\\right)-1 = 0.11246\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrossing(experiment = 1:10^4,\n         sample_size = 1000) %>% \n  mutate(data = map(sample_size, ~ rlnorm(., sdlog = 0.2)),\n         gini = map_dbl(data, ~ gini(.))) -> gini_lognormal\n\ngini_lognormal %>% \n  ggplot(aes(gini)) +\n  geom_histogram(binwidth = 0.0005, color = \"black\", fill = \"dodgerblue4\", alpha = 0.7) +\n  geom_vline(aes(xintercept = 0.11246), color = \"red\", linetype = 2) +\n  labs(title = \"Non parametric Gini estimator\",\n       subtitle = \"Under finite variance, non parametric estimator is asymptotically normal\",\n       caption = \"Data-generating process is lognormal with underlying sd = 0.2, which behaves like a Gaussian\")\n```\n\n::: {.cell-output-display}\n![](2020-06-26-gini-index-under-fat-tails_files/figure-html/lognormal-1.png){width=768}\n:::\n:::\n\n\n### Fat-tails: Non-parametric estimator\n\nHowever, when the data-generating process of $X$ is in [the MDA of the Fr√©chet](https://david-salazar.github.io/2020/06/10/fisher-tippet-th-a-clt-for-the-sample-maxima/) (i.e., it's a fat-tailed variable), the non-parametric estimator of the Gini Index loses its properties of normality. Indeed, the limiting distribution of the non-parametric index becomes a skewed-to-the-right $\\alpha$-stable law. Thus, the non-parametric estimate underestimates the true Gini Index.\n\nThis can be checked with Monte-Carlo simulations. I'll perform $10^4$ Monte-Carlo experiments: in each of them, I'll generate a 1000 samples from a Pareto with $\\alpha = 1.16$. Then, I'll calculate the Gini estimate using the non-parametric estimator. \n\nGiven this Pareto, the \"true\" Gini is thus:\n\n$$\ng = \\dfrac{1}{2\\alpha -1} = 0.7575758\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrpareto <- function(n) {\n    alpha <- 1.16\n   (1/runif(n)^(1/alpha)) # inverse transform sampling\n}\n\ncrossing(experiment = 1:10^4,\n         sample_size = 1000) %>% \n  mutate(data = map(sample_size, ~ rpareto(.)),\n         gini = map_dbl(data, ~ gini(.))) -> gini_pareto\n\ngini_pareto %>% \n  ggplot(aes(gini)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"dodgerblue4\", alpha = 0.7) +\n  geom_vline(aes(xintercept = 0.7575758), color = \"red\", linetype = 2) +\n  annotate(\"text\", x = 0.78, y = 400, label = \"True gini\", color = \"red\", \n           family = theme_get()$text[[\"family\"]]) +\n  labs(title = \"Non parametric Gini estimator\",\n       subtitle = \"Under fat-tails, non parametric estimator is skewed to the right. Thus, downward bias\",\n       caption = \"Data generating process is Pareto with alpha = 1.16\")\n```\n\n::: {.cell-output-display}\n![](2020-06-26-gini-index-under-fat-tails_files/figure-html/pareto-1.png){width=768}\n:::\n:::\n\n\nTherefore, under fat-tails, **the non-parametric Gini estimator will approach its true value more slowly, and from below.** \n\n## The Maximum Likelihood alternative\n\nA better alternative when working with fat-tails, it's to first estimate the tail and then derive your quantity of interest. Indeed, one does not need too much data to derive the properties of the tail. With a Pareto, for example, the Maximum Likelihood estimator for the tail exponent follows an inverse Gamma distribution that rapidly converges to a Gaussian tightly *around* the true $\\alpha$. Therefore, one can reliably estimate the tail exponent of the Pareto and thus understand the properties of the distribution with relatively few data.\n\nThe ML estimator for the tail exponent of a Pareto is thus:\n\n$$\n\\widehat \\alpha = \\frac{n}{\\sum _i  \\ln (x_i) }\n$$\nThen, we can derive our Maximum Likelihood estimate for the Gini Index:\n\n$$\ng = \\dfrac{1}{2\\widehat \\alpha -1}\n$$\n\nIndeed, Taleb shows that this estimator for the Gini Index is **not just asymptotically normal, but also asymptotically efficient**. We can test for these using our Monte-Carlo simulations. For each of our simulated datasets, we can derive our Maximum Likelihood estimate and then derive our Maximum Likelihood estimate for the Gini Index.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_alpha_ml <- function(observations) {\n  alpha <- length(observations)/sum(log(observations))\n  if (alpha < 1) {\n    alpha <- 1.0005 \n  }\n  alpha\n}\n\ngini_pareto %>% \n  mutate(alpha_ml = map_dbl(data, ~ estimate_alpha_ml(.)),\n         gini_ml = 1/(2*alpha_ml - 1)) -> gini_pareto\n\ngini_pareto %>%\n  rename(nonparametric = gini,\n         maximum_likelihood = gini_ml) %>% \n  pivot_longer(c(nonparametric, maximum_likelihood), names_to = \"estimator\", values_to = \"gini\") %>% \n  ggplot(aes(gini, fill = estimator)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", alpha = 0.7,\n                 position = \"identity\") +\n  geom_vline(aes(xintercept = 0.7575758), color = \"red\", linetype = 2) +\n  annotate(\"text\", x = 0.78, y = 1000, label = \"True gini\", color = \"red\", \n           family = theme_get()$text[[\"family\"]]) +\n  scale_fill_viridis_d() +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"Comparison of Gini estimators: Non-parametric vs Maximum Likelihood\",\n       subtitle = \"Under fat-tails, unlike the non parametric estimator, Max Likelihood estimate is still asymptotically normal\",\n       caption = \"Data generating process is a Pareto with alpha = 1.16\")\n```\n\n::: {.cell-output-display}\n![](2020-06-26-gini-index-under-fat-tails_files/figure-html/comparison-1.png){width=960}\n:::\n:::\n\n## Conclusion\n\nWhen the underlying distribution is fat-tailed, which is always in the case of income or wealth, the non-parametric estimator for the Gini index is skewed to the right and thus underestimates the true Gini index. In this case, it is a much statistically sound strategy to first estimate the tail behavior of the distribution with Maximum Likelihood and then estimate the Gini Index with its plug-in estimator. \n",
    "supporting": [
      "2020-06-26-gini-index-under-fat-tails_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}