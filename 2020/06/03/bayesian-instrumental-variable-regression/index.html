<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.58.3" />


<title>Bayesian Instrumental Variable Regression - Dilettanting Data Science</title>
<meta property="og:title" content="Bayesian Instrumental Variable Regression - Dilettanting Data Science">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/turner.jpg"
         width="200"
         height="200"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://www.kaggle.com/davidsalazarv95">Kaggle</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir?lang=en">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">5 min read</span>
    

    <h1 class="article-title">Bayesian Instrumental Variable Regression</h1>

    
    <span class="article-date">2020/06/03</span>
    
    

    <div class="article-content">
      


<p><a href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking</a> is a fabulous course on Bayesian Statistics (and much more). In what follows, I’ll give a succinct presentation of Instrumental Variable Regression in a Bayesian setting using simulated data.</p>
<p>I had already seen the traditional econometrics formulation and yet found Richard’s presentation both illuminating and fun. It’s a testament of his incredible achievement with this book.</p>
<div id="the-problem" class="section level1">
<h1>The problem</h1>
<p>The start of every instrumental variable setting is the following. We want to estimate the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. However, there’s a fork between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>: an unobserved variable <span class="math inline">\(U\)</span> that has an effect on both of them. In DAG form:</p>
<pre class="r"><code>dag_confound &lt;- dagitty::dagitty(&#39;dag{
                        X -&gt; Y
                        X &lt;- U
                        U -&gt; Y
                        }&#39;)
drawdag(dag_confound)</code></pre>
<pre><code>## Loading required package: dagitty</code></pre>
<p><img src="/post/2020-06-03-bayesian-instrumental-variable-regression_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Therefore, there’s a backdoor path from <span class="math inline">\(X\)</span>, through <span class="math inline">\(U\)</span>, toward <span class="math inline">\(Y\)</span> that will bias our estimates. One alternative would be to statistically adjust by <span class="math inline">\(U\)</span>; however, we don’t observe <span class="math inline">\(U\)</span>.</p>
</div>
<div id="creating-a-collider-as-a-solution" class="section level1">
<h1>Creating a collider as a solution</h1>
<p>Colliders are dangerous and scary, as Richard has said a many times. However, they can also be useful. They can create statistical relationships between certain variables that allows us to introduce certain otherwise unavailable statistical information into our models. This is the case with an instrument, <span class="math inline">\(I\)</span>, that is only related to <span class="math inline">\(X\)</span> in this DAG.</p>
<pre class="r"><code>dag_instrument &lt;- dagitty::dagitty(&#39;dag{
                        X -&gt; Y
                        X &lt;- U
                        U -&gt; Y
                        I -&gt; X
                        }&#39;)
drawdag(dag_instrument)</code></pre>
<p><img src="/post/2020-06-03-bayesian-instrumental-variable-regression_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Noticed that we’ve created a collider out of <span class="math inline">\(X\)</span>. Therefore, if we open the collider by statistically adjusting simultaneously by <span class="math inline">\(X\)</span> and <span class="math inline">\(I\)</span>, there will be a statistical relationship (not causal) between <span class="math inline">\(I\)</span> and <span class="math inline">\(U\)</span>. Thus, a collider opens a path that can help us adjust by <span class="math inline">\(U\)</span>. <strong>Our goal, then, is to create a model that simultaneously opens the collider and estimates the effefct of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</strong></p>
<div id="opening-collider-and-estimating-simultaneously" class="section level2">
<h2>Opening collider and estimating simultaneously</h2>
<p>The model then must be simultaneous. It must open the collider <strong>and</strong> regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span>. The solution is thu:</p>
<p><span class="math display">\[ \begin{bmatrix} 
Y_i \\
X_i
\end{bmatrix} \sim MVNormal(\begin{bmatrix} 
\mu_{Y,i} \\
\mu_{X, y}
\end{bmatrix}, S) \]</span></p>
<p><span class="math display">\[ \mu_{Y,i} = \alpha_y + \beta X_i \]</span></p>
<p><span class="math display">\[ \mu_{X, i} = \alpha_x + \gamma I \]</span></p>
<p>We are modelling <span class="math inline">\(X, Y\)</span> simultaneously with a joint error structure represented by <span class="math inline">\(S\)</span>. Notice, then, that at both linear models we should be adjusting by <span class="math inline">\(U\)</span>. Therefore, the errors of our each of our linear regressions, represented by <span class="math inline">\(S\)</span>, will be correlated; this is what a fork does and what creates the original bias in our estimates. <strong>However, we are opening simultaneously the collider on <span class="math inline">\(X\)</span> by adjusting with <span class="math inline">\(I\)</span>. Therefore, statistical information about <span class="math inline">\(U\)</span> is entering into our model in the form of a correlated error structure (represented by <span class="math inline">\(S\)</span>) between the two linear regressions</strong>. This statistical information of <span class="math inline">\(U\)</span> will then allow us to causally estimate the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</p>
<p>Note that, given a DAG, we can algorithmically compute if there is an instrument that we can use.</p>
<pre class="r"><code>instrumentalVariables(dag_instrument, exposure = &#39;X&#39;, outcome = &#39;Y&#39;)</code></pre>
<pre><code>##  I</code></pre>
</div>
</div>
<div id="simulated-data" class="section level1">
<h1>Simulated data</h1>
<p>In this case we will simulate data where the true effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is null.</p>
<pre class="r"><code>N &lt;- 1000
U &lt;- rnorm(N)
I &lt;- rnorm(N)
X &lt;- rnorm(N, U + I)
Y &lt;- rnorm(N, U)

data_sim &lt;- list(
  Y = standardize(Y),
  X = standardize(X),
  I = standardize(I)
)</code></pre>
<div id="naive-regression" class="section level2">
<h2>Naive regression</h2>
<p>A naive regression won’t account by the confounding effect of <span class="math inline">\(U\)</span>:</p>
<pre class="r"><code>model_naive &lt;- ulam(
  alist(
    Y ~ normal(mu, sigma),
    mu &lt;- alpha + beta*X,
    alpha ~ normal(0, 1),
    beta ~ normal(0, 1),
    sigma ~ exponential(1)
  ),
  chains = 4, cores = 4,
  data = data_sim
)
precis(model_naive)</code></pre>
<pre><code>##               mean         sd        5.5%      94.5%    n_eff     Rhat4
## alpha 7.686419e-05 0.02878504 -0.04570195 0.04442925 2171.258 0.9991456
## beta  4.429004e-01 0.02837657  0.39769608 0.48634324 1840.436 0.9994856
## sigma 8.968721e-01 0.01965704  0.86522906 0.92932230 1911.151 1.0003967</code></pre>
<p>Indeed, we have an estimate with a 87% compatibility interval of (0.40, 0.49) when we know that the true effect is zero. We can plot the expected relationship:</p>
<pre class="r"><code>data.frame(data_sim) %&gt;% 
  data_grid(X = seq_range(X, 50)) %&gt;% 
  add_predicted_draws(model_naive) %&gt;% 
  ggplot(aes(X, Y)) +
  stat_lineribbon(aes(y = .prediction), alpha = 1/4, fill = &quot;dodgerblue4&quot;) +
  geom_point(data = data.frame(data_sim), alpha = 0.4) +
  scale_fill_brewer(palette = &quot;Greys&quot;) +
  labs(title = &quot;Naive model finds a relationship&quot;,
       subtitle = &quot;Confounding effect is unaccounted for. True effect of X on Y is null&quot;)</code></pre>
<pre><code>## Warning: `combine()` is deprecated as of dplyr 1.0.0.
## Please use `vctrs::vec_c()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<p><img src="/post/2020-06-03-bayesian-instrumental-variable-regression_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="instrumental-variable-regression" class="section level2">
<h2>Instrumental Variable Regression</h2>
<p>Given our DAG and our data, we can do better. We can fit a multivariate model that, by virtue of opening a collider on <span class="math inline">\(X\)</span>, will allows us to statistical adjust by the confounding factor <span class="math inline">\(U\)</span>.</p>
<pre class="r"><code>model_instrumental &lt;- ulam(
  alist(
    c(Y, X) ~ multi_normal(c(muY, muX), Rho, Sigma),
    muY &lt;- alphaY + beta*X,
    muX &lt;- alphaX + gamma*I,
    c(alphaY, alphaX) ~ normal(0, 0.2),
    c(beta, gamma) ~ normal(0, 0.5),
    Rho ~ lkj_corr(2),
    Sigma ~ exponential(1)
  ),
  data = data_sim, chains = 4, cores = 4
)</code></pre>
<pre><code>## Warning: The largest R-hat is NA, indicating chains have not mixed.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#r-hat</code></pre>
<pre><code>## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#bulk-ess</code></pre>
<pre><code>## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#tail-ess</code></pre>
<pre class="r"><code>precis(model_instrumental)</code></pre>
<pre><code>## 6 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##                 mean         sd        5.5%      94.5%     n_eff     Rhat4
## alphaX -2.163636e-04 0.02565338 -0.04077942 0.04153302 1268.8566 1.0049438
## alphaY -7.310246e-05 0.03078223 -0.04852639 0.04791494 1275.9310 1.0030601
## gamma   5.687327e-01 0.02630331  0.52649872 0.61093559 1277.6167 0.9996663
## beta    6.006303e-02 0.05424077 -0.02987023 0.13946288  935.7473 1.0042827</code></pre>
<p>Whereas before we posited a positive and relatively large effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, now we correctly infer that the true effect is null. Because <span class="math inline">\(\beta\)</span> has lots of its mass around zero.</p>
<pre class="r"><code>model_instrumental %&gt;% 
  spread_draws(beta) %&gt;% 
  ggplot(aes(beta)) +
  geom_histogram(color = &quot;black&quot;, fill = &quot;dodgerblue4&quot;, alpha = 4/10,
                 binwidth = 0.05) +
  geom_vline(aes(xintercept = 0), linetype = 2, color = &quot;red&quot;) +
  labs(title = &quot;Instrumental Variable Regression&quot;,
       subtitle = &quot;Accounting for the confounding through IV, finds true null effect&quot;)</code></pre>
<p><img src="/post/2020-06-03-bayesian-instrumental-variable-regression_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
</div>

    </div>
  

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


  
  </article>

</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/python.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

