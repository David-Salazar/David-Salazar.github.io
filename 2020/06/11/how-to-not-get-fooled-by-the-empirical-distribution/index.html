<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.91.2" />


<title>How to not get fooled by the &#34;Empirical Distribution&#34; - David Salazar&#39;s blog</title>
<meta property="og:title" content="How to not get fooled by the &#34;Empirical Distribution&#34; - David Salazar&#39;s blog">


  <link href='https://david-salazar.github.io/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/booglee.jpeg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">9 min read</span>
    

    <h1 class="article-title">How to not get fooled by the &#34;Empirical Distribution&#34;</h1>

    
    <span class="article-date">2020-06-11</span>
    

    <div class="article-content">
      


<p>With fat-tailed random variables, as Nassim Taleb says, <a href="https://twitter.com/nntaleb/status/1245399854710509574/photo/1">the tail wags the dogs</a>. That is, “the tails (the rare events) play a disproportionately large role in determining the properties”. Following the presentation given by Taleb in his latest <a href="https://www.researchers.one/media/documents/260-m-Technical%20Incerto%20Vol%201.pdf">technical book: Statistical Consequences of Fat Tails</a>, I’ll show:</p>
<ul>
<li>Why using the empirical distribution for estimating the moments of a fat-tailed random variable is a terrible idea.</li>
<li>A less “unreliable” alternative to estimating the moments.</li>
</ul>
<div id="why-does-the-empirical-distribution-fool-us" class="section level2">
<h2>Why does the empirical distribution fool us?</h2>
<p>The tails play a disproportionate role in defining the theoretical moments for fat-tailed distributions. However, if we are working with the non-parametric <em>“empirical distribution”</em>, we are effectively <strong>cutting the tail at our sample maximum</strong>. The rest of the tail, the possible values larger than our sample maximum, <strong>are taken out of the equation when estimating any moment through the “empirical” distribution</strong>. This <em>hidden contribution</em> to the theoretical mean that does not appear in the sample, however, is <strong>precisely</strong> the most important to define the theoretical moment that we are trying to estimate. Thus, our estimates with the “empirical” distribution will be terrible.</p>
<p>Instead of using the “empirical distribution”, what one should attempt is an <em>intelligent</em> extrapolation to take into consideration <a href="2020-06-10-fisher-tippet-th-a-clt-for-the-sample-maxima.html">future maxima</a> and their influence in our estimate. This can be done, in the case of a Pareto distribution, by estimating the <a href="2020-05-19-understanding-the-tail-exponent.html">tail exponent <span class="math inline">\(\alpha\)</span></a> and then <strong>plug-in</strong> our estimated alpha to estimate the mean.</p>
</div>
<div id="visualizing-the-invisible-tail" class="section level2">
<h2>Visualizing the invisible tail</h2>
<p>The tails contribute the most for any theoretical moment of any fat-tailed variable. However, when we work with the “empirical” distribution, we are ignoring the contribution of the tail beyond our sample maximum. Graphically, Taleb shows it thus:</p>
<div class="figure">
<img src="/images/hiddentail.PNG" alt="" />
<p class="caption">Hidden contribution to the p-moment</p>
</div>
<p>Taleb also shows how this ignorance of the tail is most worrisome the fatter the distribution:</p>
<div class="figure">
<img src="/images/worrysomethefatter.PNG" alt="" />
<p class="caption">The fatter, the worse is the mistake of the empirical</p>
</div>
</div>
<div id="estimating-the-tail-first-then-the-mean" class="section level2">
<h2>Estimating the tail first, then the mean</h2>
<p><a href="2020-05-19-understanding-the-tail-exponent.html">By definition</a> the tail exponent tells us information about the tail. Specifically, about the survival’s function rate of decay. Therefore:</p>
<blockquote>
<p>The tail exponent <span class="math inline">\(\alpha\)</span> captures, by extrapolation, the low probability deviation not seen in the data, but that plays a disproportionately large share in determining the mean.</p>
</blockquote>
<p>Thus, once one has taken into account the hidden tail’s influence with the estimated <span class="math inline">\(\widehat \alpha\)</span>, we can produce a less unreliable estimate of the mean (or other higher moments). However, care must be taken: <strong>with a Pareto, the mean is hardly what matters</strong>. What is really important here is the <strong>idea of first figuring out the properties of the fat-tailed distribution</strong> and <em>then</em> trying to estimate things.</p>
</div>
<div id="maximum-likelihood" class="section level2">
<h2>Maximum Likelihood</h2>
<p>For a Pareto with known minimum observation 1, things are pretty straightforward. As it is often the case in statistics, the answer is maximum likelihood. Just posit a likelihood for your data, take the log, differentiate w.r.t <span class="math inline">\(\alpha\)</span> and you have your estimate:</p>
<p><span class="math display">\[ L(\alpha) = \prod_{i=1}^n \alpha \frac {1} {x_i^{\alpha+1}} = \alpha^n \prod_{i=1}^n \frac {1}{x_i^{\alpha+1}}. \]</span></p>
<p><span class="math display">\[ \ell(\alpha) = n \ln \alpha  - (\alpha + 1) \sum_{i=1} ^n \ln x_i. \]</span>
<span class="math display">\[ \widehat \alpha = \frac{n}{\sum _i  \ln (x_i) }\]</span>
Luckily, this maximum likelihood estimate for <span class="math inline">\(\alpha\)</span> works reasonably well with relatively small amounts of data. Why? Because <span class="math inline">\(\widehat \alpha\)</span> follows an Inverse gamma distribution with shape parameter equal to <span class="math inline">\(n\)</span> and scale parameter equal to <span class="math inline">\(\alpha n\)</span>. Although biased, the distribution of the estimator rapidly converges to a normal distribution tightly <em>around</em> the true <span class="math inline">\(\alpha\)</span>. Therefore, one can reliably estimate the tail exponent of the Pareto and thus understand the properties of the distribution with relatively few data.</p>
<p>Once we have an estimate for <span class="math inline">\(\widehat \alpha\)</span>, our estimate for the mean will be <span class="math inline">\(\dfrac{\widehat \alpha}{ \widehat \alpha - 1 }\)</span>. This is the <strong>plug-in</strong> estimator for the mean.</p>
<div id="maximum-likelihood-in-practice" class="section level3">
<h3>Maximum likelihood in practice</h3>
<p>To demonstrate the <em>superiority</em> of the <strong>maximum likelihood and plug in estimator</strong> approach to the sample mean of an empirical distribution, I’ll simulate 10^5 Monte-Carlo experiments. For each experiment, I’ll sample <span class="math inline">\(n\)</span> observations from a Pareto with <span class="math inline">\(\alpha = 1.2\)</span> and theoretical mean <span class="math inline">\(\dfrac{1.2}{1.2 - 1} = 6\)</span>. Then, I’ll produce the <strong>maximum likelihood estimate for the tail exponent</strong> and an estimate of the mean using our <strong>plug-in</strong> estimator. At the same time, I’ll produce the regular sample mean for each experiment considering the <em>“empirical distribution”</em>. Finally, I’ll compare the resulting distribution of both the sample mean and the mean from the plug-in estimator.</p>
<p>I’ll repeat this for both <span class="math inline">\(n = 100, 1000\)</span></p>
<pre class="r"><code>alpha &lt;- 1.2
rpareto &lt;- function(n) {
   (1/runif(n)^(1/alpha)) # inverse transform sampling
}

estimate_alpha_ml &lt;- function(observations) {
  alpha &lt;- length(observations)/sum(log(observations))
  if (alpha &lt; 1) {
    alpha &lt;- 1.0005 
  }
  alpha
}

crossing(experiment = 1:10^5, sample_size = c(100, 1000)) %&gt;% 
  mutate(data = map(sample_size, ~ rpareto(.)),
         mean_sample = map_dbl(data, ~ mean(.)),
         alpha_ml = map_dbl(data, ~ estimate_alpha_ml(.)),
         mean_ml = alpha_ml / (alpha_ml - 1) ) -&gt; simulations_result</code></pre>
</div>
</div>
<div id="maximum-likelihoods-alpha-distribution" class="section level2">
<h2>Maximum likelihood’s alpha distribution</h2>
<p>From relatively few observations, we can reliably estimate the tail exponent of the distribution.</p>
<p>This goes against the usual comment that with fat-tailed variables we <em>need more</em> and more observations; <strong>the information about the properties of the distribution</strong> is already there with <em>some</em> data. Let’s check our Monte-Carlo distribution for our maximum likelihood alpha estimates for both values of <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(n= 1000\)</span></p>
<p><img src="/post/2020-06-11-how-to-not-get-fooled-by-the-empirical-distribution_files/figure-html/unnamed-chunk-3-1.png" width="960" /></p>
</div>
<div id="from-ml-estimator-for-alpha-to-plug-in-mean" class="section level2">
<h2>From ML estimator for alpha to plug-in mean</h2>
<p>Once we have convinced ourselves that we can <strong>reliably estimate <span class="math inline">\(\alpha\)</span></strong>, we can then use this alpha estimate to <em>estimate</em> the <strong>mean of the distribution</strong>. However, one must be cautious. To prepare the reader, there are going to be <em>crazy</em> large observations that will confuse both methods at some Monte-Carlo experiments: this is just the nature of fat-tails and the precise reason why forecasting <strong>just a single variable is so dangerous</strong>. Therefore, the mean, or <em>any other</em> single estimate, <strong>cannot possibly prepare us</strong> for the enormous variation that a fat-tailed variable encodes. Thus, these problems haunt even our Maximum Likelihood estimator for the mean; <em>just less</em> than they haunt our estimate for the mean when we use the “empirical distribution”.</p>
<p>These problems show themselves in the form of a large mean for the distribution of the estimates according to each method. Alongside these means, the median and other percentiles of the distributions for both type of estimation methods and both <span class="math inline">\(n\)</span>’s appear in the table below:</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#cipbnscuuz .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#cipbnscuuz .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cipbnscuuz .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#cipbnscuuz .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#cipbnscuuz .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cipbnscuuz .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cipbnscuuz .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#cipbnscuuz .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#cipbnscuuz .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#cipbnscuuz .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#cipbnscuuz .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#cipbnscuuz .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#cipbnscuuz .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#cipbnscuuz .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#cipbnscuuz .gt_from_md > :first-child {
  margin-top: 0;
}

#cipbnscuuz .gt_from_md > :last-child {
  margin-bottom: 0;
}

#cipbnscuuz .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#cipbnscuuz .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#cipbnscuuz .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cipbnscuuz .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#cipbnscuuz .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cipbnscuuz .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#cipbnscuuz .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cipbnscuuz .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cipbnscuuz .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#cipbnscuuz .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cipbnscuuz .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#cipbnscuuz .gt_left {
  text-align: left;
}

#cipbnscuuz .gt_center {
  text-align: center;
}

#cipbnscuuz .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#cipbnscuuz .gt_font_normal {
  font-weight: normal;
}

#cipbnscuuz .gt_font_bold {
  font-weight: bold;
}

#cipbnscuuz .gt_font_italic {
  font-style: italic;
}

#cipbnscuuz .gt_super {
  font-size: 65%;
}

#cipbnscuuz .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="cipbnscuuz" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">method</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">n</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">mean</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">percentile_25</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">median</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">percentile_75</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">maximum_value</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr>
      <td class="gt_row gt_left">Empirical Distribution</td>
      <td class="gt_row gt_right">100</td>
      <td class="gt_row gt_right">5.74</td>
      <td class="gt_row gt_right">3.34</td>
      <td class="gt_row gt_right">3.99</td>
      <td class="gt_row gt_right">5.12</td>
      <td class="gt_row gt_right">21,870.11</td>
    </tr>
    <tr>
      <td class="gt_row gt_left" style="background-color: #F7EFB2;">Maximum Likelihood</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">100</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">67.14</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">4.47</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">5.93</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">8.95</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">29,762.42</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">Empirical Distribution</td>
      <td class="gt_row gt_right">1000</td>
      <td class="gt_row gt_right">7.66</td>
      <td class="gt_row gt_right">4.16</td>
      <td class="gt_row gt_right">4.64</td>
      <td class="gt_row gt_right">5.42</td>
      <td class="gt_row gt_right">189,816.61</td>
    </tr>
    <tr>
      <td class="gt_row gt_left" style="background-color: #F7EFB2;">Maximum Likelihood</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">1000</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">6.16</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">5.42</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">6.00</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">6.71</td>
      <td class="gt_row gt_right" style="background-color: #F7EFB2;">47.60</td>
    </tr>
  </tbody>
  
  
</table></div>
<p>For what it’s worth, the medians of the maximum likelihood method’s distributions demonstrate its superiority versus using the mean of the empirical distribution. Once we zoom in on the majority of the sample, the histogram also shows the superiority of the maximum likelihood over the empirical distribution way of estimating the mean using the sample mean:</p>
<p><img src="/post/2020-06-11-how-to-not-get-fooled-by-the-empirical-distribution_files/figure-html/comparison_dist-1.png" width="960" /></p>
<p>Just remember, superiority over the “empirical distribution” is not that big of a compliment.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>The “empirical distribution” is a patently bad approach for fat-tailed distributions. It cuts the tail at the sample maxima. Thus, a portion of the tail is hidden and ignored in our mean estimation. A better approach is to take advantage of what one can possibly know from the data: the tail properties. For a Pareto, we can estimate its <span class="math inline">\(\alpha\)</span> and then exploit the knowledge we gain about the tail to estimate the mean. This latter approach is less “unreliable”:</p>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

