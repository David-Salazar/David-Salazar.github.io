<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.91.2" />


<title>Statistical Rethinking Week 10 - David Salazar&#39;s blog</title>
<meta property="og:title" content="Statistical Rethinking Week 10 - David Salazar&#39;s blog">


  <link href='https://david-salazar.github.io/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/booglee.jpeg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">7 min read</span>
    

    <h1 class="article-title">Statistical Rethinking Week 10</h1>

    
    <span class="article-date">2020-06-09</span>
    

    <div class="article-content">
      


<p>This is the final week of the best Statistics course out there. It showed the benefits of being ruthless with conditional probabilities: replace everything you don’t know with a distribution conditioned on what you do know. Bayes will do the rest. This holds for both measurement error and missing data.</p>
<div id="st-problem" class="section level1">
<h1>1st problem</h1>
<p>Consider the relationship between brain volume (brain) and body mass (body) in the data(Primates301). These values are presented as single values for each species. However, there is always a range of sizes in a species, and some of these measurements are taken from very small samples. So these values are measured with some unknown error.</p>
<p>Let’s begin by copying Richard’s code to simulate a measurement error:</p>
<pre class="r"><code>data(Primates301)
d &lt;- Primates301
cc &lt;- complete.cases( d$brain , d$body )
B &lt;- d$brain[cc]
M &lt;- d$body[cc]
B &lt;- B / max(B)
M &lt;- M / max(M)

Bse &lt;- B*0.1
Mse &lt;- M*0.1</code></pre>
<p>Ignoring measurement error, the model is thus:</p>
<pre class="r"><code>dat_list &lt;- list(
  B = B,
  M = M 
  )
model_no_measurement &lt;- ulam(
  alist(
  B ~ dlnorm( mu , sigma ),
  mu &lt;- a + b*log(M),
  a ~ normal(0,1),
  b ~ normal(0,1),
  sigma ~ exponential(1)
) , data=dat_list ,
  log_lik = TRUE)</code></pre>
<pre><code>## 
## SAMPLING FOR MODEL &#39;09a4efe803be46fb4328e9d647050be9&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)
## Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)
## Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)
## Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)
## Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)
## Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)
## Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)
## Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)
## Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)
## Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)
## Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)
## Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.148 seconds (Warm-up)
## Chain 1:                0.134 seconds (Sampling)
## Chain 1:                0.282 seconds (Total)
## Chain 1:</code></pre>
<p>With the posterior:</p>
<pre class="r"><code>precis(model_no_measurement)</code></pre>
<pre><code>##            mean         sd      5.5%     94.5%    n_eff     Rhat4
## a     0.4250611 0.05930180 0.3343371 0.5170103 198.3103 0.9985693
## b     0.7829264 0.01447397 0.7598788 0.8044931 192.7510 0.9982643
## sigma 0.2946587 0.01579754 0.2698589 0.3200564 237.8571 0.9981641</code></pre>
<p>Your job is to add the measurement errors to this model. Use the divorce/marriage example in the chapter as a guide.</p>
<div id="solution" class="section level2">
<h2>Solution</h2>
<p>To handle measurement error we will state that the observed values for both M and B come from a distribution centered around true unknown values but with known measurement error (the one that Richard just simulated).</p>
<pre class="r"><code>dat_list$B_se &lt;- Bse
dat_list$M_se &lt;- Mse

model_with_measurement &lt;- ulam(
  alist(
    B ~ normal(B_true, B_se),
    vector[182]: B_true ~ dlnorm(mu, sigma),
    mu &lt;- a + b*log(M_true[i]),
    vector[182]: M_true ~ dlnorm(0.5, 1),
    M ~ normal(M_true, M_se),
    a ~ normal(0,1),
    b ~ normal(0,1),
    sigma ~ exponential(1)
  ),
  data = dat_list,
  chains = 4, cores = 4, 
  start=list( M_est=dat_list$M , B_est=dat_list$B ),
  log_lik = TRUE
)</code></pre>
<p>Let’s check our posterior:</p>
<pre class="r"><code>precis(model_with_measurement)</code></pre>
<pre><code>## 364 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##            mean         sd      5.5%     94.5%    n_eff     Rhat4
## a     0.4179103 0.05630581 0.3253441 0.5061109 2710.747 0.9994487
## b     0.7904683 0.01356841 0.7687093 0.8117376 2440.973 1.0002684
## sigma 0.2636770 0.01733469 0.2376195 0.2930628 3211.569 0.9990291</code></pre>
<p>Our inferences have hardly changed now that we have taken into account the measurement error.</p>
<pre class="r"><code>compare(model_no_measurement, model_with_measurement)</code></pre>
<pre><code>##                                 WAIC           SE        dWAIC        dSE
## model_no_measurement   -8.690610e+02 3.771016e+01 0.000000e+00         NA
## model_with_measurement  1.526778e+13 7.769168e+12 1.526778e+13 7.7906e+12
##                               pWAIC weight
## model_no_measurement   2.711484e+00      1
## model_with_measurement 7.633692e+12      0</code></pre>
<p>Let’s plot the predicted relationship:</p>
<pre class="r"><code>samples &lt;- extract.samples(model_with_measurement)

B_est &lt;- apply(samples$B_true, 2, mean)
M_est &lt;- apply(samples$M_true, 2, mean)</code></pre>
<pre class="r"><code>data.frame(dat_list) %&gt;% 
  add_fitted_draws(model_with_measurement) %&gt;% 
  mutate(.value = exp(.value)) -&gt; data_for_plot</code></pre>
<pre><code>## Warning: `combine()` is deprecated as of dplyr 1.0.0.
## Please use `vctrs::vec_c()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<pre class="r"><code>data_for_plot %&gt;% 
  ggplot(aes(M, .value)) +
  geom_point(aes(y = B), alpha = 0.2) +
  geom_point(data = data.frame(M_est, B_est),
             aes(M_est, B_est), color = &quot;red&quot;, alpha = 0.2) +
  stat_lineribbon(fill = &quot;dodgerblue4&quot;, alpha = 0.2) +
  labs(y = &quot;Brain Volume&quot;,
       x = &quot;Body Mass&quot;,
       title = &quot;Brain Volume as a function of Body Mass&quot;,
       subtitle = &quot;Predicted true measurements in red. Observed measurements in black \n 
       Small animals with small measurement error inform the whole relationship. &quot;)</code></pre>
<p><img src="/post/2020-06-09-statistical-rethinking-week-10_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>The regression line is mainly informed by the small animals because they are more numerous and have smaller measurement errors (by assumption). Therefore, the terrible fit for the largest animals in the sample: there’s few of them and they have the largest measurement error.</p>
</div>
</div>
<div id="second-problem" class="section level1">
<h1>Second problem</h1>
<p>Now consider missing values—this data set is lousy with them. You can ignore measurement error in this problem. Let’s get a quick idea of the missing values by counting them in each variable:</p>
<pre class="r"><code>data(Primates301)
d &lt;- Primates301
colSums( is.na(d) )</code></pre>
<pre><code>##                name               genus             species          subspecies 
##                   0                   0                   0                 267 
##              spp_id            genus_id     social_learning     research_effort 
##                   0                   0                  98                 115 
##               brain                body          group_size           gestation 
##                 117                  63                 114                 161 
##             weaning           longevity        sex_maturity maternal_investment 
##                 185                 181                 194                 197</code></pre>
<pre class="r"><code>cc &lt;- complete.cases( d$body )
M &lt;- d$body[cc]
M &lt;- M / max(M)
B &lt;- d$brain[cc]
B &lt;- B / max( B , na.rm=TRUE )
dat_list &lt;- list(
  B = B,
  M = M 
  )</code></pre>
<p>You should end up with 238 species and 56 missing brain values among them. First, consider whether there is a pattern to the missing values. Does it look like missing values are associated with particular values of body mass?</p>
<pre class="r"><code>data.frame(B, M) %&gt;% 
  mutate(M_groups = cut(M, 20)) %&gt;% 
  group_by(M_groups) %&gt;% 
  summarise(na_percentage = sum(is.na(B))) %&gt;% 
  ggplot(aes(y = M_groups, x = na_percentage)) +
  geom_point() +
  labs(title = &quot;Brain Volume&#39;s NA count by Mass Values&quot;,
       y = &quot;Mass values&quot;,
       x = &quot;Brain Volume&#39;s NA count&quot;,
       subtitle = &quot;NAs are accumulated on animals with small masses&quot;) </code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<p><img src="/post/2020-06-09-statistical-rethinking-week-10_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<blockquote>
<p>Draw a DAG that represents how missingness works in this case. Which type (MCAR, MAR, MNAR) is this?</p>
</blockquote>
<p>Therefore, this is indicative that observations for Brain Size are, in the taxonomy of Don Rubin’s missingess, “Missing at random”. That is, their <em>missingness</em> is related to one of the predictor variables: M.</p>
<p>In DAG form, we say that the missing values arise thus:</p>
<pre class="r"><code>dag &lt;- dagitty::dagitty(&quot;dag {
                        M -&gt; B_true
                        B_true -&gt; B_observed
                        R_B -&gt; B_observed
                        M -&gt; R_B
                        }&quot;)
drawdag(dag)</code></pre>
<pre><code>## Loading required package: dagitty</code></pre>
<p><img src="/post/2020-06-09-statistical-rethinking-week-10_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<blockquote>
<p>Second, impute missing values for brain size.</p>
</blockquote>
<p>As always, be ruthless with conditioning. Replace the values that we don’t know with their own distribution conditional on what we do know. In this case, our likelihood, the lognormal, will serve simultaneously as the prior for the missing observations.</p>
<pre class="r"><code>model_imputing &lt;- ulam(
  alist(
    B ~ dlnorm( mu , sigma ),
    mu &lt;- a + b*log(M),
    a ~ normal(0,1),
    b ~ normal(0,1),
    sigma ~ exponential(1)
  ),
  data = dat_list,
  chains = 4, cores = 4, 
  start=list( B_impute = rep(0.5, 56) )
)</code></pre>
<pre><code>## Found 56 NA values in B and attempting imputation.</code></pre>
<pre><code>## Warning: There were 2 divergent transitions after warmup. Increasing adapt_delta above 0.95 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>## Warning: Examine the pairs() plot to diagnose sampling problems</code></pre>
<pre class="r"><code>precis(model_imputing)</code></pre>
<pre><code>## 56 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##            mean         sd      5.5%     94.5%    n_eff     Rhat4
## a     0.4277080 0.05707665 0.3322580 0.5183632 1169.555 0.9995750
## b     0.7833956 0.01389627 0.7606293 0.8061840 1174.226 0.9993851
## sigma 0.2928041 0.01557047 0.2694383 0.3193382 1216.723 1.0012105</code></pre>
<p>There’s really no difference in our inferences compared to what the inferences that we made when we dropped all the missing values. The answer is simple: most of the imputted variables correspond to animals with small body sizes and therefore were imputted with small brain sizes. Before, our model was already dominated by this type of animals. Now that we have imputed them, it only reinforces this dominance over the regression line. That is, the missing info, once it is accounted for, is redundant: it adds no new information to our model.</p>
<p>Indeed, let’s compare the observed observations to the imputed observations:</p>
<pre class="r"><code>samples &lt;- extract.samples(model_imputing)
B_imputed &lt;- apply(samples$B_impute, 2, mean)
B_imputed_intervals &lt;- apply(samples$B_impute, 2, PI) 

data.frame(B_imputed, low = B_imputed_intervals[1,], high = B_imputed_intervals[2,],
           M = M[!complete.cases(B)]) %&gt;% 
  ggplot(aes(x = M, y = B_imputed)) +
  geom_linerange(aes(ymin = low, ymax = high), linetype = 2, color = &quot;red&quot;) +
  geom_point(color = &quot;red&quot;) +
  geom_point(data = data.frame(M, B),
             aes(M, B), color = &quot;dodgerblue4&quot;, alpha = 0.2) +
  labs(x = &quot;Body Mass&quot;,
       y = &quot;Brain Volume&quot;,
       title = &quot;Imputed values are redundant information&quot;,
       subtitle = &quot;Imputed values appear in red. They add no new information to the model&quot;)</code></pre>
<p><img src="/post/2020-06-09-statistical-rethinking-week-10_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

