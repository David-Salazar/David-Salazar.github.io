<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.91.2" />


<title>Statistical Rethinking: Week 1 - David Salazar&#39;s blog</title>
<meta property="og:title" content="Statistical Rethinking: Week 1 - David Salazar&#39;s blog">


  <link href='https://david-salazar.github.io/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/booglee.jpeg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">11 min read</span>
    

    <h1 class="article-title">Statistical Rethinking: Week 1</h1>

    
    <span class="article-date">2020-04-19</span>
    

    <div class="article-content">
      


<div id="week-1" class="section level1">
<h1>Week 1</h1>
<p>Week 1 tries to go as deep as possible in the intuition and the mechanics of a very simple model. As always with McElreath, he goes on with both clarity and erudition.</p>
<blockquote>
<p>Suppose the globe tossing data had turned out to be 8 water in 15 tosses.
Construct the posterior distribution, using grid approximation. Use the
same flat prior as before.</p>
</blockquote>
<pre class="r"><code># define grid

p_grid &lt;- seq(from = 0, to = 1, length.out = 1000)

# define prior

prior &lt;- rep(1, 1000)

# compute likelihood at each value in grid

likelihood &lt;- dbinom(8, size = 15, prob = p_grid)

# compute product of likelihood and prior

unstd.posterior &lt;- likelihood * prior

# standardize the posterior, so its sums to 1

posterior &lt;- unstd.posterior / sum(unstd.posterior)

samples_uniform &lt;- sample(p_grid, prob = posterior, size = 10000, 
                           replace = TRUE)

data.frame(samples_uniform) %&gt;% 
  ggplot(aes(samples_uniform)) +
    geom_histogram(alpha = 0.6, fill = &quot;dodgerblue4&quot;, color = &quot;black&quot;,
                   binwidth = 0.01) +
   hrbrthemes::theme_ipsum_rc() +
  scale_x_continuous(labels = scales::percent) +
  labs(x = &quot;probability of water&quot;,
       title = &quot;Samples from the Posterior probability&quot;,
       subtitle = &quot;8 water out of 15 tosses. Binwidth of 1 p.p&quot;) +
  geom_vline(xintercept = 0.7, linetype = 2, color = &quot;red&quot;) +
  annotate(&quot;text&quot;, label = &quot; True percentage of water&quot;, x = 0.8, y = 250)</code></pre>
<p><img src="/post/2020-04-19-statistical-rethinking-week-1_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>mean(samples_uniform)</code></pre>
<pre><code>## [1] 0.5313733</code></pre>
<blockquote>
<p>Start over in 1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5. This corresponds to prior information that a majority
of the Earth’s surface is water. What difference does the better prior make?
If it helps, compare posterior distributions (using both priors) to the true
value p = 0.7.</p>
</blockquote>
<pre class="r"><code># define prior

prior &lt;- ifelse(p_grid &lt; 0.5, 0, 2)
  
# compute product of likelihood and prior

unstd.posterior &lt;- likelihood * prior

# standardize the posterior, so its sums to 1

posterior_new &lt;- unstd.posterior / sum(unstd.posterior)

samples_new &lt;- sample(p_grid, prob = posterior_new, 10000, replace = TRUE)
samples_new &lt;- data.frame(samples_new)

data.frame(samples_uniform) %&gt;% 
  ggplot(aes(samples_uniform)) +
    geom_histogram(alpha = 0.6, fill = &quot;dodgerblue4&quot;, color = &quot;black&quot;,
                   binwidth = 0.01) +
  geom_histogram(data = samples_new, mapping = aes(samples_new), alpha = 0.6, fill = &quot;red&quot;, color = &quot;black&quot;,
                 binwidth = 0.01) +
   hrbrthemes::theme_ipsum_rc() +
  scale_x_continuous(labels = scales::percent) +
  labs(x = &quot;probability of water&quot;,
       title = &quot;Samples from Posterior&quot;,
       subtitle = &quot;2 different priors&quot;,
       caption = &quot;8 water out of 15 tosses. Binwidth of 1 p.p&quot;) +
  geom_vline(xintercept = 0.7, linetype = 2, color = &quot;red&quot;)</code></pre>
<p><img src="/post/2020-04-19-statistical-rethinking-week-1_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>By rejecting altogether from the beginning the possibility of having less than the half of the world covered with water, the model with the new prior piles on more plausibility on the values closer to the true value. Thus, the more informative prior helps our inference.</p>
<blockquote>
<p>This problem is more open-ended than the others. Feel free to collaborate on the solution. Suppose you want to estimate the Earth’s proportion of
water very precisely. Specifically, you want the 99% percentile interval of the
posterior distribution of p to be only 0.05 wide. This means the distance between the upper and lower bound of the interval should be 0.05. How many
times will you have to toss the globe to do this? I won’t require a precise
answer. I’m honestly more interested in your approach.</p>
</blockquote>
<div id="practice-from-chapter-3" class="section level2">
<h2>Practice from Chapter 3</h2>
<div id="easy" class="section level3">
<h3>Easy</h3>
<pre class="r"><code>p_grid &lt;- seq(from = 0, to = 1, length.out = 1000)
prior &lt;- rep(1, 1000)
likelihood &lt;- dbinom(6, size = 9, prob = p_grid)
posterior &lt;- likelihood * prior
posterior &lt;- posterior / sum(posterior)
set.seed(100)
samples &lt;- sample(p_grid, prob = posterior, size = 1000, replace = TRUE)</code></pre>
<blockquote>
<p>How much posterior probability lies below p = 0.2?</p>
</blockquote>
<pre class="r"><code>prob &lt;- sum(samples &lt; 0.2)/ length(samples)
glue::glue(&quot;The probability below p = 0.2 is {prob*100}%&quot;)</code></pre>
<pre><code>## The probability below p = 0.2 is 0.1%</code></pre>
<blockquote>
<p>How much posterior probability lies above p = 0.8?</p>
</blockquote>
<pre class="r"><code>prob &lt;- sum(samples &gt; 0.8) / length(samples)
glue::glue(&quot;The probability above p = 0.8 is {prob * 100}%&quot;)</code></pre>
<pre><code>## The probability above p = 0.8 is 9.1%</code></pre>
<blockquote>
<p>How much posterior probability lies between p = 0.2 and p = 0.8</p>
</blockquote>
<pre class="r"><code>prob &lt;- sum(samples &lt; 0.8 &amp; samples &gt; 0.2) / length(samples)
glue::glue(&quot;The probability is {prob * 100}%&quot;)</code></pre>
<pre><code>## The probability is 90.8%</code></pre>
<blockquote>
<p>20% of the posterior probability lies below which value of p?</p>
</blockquote>
<pre class="r"><code>percentile &lt;- quantile(samples, 0.2)
percentile</code></pre>
<pre><code>##       20% 
## 0.5163163</code></pre>
<blockquote>
<p>20% of the posterior probability lies above which value of p?</p>
</blockquote>
<pre class="r"><code>percentile &lt;- quantile(samples, 0.8)
percentile</code></pre>
<pre><code>##       80% 
## 0.7427427</code></pre>
<blockquote>
<p>Which values of p contain the narrowest interval equal to 66% of the posterior probability?</p>
</blockquote>
<pre class="r"><code>rethinking::HPDI(samples, 0.66)</code></pre>
<pre><code>##     |0.66     0.66| 
## 0.5135135 0.7697698</code></pre>
<blockquote>
<p>Which values of p containt 66% of the posterior probability, assuming equal posterior probability both below and above the interval?</p>
</blockquote>
<pre class="r"><code>rethinking::PI(samples, 0.66)</code></pre>
<pre><code>##       17%       83% 
## 0.4961562 0.7569269</code></pre>
</div>
<div id="medium" class="section level3">
<h3>Medium</h3>
<pre class="r"><code>p_grid &lt;- seq(from = 0, to = 1, length.out = 1000)
prior &lt;- rep(1, 1000)
likelihood &lt;- dbinom(8, size = 15, prob = p_grid)
posterior &lt;- likelihood * prior
posterior &lt;- posterior / sum(posterior)
set.seed(100)
samples &lt;- sample(p_grid, prob = posterior, size = 10000, replace = TRUE)</code></pre>
<blockquote>
<p>HPDI 90% for p</p>
</blockquote>
<pre class="r"><code>rethinking::HPDI(samples, 0.9)</code></pre>
<pre><code>##      |0.9      0.9| 
## 0.3343343 0.7217217</code></pre>
<blockquote>
<p>Posterior predictive check. 8 tosses in 15, prediction averaged over our posterior distribution.</p>
</blockquote>
<pre class="r"><code>posterior_predictions &lt;- rbinom(10000, size = 15, prob = samples)
sum(posterior_predictions == 8) / length(posterior_predictions)</code></pre>
<pre><code>## [1] 0.1499</code></pre>
<blockquote>
<p>Using the posterior distribution contracted from the 8/15 data, now calculate the probability of observing 6 water in 9 tosses.</p>
</blockquote>
<pre class="r"><code>posterior_predictions &lt;- rbinom(10000, size = 9, prob = samples)
sum(posterior_predictions == 6) / length(posterior_predictions)</code></pre>
<pre><code>## [1] 0.1842</code></pre>
<div id="different-prior" class="section level4">
<h4>Different prior</h4>
<pre class="r"><code>p_grid &lt;- seq(from = 0, to = 1, length.out = 1000)
prior &lt;- (c(rep(0, 500), rep(1, 500)))
likelihood &lt;- dbinom(8, size = 15, prob = p_grid)
posterior &lt;- likelihood * prior
posterior &lt;- posterior / sum(posterior)
set.seed(100)
samples &lt;- sample(p_grid, prob = posterior, size = 10000, replace = TRUE)</code></pre>
<blockquote>
<p>HPDI 90% for p</p>
</blockquote>
<pre class="r"><code>rethinking::HPDI(samples, 0.9)</code></pre>
<pre><code>##      |0.9      0.9| 
## 0.5005005 0.7097097</code></pre>
<blockquote>
<p>Posterior predictive check. 8 tosses in 15, prediction averaged over our posterior distribution.</p>
</blockquote>
<pre class="r"><code>posterior_predictions &lt;- rbinom(10000, size = 15, prob = samples)
sum(posterior_predictions == 8) / length(posterior_predictions)</code></pre>
<pre><code>## [1] 0.163</code></pre>
<blockquote>
<p>Using the posterior distribution contracted from the 8/15 data, now calculate the probability of observing 6 water in 9 tosses.</p>
</blockquote>
<pre class="r"><code>posterior_predictions &lt;- rbinom(10000, size = 9, prob = samples)
sum(posterior_predictions == 6) / length(posterior_predictions)</code></pre>
<pre><code>## [1] 0.2353</code></pre>
<blockquote>
<p>Number of tosses have a 99% percentile interval to be only 0.05 wide.</p>
</blockquote>
<p>We know the true value of our problem: <span class="math inline">\(p = 0.7\)</span>. We will simulate data for many Ns and find out how precisely we can estimate the interval for each of these values. We will repeat these simulations for each value of N 100 times. Then, we plot the different bounds that we get.</p>
<pre class="r"><code>simulate &lt;- function(N) {

  water &lt;- rbinom(1, size = N, 0.7)
  p_grid &lt;- seq(from = 0, to = 1, length.out = 1000)
  prior &lt;- (c(rep(0, 500), rep(1, 500)))
  likelihood &lt;- dbinom(water, size = N, prob = p_grid)
  posterior &lt;- likelihood * prior
  posterior &lt;- posterior / sum(posterior)
  samples &lt;- sample(p_grid, prob = posterior, size = 10000, replace = TRUE)
  interval &lt;- rethinking::PI(samples, 0.99)
  bound &lt;- (interval[2] - interval[1])
  as.numeric(bound)
}

simulate_repeated &lt;- function(n_value) {
  
  rerun(100, simulate(n_value)) %&gt;% 
    unlist() %&gt;% 
    data.frame(bounds = ., tosses = n_value)
  
}

n_values &lt;- seq(1000, 4000, 100)

n_values %&gt;% 
  map_df(simulate_repeated) %&gt;% 
  ggplot(aes(tosses, bounds)) +
    geom_point(alpha = 0.2) +
  hrbrthemes::theme_ipsum_rc() +
  scale_x_continuous(labels = scales::comma) +
  labs(title = &quot;Simulated width of 89% PI &quot;,
       subtitle = &quot;Decreasing marginal return of more data.&quot;,
       x = &quot;width&quot;,
       y = &quot;# of tosses&quot;)</code></pre>
<p><img src="/post/2020-04-19-statistical-rethinking-week-1_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>It seems we would have to toss the worldarround 2000 times to get a bound close to 0.05. The marginal benefit that we get, in terms of tighting our estimated bound, decreases as we toss more and more. The greates benefits of increasing the data seem to be at the beginning.</p>
</div>
</div>
</div>
<div id="hard" class="section level2">
<h2>Hard</h2>
<pre class="r"><code>library(rethinking)
data(homeworkch3)

birth1</code></pre>
<pre><code>##   [1] 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1
##  [38] 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1
##  [75] 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1</code></pre>
<pre class="r"><code>birth2</code></pre>
<pre><code>##   [1] 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0
##  [38] 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0
##  [75] 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0</code></pre>
<blockquote>
<p>Using grid approximation, compute the posterior distribution for the probability of a birth being a boy. Assume a uniform probability…</p>
</blockquote>
<p>So, set up a binomial likelihood with <span class="math inline">\(n, k\)</span>:</p>
<pre class="r"><code>n &lt;- length(birth1) + length(birth2)
k &lt;- sum(birth1) + sum(birth2)
print(c(n, k))</code></pre>
<pre><code>## [1] 200 111</code></pre>
<pre class="r"><code># set up the grid points for the parameter p
p_grid &lt;- seq(from = 0, to = 1, length.out = 100)

# set an uniform prior
prior &lt;- rep(1, 100)

# compute likelihood for all possible values of p
likelihood &lt;- dbinom(k, n, prob = p_grid)

# compute unstandardised posterior
posterior &lt;- likelihood * prior

# standardise prior
posterior &lt;- posterior/sum(posterior)

# which parameter value maximizes the posterior probability
max_posterior &lt;- p_grid[which.max(posterior)]
glue::glue(&quot;Maximum posterior probability is obtained at {round(max_posterior, 2)}&quot;)</code></pre>
<pre><code>## Maximum posterior probability is obtained at 0.56</code></pre>
<p>A logical answer, considering the slight majority of boys at the sample.</p>
<blockquote>
<p>Draw 10000 random samples from the posterior distribution… HPDI for 50%, 89%, and 97%</p>
</blockquote>
<pre class="r"><code>samples &lt;- sample(p_grid, 10000, prob = posterior, replace = TRUE)
HPDI(samples, prob = c(0.5, 0.89, 0.97))</code></pre>
<pre><code>##     |0.97     |0.89      |0.5      0.5|     0.89|     0.97| 
## 0.4848485 0.5050505 0.5454545 0.5858586 0.6060606 0.6262626</code></pre>
<blockquote>
<p>Check that the model’s implied predictions fit the actual count</p>
</blockquote>
<pre class="r"><code>implied_predictions = rbinom(10000, n, prob = samples)

implied_predictions %&gt;% 
  tibble::tibble(predicted_counts = .) %&gt;% 
  ggplot(aes(predicted_counts)) +
    geom_histogram(binwidth = 1, color = &quot;black&quot;, fill = &quot;dodgerblue4&quot;,
                   alpha = 0.6) +
  hrbrthemes::theme_ipsum_rc() +
  scale_y_continuous(labels = scales::comma) +
  geom_vline(xintercept = k, linetype = 2, color = &quot;red&quot;) +
  labs(title = &quot;Implied predictions by posterior distribution&quot;,
       caption = &quot;Observed value: red line. Binwidth = 1 count value&quot;,
       subtitle = &quot;Posterior fits the data well&quot;)</code></pre>
<p><img src="/post/2020-04-19-statistical-rethinking-week-1_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<blockquote>
<p>Now compare 10,000 counts of boys from 100 simulated first borns only to the number of boys in the first births. How does the model look in this light</p>
</blockquote>
<pre class="r"><code>boys_one &lt;- sum(birth1)


implied_predictions = rbinom(10000, 100, prob = samples)

implied_predictions %&gt;% 
  tibble::tibble(predicted_counts = .) %&gt;% 
  ggplot(aes(predicted_counts)) +
    geom_histogram(binwidth = 1, color = &quot;black&quot;, fill = &quot;dodgerblue4&quot;,
                   alpha = 0.6) +
  hrbrthemes::theme_ipsum_rc() +
  scale_y_continuous(labels = scales::comma) +
  geom_vline(xintercept = boys_one, linetype = 2, color = &quot;red&quot;) +
  labs(title = &quot;Implied predictions by posterior distribution&quot;,
       caption = &quot;Observed value: red line. Binwidth = 1 count value&quot;,
       subtitle = &quot;Posterior fits the distribution of first borns inadequately.&quot;)</code></pre>
<p><img src="/post/2020-04-19-statistical-rethinking-week-1_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>Now the model seems to be underperforming. It’s implied prediction for 100 boys is way larger thatn the actual observed value.</p>
<blockquote>
<p>The model assumes that sex of first and second births are independent. Validate this assumption.</p>
</blockquote>
<p>If the sex of first and second births are independent, after condintioning on the first being a girl, the probability of being a boy should be the same as in the whole sample. Let’s predict with our model conditioning on the boy having an older sister.</p>
<pre class="r"><code># second births that followed female first borns

n = sum(birth1 == 0)
k = sum(birth2[birth1 == 0])

implied_predictions = rbinom(10000, n, prob = samples)

implied_predictions %&gt;% 
  tibble::tibble(predicted_counts = .) %&gt;% 
  ggplot(aes(predicted_counts)) +
    geom_histogram(binwidth = 1, color = &quot;black&quot;, fill = &quot;dodgerblue4&quot;,
                   alpha = 0.6) +
  hrbrthemes::theme_ipsum_rc() +
  scale_y_continuous(labels = scales::comma) +
  geom_vline(xintercept = k, linetype = 2, color = &quot;red&quot;) +
  labs(title = &quot;Implied predictions by posterior distribution&quot;,
       caption = &quot;Observed value: red line. Binwidth = 1 count value&quot;,
       subtitle = &quot;Posterior fit to the distribution of boys after girls is terribly wrong.&quot;)</code></pre>
<p><img src="/post/2020-04-19-statistical-rethinking-week-1_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<pre class="r"><code>prob &lt;- sum(implied_predictions == 39)/ length(implied_predictions)
glue::glue(&quot;Our model only assumes a {prob*100}% to the observed value&quot;)</code></pre>
<pre><code>## Our model only assumes a 0.06% to the observed value</code></pre>
<p>The model under predicts the number of boys that have older sisters. It seems that, in our sample, the sex of the first and second births are not independent. It may be that our sample is biased. Or maybe people keep having babies until they have a boy. Who knows, right?</p>
</div>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

