<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.58.3" />


<title>Spurious PCA under Thick Tails - Dilettanting Data Science</title>
<meta property="og:title" content="Spurious PCA under Thick Tails - Dilettanting Data Science">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/turner.jpg"
         width="200"
         height="200"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://www.kaggle.com/davidsalazarv95">Kaggle</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir?lang=en">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">5 min read</span>
    

    <h1 class="article-title">Spurious PCA under Thick Tails</h1>

    
    <span class="article-date">2020/04/27</span>
    
    

    <div class="article-content">
      


<div id="spurious-pca-under-thick-tails" class="section level1">
<h1>Spurious PCA under Thick Tails</h1>
<p>PCA is a dimensionality reduction technique. It seeks to project the data onto a lower dimensional hyperplane such that as much of the original data variance is preserved. The underlying idea is that the vectors creating these lower dimensional hyperplanes reflect a latent structure in the data. However, what happens when there is no structure at all?</p>
<p>In his most recently published <a href="https://www.researchers.one/media/documents/260-m-Technical%20Incerto%20Vol%201.pdf">technical book</a>,
Taleb examines this question under two different regimes: <em>Mediocristan and Extremistan</em>. That is, he examines what PCA ends up doing when the data is totally random (i.e., come from i.i.d. random variables); where the randomness can come from a thin-tail, like a Gaussian, or from a thick-taile r.v.</p>
<p>In this post, I’ll try to replicate his findings using a small Monte Carlo experiment in R.</p>
<div id="mediocristan-what-is-should-happen" class="section level2">
<h2>Mediocristan: What is should happen?</h2>
<p>When the data comes from uncorrelated random variables, there’s absolutely no structure in the data. That is, no axis of variation should explain the data more than any other axis. Thus, Taleb writes:</p>
<blockquote>
<p>In the simulation, the data that has absolutely no structure: principal components (PCs) should be all equal…</p>
</blockquote>
<p>However, he continues to say that this will only happen if we have enough data:</p>
<blockquote>
<p>But if there is not enough data there is an illusion of what the structure is. As we increase the data (the n variables), the structure becomes ﬂat</p>
</blockquote>
</div>
<div id="the-simulation" class="section level2">
<h2>The Simulation</h2>
<div id="mediocristan" class="section level3">
<h3>Mediocristan</h3>
<pre class="r"><code>pca &lt;- function(df) {
  df %&gt;% 
    prcomp(retx = FALSE, rank. = 30) -&gt; df
  df$sdev[1:30] %&gt;% 
    tibble(component = seq(1, 30), &#39;var_explained&#39; = .) %&gt;%
    mutate(var_explained = var_explained^2) -&gt; pca
  pca
}</code></pre>
<p>Let’s try to replicate this behavior in R. I’ll create 30 i.i.d. gaussians. First, I’ll sample 100 observations. Secondly, I’ll sample 1,000 observations. For each of these two simulated datasets, I’ll perform PCA and store the relative importance assigned to each Principle component.</p>
<pre class="r"><code>gaussian_small &lt;- rerun(30, rnorm(100)) %&gt;% 
  bind_cols()

gaussian_large &lt;- rerun(30, rnorm(10^6)) %&gt;% 
  bind_cols()

pca(gaussian_small) %&gt;% 
  left_join(pca(gaussian_large), by = c(&quot;component&quot;, &quot;component&quot;), suffix = c(&quot;_Small Sample&quot;, &quot;_Large Sample&quot;)) %&gt;% 
  pivot_longer(cols = starts_with(&quot;var&quot;), names_prefix = &quot;var_explained_&quot;) %&gt;% 
  rename(&quot;sample&quot; = name, 
         &quot;variance&quot; = value) -&gt; pcas_gaussian</code></pre>
<p>Now, let’s plot the results and check the different importances assigned to each of the principle components:</p>
<pre class="r"><code>pcas_gaussian %&gt;%
  ggplot(aes(x = component, y = variance, fill = sample)) +
    geom_col(color = &quot;black&quot;, alpha = 0.8) +
  facet_wrap(~sample) +
  theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_brewer(palette = &quot;Set1&quot;) +
  guides(fill = FALSE) +
  labs(y = &quot;Variance&quot;,
       x = &quot;PCA Component&quot;,
       title = &quot;PCA Ranking on uncorrelated randomness from Mediocristan&quot;,
       subtitle = &quot;Large sample washs away spurious correlation&quot;,
       caption = &quot;There&#39;s absolutely no structure in the data. That is, no axis of variation should explain the data more than any other axis&quot;) </code></pre>
<p><img src="/post/2020-04-27-spurious-pca-under-thick-tails_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>ggsave(&quot;mediocristan.jpg&quot;)</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
<p>Great! I got the same results as Taleb did. In his own words, the results are explained thus:</p>
<blockquote>
<p>We can see the “ﬂatter” PCA structure with the Gaussian as n increases (the difference between PCAs shrinks).</p>
</blockquote>
<p>Thus, with reasonably enough data, the spurious correlation between the total variance in the data and the different axes of variations identified by the algorithm wash away pretty quickly. Let’s see what happens under thick-tails.</p>
</div>
<div id="extremistan" class="section level3">
<h3>Extremistan</h3>
<p>Just as before, I’ll create 30 random variables. With the difference being that this time the random variables will be Stabled Distributions with <span class="math inline">\(\alpha = \dfrac{3}{2}, \beta = 1, \mu = 0, \sigma = 1\)</span>. Just as before, I’ll create two datasets: one with 100 observations and other one with 1,000. For each of these, I’ll perform PCA and store the relative importance given to the identified PCAs.</p>
<pre class="r"><code>stable_small &lt;- rerun(30, rstable(100, alpha = 3/2, beta = 1, gamma = 1, delta = 0)) %&gt;% 
  bind_cols()

stable_large &lt;- rerun(30, rstable(10^6, alpha = 3/2, beta = 1, gamma = 1, delta = 0)) %&gt;% 
  bind_cols() 

pca(stable_small) %&gt;% 
  left_join(pca(stable_large), by = c(&quot;component&quot;, &quot;component&quot;), suffix = c(&quot;_Small Sample&quot;, &quot;_Large Sample&quot;)) %&gt;% 
  pivot_longer(cols = starts_with(&quot;var&quot;), names_prefix = &quot;var_explained_&quot;) %&gt;% 
  rename(&quot;sample&quot; = name, 
         &quot;variance&quot; = value) -&gt; pcas_stable</code></pre>
<p>Let’s plot the results:</p>
<pre class="r"><code>pcas_stable %&gt;% 
  ggplot(aes(x = component, y = variance, fill = sample)) +
    geom_col(color = &quot;black&quot;, alpha = 0.8) +
  facet_wrap(~sample) +
  theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_brewer(palette = &quot;Set1&quot;) +
  guides(fill = FALSE) +
  labs(x = &quot;PCA component&quot;,
       y = &quot;Variance&quot;,
       title = &quot;PCA Ranking on uncorrelated randomness from Extremistan&quot;,
       subtitle = &quot;Spurious correlations do not wash away so easily&quot;,
       caption = &quot;There&#39;s absolutely no structure in the data. That is, no axis of variation should explain the data more than any other axis&quot;)</code></pre>
<p><img src="/post/2020-04-27-spurious-pca-under-thick-tails_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>ggsave(&quot;extremistan.jpg&quot;)</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
<p>Wheras before in Mediocristan the algorithm correctly identified that no axis of variation could possibly explain more than any other axis the total variation in the data, now the algorithm is fooled by the randomness coming from the thick-tail variables. Indeed, Taleb writes:</p>
<blockquote>
<p>The small sample effect causes the ordered PCAs to show a declining slope. We have zero correlation on the matrix. For a thick tailed distribution (the lower section), we need a lot more data for the spurious correlation to wash out i.e., dimension reduction does not work with thick tails.</p>
</blockquote>
</div>
</div>
</div>
<div id="conclusions" class="section level1">
<h1>Conclusions</h1>
<p>Just as with the <a href="2020-04-17-fat-vs-thin-does-lln-work.html">mean estimations</a>, Taleb shows that most of the statistical algorithms, this time PCA, suffer from a persistent small sample effect when dealing with randomness coming from thick tailed distribution. Thus, one must thread very carefully.</p>
<p>Finally, replicating his plots is still a great distraction from all the Covid noise.</p>
</div>

    </div>
  

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


  
  </article>

</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/python.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

