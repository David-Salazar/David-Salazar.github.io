<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.91.2" />


<title>Fat vs Thin: does LLN work? - David Salazar&#39;s blog</title>
<meta property="og:title" content="Fat vs Thin: does LLN work? - David Salazar&#39;s blog">


  <link href='https://david-salazar.github.io/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/booglee.jpeg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">5 min read</span>
    

    <h1 class="article-title">Fat vs Thin: does LLN work?</h1>

    
    <span class="article-date">2020-04-17</span>
    

    <div class="article-content">
      


<div id="fat-tails-are-a-different-beast" class="section level1">
<h1>Fat tails are a different beast</h1>
<blockquote>
<p>Statistical estimation is based on the LLN and CLT. The CLT states that the sampling distribution will look like a normal. The LLN that the variance of the normal will decrease as our sampling size increases.</p>
</blockquote>
<p>Or so does Nassim Nicholas Taleb says in his recently published <a href="https://www.researchers.one/media/documents/260-m-Technical%20Incerto%20Vol%201.pdf">technical book</a>, wherein he explains how common practice statistical methodology breaks down under the Extremistan regime. That is, under fat tails.</p>
<p>In this post, I’ll try my best to understand why is he right. The key idea, I believe, when extremely rare things can happen, they alone determine the distribution. Thus, one cannot hope to understand it with normal samples.</p>
<div id="a-first-intuitive-approximation" class="section level2">
<h2>A first intuitive approximation</h2>
<p>Taleb begins by giving an intuitive explanation. Imagine that you are working with a sample. You observe a large deviation from the values that you have. Is this deviation caused by one big observation or multiple medium deviations.</p>
<blockquote>
<p>Assume a large deviation X.
- In Mediocristan, the probability of sampling higher than X twice in a
row is greater than sampling higher than 2X once.
- In Extremistan, the probability of sampling higher than 2X once is
greater than the probability of sampling higher than X twice in a row.</p>
</blockquote>
<p>Let’s try to replicate what he did in R. He proposes to analyze the ratio of observing exceeding deviations in terms of sigmas for a normal. For example, the ratio of the Survival of two 2-sigma events to the Survival one 4-sigma event. Then, he plots this ratio for different values of <span class="math inline">\(\sigma\)</span>. Let’s do it in R.</p>
<pre class="r"><code>x &lt;- seq(0, 3.45, 0.05)

two_x &lt;- x*2

ratio &lt;-((1 -pnorm(x))^2)/(1-pnorm(two_x))

tibble(ratio) %&gt;% 
  cbind(x) %&gt;% 
  rename(&#39;k&#39; = x) %&gt;% 
  mutate(k = as.double(k)) %&gt;% 
  arrange(k) %&gt;% 
  ggplot(aes(x = k, y = ratio)) +
    geom_point(color = &#39;dodgerblue4&#39;) +
  hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_y_continuous(labels = scales::comma) +
  labs(x = &quot;k in terms of sigma&quot;,
       title = &quot;Mediocristan&quot;, 
       subtitle = &quot;Ratio of S(X)^2/S(2X) from a Standard Normal&quot;)</code></pre>
<p><img src="/post/2020-04-17-fat-vs-thin-does-lln-work_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Thus, it is almost impossible to fathom a 4-sigma event with a standard normal. <strong>It is much more likely that our deviation comes from two 2 sigma events</strong>. Thus, the distribution can be inferred disregarding the extreme. However, not all distributions work the same way. Let’s see how the LLN works differently for different types of random variables.</p>
</div>
<div id="law-of-large-numbers" class="section level2">
<h2>Law of Large Numbers</h2>
<p>What are the consequences of these differences? Imagine the law of large numbers. We are sampling to estimate the mean. With a standard normal, even if we get a deviation, it will be a mild one and it will probably come from some consecutive observations. Thus, with enough observations, the weighted contribution to the mean of these observations won’t derail our estimates.</p>
<p>However, in Extremistan this does not play out; at least, not quick enough. Given the size of the deviations we get every once in a while, they alone will determine our estimates; making the rest of data meaningless.</p>
<p>Let’s check this with some simulations.</p>
<div id="mediocristan" class="section level3">
<h3>Mediocristan</h3>
<p>In Mediocristan, given the tamed randomness that we are dealing with, we do not expect large deviations to play a significant role. As we said before, we will only have medium deviations from the mean that are smooth over pretty quickly as their weighted contribution to the average drops. That is, the LLN is with a relatively small number of observations.</p>
<pre class="r"><code>samples &lt;- 10000

thin &lt;-rnorm(samples, sd = 20)

fat &lt;- rlnorm(samples, sdlog = 5,meanlog = 0)

cumulative_mean &lt;- function(numbers) {
    x &lt;- seq(1, length(numbers))
    cum_mean &lt;- cumsum(numbers)/x 
    cum_mean
}


thin_cum_mean &lt;- cumulative_mean(thin)

thin_cum_mean %&gt;%
  tibble(running_mean = .) %&gt;% 
  add_rownames(var = &#39;number_samples&#39;) %&gt;% 
  mutate(number_samples = as.double(number_samples)) %&gt;% 
  arrange(number_samples) %&gt;% 
  ggplot(aes(x = number_samples, y = running_mean)) +
    geom_line(color = &#39;dodgerblue4&#39;) +
    geom_hline(yintercept = 0, linetype = 2, color = &#39;red&#39;) +
  hrbrthemes::theme_ipsum_rc(grid = &#39;Y&#39;) +
  scale_x_continuous(labels = scales::comma) +
  labs(x = &quot;# of samples&quot;,
       title = &quot;High variance (20) Gaussian&quot;, 
       subtitle = &quot;Sample is helpful. Red line is mean.&quot;)</code></pre>
<p><img src="/post/2020-04-17-fat-vs-thin-does-lln-work_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="extremistan" class="section level3">
<h3>Extremistan</h3>
<p>However, in Extremistan we are on an entirely different regime. As large deviations determine the whole distribution, most of the information we get about the distribution is pure noise that won’t be helpful to estimate the mean. Indeed, Taleb writes:</p>
<blockquote>
<p>The mean of a distribution will rarely correspond to the sample mean; it will have a persistent small sample effect (downward or upward)…</p>
</blockquote>
<pre class="r"><code>samples &lt;- 1000

fat &lt;- 1/(runif(samples))^(1/1.13)

fat_cum_mean &lt;- cumulative_mean(fat)

mean &lt;- 1.13/0.13

fat_cum_mean %&gt;% 
  tibble(running_mean = .) %&gt;% 
  add_rownames(var = &#39;number_samples&#39;) %&gt;% 
  mutate(number_samples = as.double(number_samples)) %&gt;% 
  arrange(number_samples) %&gt;% 
  ggplot(aes(x = number_samples, y = running_mean)) +
    geom_line(color = &#39;dodgerblue4&#39;) +
  hrbrthemes::theme_ipsum_rc(grid = &#39;Y&#39;) +
  scale_y_continuous(labels = scales::comma) +
  geom_hline(yintercept = mean, linetype = 2, color = &#39;red&#39;) +
  labs(title = &#39;Extremistan, Pareto 80/20&#39;,
       subtitle = &#39;Sample mean is uninformative. Red line is mean&#39;)</code></pre>
<p><img src="/post/2020-04-17-fat-vs-thin-does-lln-work_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
</div>
<div id="central-limit-theorem" class="section level2">
<h2>Central Limit Theorem</h2>
<p>In the same way, when a distribution is dominated by its extremes, it will take much, much longer for the sampling distribution to compress than it would with your average Gaussian.</p>
<div id="mediocristan-1" class="section level3">
<h3>Mediocristan</h3>
<pre class="r"><code>gaussian_mean &lt;- function(sample_size) {
  
  samples &lt;- rnorm(sample_size)
  return(mean(samples))
}

mean_30 &lt;- purrr::rerun(1000, gaussian_mean(30)) %&gt;% 
  unlist()

mean_1 &lt;- rnorm(1000)

tibble(iteration = seq(1, 1000, 1), mean_30, mean_1) %&gt;% 
  pivot_longer(cols = starts_with(&quot;mean&quot;)) %&gt;%  
  ggplot(aes(x = value, fill = name)) +
  geom_density(alpha = 0.6) +
  hrbrthemes::theme_ipsum_rc() +
  hrbrthemes::scale_fill_ft() +
  labs(subtitle = &quot;Distribution compress very quickly&quot;,
       title = &quot;Sample distribution for the mean of Gaussian&quot;)</code></pre>
<p><img src="/post/2020-04-17-fat-vs-thin-does-lln-work_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="extremistan-1" class="section level3">
<h3>Extremistan</h3>
<pre class="r"><code>pareto_mean &lt;- function(sample_size) {

  fat &lt;- 1/(runif(sample_size))^(1/1.13)
  mean(fat)
}

mean_300 &lt;- purrr::rerun(1000, pareto_mean(300)) %&gt;% 
  unlist()

mean_500 &lt;- purrr::rerun(1000, pareto_mean(500)) %&gt;% 
  unlist()

tibble(iteration = seq(1, 1000, 1), mean_300, mean_500) %&gt;% 
  pivot_longer(cols = starts_with(&quot;mean&quot;)) %&gt;%  
  ggplot(aes(x = value, fill = name)) +
  geom_density(alpha = 0.6) +
  scale_x_continuous(limits = c(0, 30)) +
  hrbrthemes::theme_ipsum_rc() +
  hrbrthemes::scale_fill_ft() +
  labs(title = &quot;Pare 80/20 mean for 300 and 500 obs&quot;,
       subtitle = &quot;The sampling distribution for the mean does not compress&quot;)</code></pre>
<p><img src="/post/2020-04-17-fat-vs-thin-does-lln-work_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>When a distribution is determined by a rare event, then, by definition, you will almost never observe its true properties from a sample. Also, the intuition that we gain from studying the Gaussian dulls our senses: it conditions us to a type of tame randomness that goes in the total opposite direction.</p>
</div>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

