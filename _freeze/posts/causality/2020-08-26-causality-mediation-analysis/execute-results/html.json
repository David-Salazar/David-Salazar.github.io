{
  "hash": "700690341221ad9b81f0d34e7299245c",
  "result": {
    "markdown": "---\ntitle: 'Causality: Mediation Analysis'\nauthor: ''\ndate: '2020-08-26'\nslug: causality-mediation-analysis\ncategories: []\ntags: []\naliases: \n  - ../../2020/08/26/causality-mediation-analysis/\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggdag)\nextrafont::loadfonts(device=\"win\")\ntheme_set(theme_dag(base_family = \"Roboto Condensed\"))\n```\n:::\n\n\n## Motivation\n\nKids are the prototypical question makers; they never stop asking questions. Just after you have answered a **Why?** question, they ask yet another *Why*? This is the problem of mediation analysis: if you answer that *X causes Y*, how does exactly **the causal mechanism work**? Is the causal **effect direct or mediated** through yet another variable M? Mediation analysis aims to disentangle the **direct effect** (which does not pass through the mediator) from the indirect effect (the part that passes through the mediator).\n\nJudah Pearl has formulated an answer to the mediation problem by using counterfactuals. By giving precise counterfactual interpretations to both the **Natural Direct Effects (NDE)** and the **Natural Indirect Effects (NIE)**, we can use the machinery of Causal Inference to solve the mediation problem.  \n\nIn this post, we'll study the **counterfactual definition and identification criteria** behind *direct and indirect effects*. Finally, we'll solve a numerical example to put what we have learnt into practice. \n\nAll quotes come from Chapter 9 of Pearl's Causality and Chapter 4 of his primer. \n\n## Counterfactual Definitions\n\nWe will use the following canonical Structural Model for a mediation problem to define the following direct and indirect effects. \n\n$$\nt=f_{T}\\left(u_{T}\\right) \\quad m=f_{M}\\left(t, u_{M}\\right) \\quad y=f_{Y}\\left(t, m, u_{Y}\\right)\n$$\nLet $T$ be a binary treatment. \n\n### Control freak\n\nSo far, we have studied the total causal effect of $X$ on $Y$: $P(Y|do(X))$. \"The term “direct effect” is meant to quantify an effect that\nis not mediated by other variables in the model or, more accurately, the sensitivity of $Y$ to changes in $X$ while all other factors in the analysis are held fixed\". Notice that holding variables fixed implies an **intervention** that *cannot always* be mimicked by **conditioning**. \n\nWe will label this effect the **Controlled Direct Effect (CDE)**. In counterfactual terms, it is defined thus:\n\n\\[\n\\begin{aligned}\n\\operatorname{CDE}(m) &=E\\left[Y_{1, m}-Y_{0, m}\\right] \\\\\n&=E[Y \\mid d o(T=1, M=m)]-E[Y \\mid d o(T=0, M=m)]\n\\end{aligned}\n\\]\n\n> CDE measures the expected increase in \\( Y \\) as the treatment changes from \\( T=0 \\) to \\( T=1, \\) while the mediator is set to a specified level \\( M=m \\) uniformly over the entire population.\n\nHowever, intervening on the mediator is an over-kill. We need to be more intelligent.\n\n### Natural: Let it flow\n\nA less stringent intervention is defined by studying the expected increase in \\( Y \\) as the treatment changes from \\( T=0 \\) to \\( T=1, \\), \"while the mediator is set to whatever value *it would have attained (for each individual) prior to the change*, that is, under $T = 0$\". We will label this the **Natural Direct Effect (NDE)**. In counterfactual terms:\n\n$$\nN D E=E\\left[Y_{1, M_{0}}-Y_{0, M_{0}}\\right]\n$$\nWhereas the CDE is made out of do-expressions, the NDE is defined in terms of *nested counterfactuals*. Therefore, according to [Pearl's Ladder of Causation and Bareinboim's Causal Hierarchy Theorem](https://david-salazar.github.io/2020/08/10/causality-counterfactuals-clash-of-worlds/), NDE requires a **more elaborate causal knowledge** to be *identified* than the CDE. That is, whereas the CDE could be estimated using experimental evidence, the NDE, in principle, cannot be estimated using **only** experimental evidence.  \n\n#### What about indirect effects?\n\nOnce we have defined a direct effect, the natural thing to do, in order to tackle the mediation problem, is to also define an *indirect* effect. The comparison of the two terms will allow us to answer the mediation problem. \n\nNotice that we must define the **Natural Indirect Effect (NIE)** such that it measures \"the portion of the effect that can be explained by mediation alone. Thus, it must disable the capacity of $Y$ to respond to $X$\". To do so, we will define the NIE thus:\n\n> NIE measures the expected increase in Y when the treatment is held constant, at $T = 0$, and $M$ changes to whatever value it would have attained (for each individual) under $T=1$.\n\nIn counterfactual language:\n\n$$\nN I E=E\\left[Y_{0, M_{1}}-Y_{0, M_{0}}\\right]\n$$\nJust like with the NDE, we are faced with nested counterfactuals that cannot always be estimated using experimental evidence. \n\n### Response fractions\n\nTo answer the mediation question, it is useful to state the direct and indirect effects in terms of the total effect. \n\nWhat percentage is due to the **direct effect** of $X$? The ratio $NDE/TE$ \"measures the fraction of the response that is transmitted directly, with $M$ frozen.\"\n\nWhat percentage is due to the mediator variable, that is, is due to the **indirect effect** of $X$? \n\n> $NIE∕TE$ measures the fraction of the response that **may be** transmitted through $M$, with $Y$ blinded to\n$X$. Consequently, the difference $(TE − NDE)∕TE$ measures the fraction of the response that **is\nnecessarily** due to M.\n\n## Identification \n\nBecause both the NDE and the NIE are defined with *nested counterfactuals*, they imply a contradiction between two **different and clashing causal worlds** that can only be resolved through the invariant information across worlds. However, not all structural causal models (SCM) imply enough restrictions such that this invariant information is enough to estimate the nested counterfactuals with a combination of **observational and experimental evidence**. \n\nWhat type of causal models yield NDE (and NIE) that are identifiable? In [this paper](), Pearl says that every model where there is a set $w$ of measured covariates such that:\n\n1. No member of $W$ is a descendant of $T$.\n\n1. $W$ blocks all backdoor paths from $M$ to $Y$ not traversing $T$. That is, $W$ deconfounds the mediator-outcome relationship (holding $T$ constant).\n\nThen, both effects (NDE and NIE) are **identifiable** with *experimental evidence*. The formula for the NDE becomes thus:\n\n$$\n\\begin{aligned}\n N D E=\\sum_{m} \\sum_{w}\\left[E(Y \\mid d o(T=1, M=m)), W=w)-E(Y \\mid d o(T=0, M=m), W=w)\\right] \\\\\nP(M=m \\mid d o(T=0), W=w) P(W=w)\n\\end{aligned}\n$$\n\nThe intuition is the following:\n\n> The natural direct effect is the weighted average of the controlled direct effect \\( C D E(m), \\) shown in the square brackets, using the no-treatment distribution \\( P(M=m \\mid T=0) \\) as a weighting function. \n\nFurthermore, if we require **identification** with *observational data*, we must have a causal model where, *besides* the former two assumptions, the following two assumptions also hold:\n\n- The \\( W \\) -specific effect of the treatment on the mediator is identifiable by some means.\n\\[\n[P(m \\mid d o(t), w) \\text { is identifiable }]\n\\]\n- The \\( W \\) -specific joint effect of \\( \\{ \\) treatment \\( + \\) mediator \\( \\} \\) on the outcome is identifiable by some means.\n\\[\n[P(y \\mid d o(t, m), w) \\text { is identifiable }]\n\\]\n\nThen, the equation for the NDE (and the NIE) becomes:\n\n\n$$\n\\begin{equation}\n\\begin{array}{c}\nN D E=\\sum_{m} \\sum_{w}[E(Y \\mid T=1, M=m, W=w)-E(Y \\mid T=0, M=m, W=w)] \\\\\nP(M=m \\mid T=0, W=w) P(W=w) \\\\\nN I E=\\sum_{m} \\sum_{w}[P(M=m \\mid T=1, W=w)-P(M=m \\mid T=0, W=w)] \\\\\nE(Y \\mid T=0, M=m, W=w) P(W=w)\n\\end{array}\n\\end{equation}\n$$\n\nFinally, if there is no confounding in our causal model whatsoever, there's no need fo conditioning on $W$ and we arrive at the **mediation formulas**:\n\n$$\nNDE = \\sum_{m}[E[Y \\mid T=1, M=m]-E[Y \\mid T=0, M=m]] P(M=m \\mid T=0)\n$$\nSimilarly, for the NIE the mediation formula is the following:\n\n$$\nN I E=\\sum_{m} E[Y \\mid T=0, M=m][P(M=m \\mid T=1)-P(M=m \\mid T=0)]\n$$\nIn the following section, I'll present four examples of causal models where the NDE and NIE may not be identifiable.\n\n### Examples of Identification\n\n#### First example\n\nSuppose you have the following causal model. Are the NDE and NIE identifiable?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfirst_example <- dagify(y ~ t + m,\n                        m ~ t)\nggdag(first_example) +\n  labs(title = \"Are the NDE and NIE identifiable?\",\n       subtitle = \"Given that there's no confounding, they are identifiable!\")\n```\n\n::: {.cell-output-display}\n![](2020-08-26-causality-mediation-analysis_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nYes, the effects are identifiable: there's no confounding and we can use the **mediator formulas**.\n\n#### Second example\n\nSuppose you have the following causal model. Are the NDE and NIE identifiable?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsecond_example <- dagify(y ~ t + m + w,\n                        m ~ t + w,\n                        t ~ w)\nggdag(second_example) +\n  labs(title = \"Are the NDE and NIE identifiable?\",\n       subtitle = \"w confounds all three relationships. Adjusting for W, renders NDE and NIE identifiable\")\n```\n\n::: {.cell-output-display}\n![](2020-08-26-causality-mediation-analysis_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\nYes, we can identify the NDE and the NIE. Although $W$ confounds all three relationships, by adjusting by $W$, we can deconfound them and estimate the NDE and NIE. \n\n#### Third example\n\nSuppose you have the following causal model where the dashed arc represents a common unobserved ancestor. Are the NDE and NIE identifiable?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthird_example <- dagify(m ~ t,\n                        z ~ m,\n                        y ~ z + t,\n                        m ~~ y)\ntidy_dagitty(third_example, layout = \"nicely\", seed = 2) %>% \n  mutate(linetype = if_else(direction == \"->\", \"solid\", \"dashed\")) %>% \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend, edge_linetype = linetype)) +\n  geom_dag_edges(aes(end_cap = ggraph::circle(10, \"mm\"))) +\n  geom_dag_point() + \n  geom_dag_text() +\n  labs(title = \"Are the NDE and NIE identifiable?\",\n       subtitle = \"Although the causal effect M->Y is identifiable, we cannot deconfound the relationships and\n        thus cannot estimate neither the NDE nor the NIE\")\n```\n\n::: {.cell-output-display}\n![](2020-08-26-causality-mediation-analysis_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWe cannot!\n\n> Unfortunately, although the causal effect of \\( \\{T, M\\} \\) on \\( Y, \\) as well as the controlled direct effect \\( C D E(m) \\) are both identifiable (through the front-door estimator), condition \\(2 \\) cannot be satisfied; no covariate can be measured that deconfounds the \\( M \\rightarrow Y \\) relationship. The front-door estimator provides a consistent estimate of the population causal effect, \\( P(Y=y \\mid d o(M=m)), \\) while unconfoundedness, as defined before, requires independence of \\( U_{M} \\) and \\( U_{Y}, \\) which measurement of \\( Z \\) cannot induce.\n\nThis is yet another example of the **Causal Hierarchy Theorem**: experimental evidence is not enough to determine counterfactual information. In this case, causal effects are not enough to determine the nested counterfactuals that define the NDE. \n\n#### Four example\n\nSuppose you have the following causal model. Are the NDE and NIE identifiable?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfourth_example <- dagify(y ~ t + m + w,\n                        m ~ t + w,\n                        w ~ t)\nggdag(fourth_example) +\n  labs(title = \"Are the NDE and NIE identifiable?\",\n       subtitle = \"Although W deconfounds M->Y, it is a descendant of T. Thus, we cannot identify NDE or NIE. \")\n```\n\n::: {.cell-output-display}\n![](2020-08-26-causality-mediation-analysis_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nNo, neither NDE nor NIE are identifiable. Given our first assumption, there's the following \"general pattern that prevents identification of natural effects in any non-parametric model\":\n\n> Whenever a variable exists, be it measured or unmeasured, that\nis a descendant of T and an ancestor of both M and Y (W in our examples), NDE is not\nidentifiable.\n\nHowever, the restriction does not apply to linear models where every counterfactual is identifiable once the parameters are identified. Sadly, \"the increased identification power comes at increasing the danger of mis-specification\".\n\n## Numerical example\n\nI'll finish the post by giving the following numerical example to show how we can use what we've learnt to estimate natural effects and solve a mediation problem with data. This is the exercise 4.5.4 in Pearl's primer. \n\n> Suppose that a company is accused of gender discrimination. Let $T = 1$ standing for male\napplicants, $M = 1$ standing for highly qualified applicants, and $Y = 1$ standing for hiring.\n(Find the proportion of the hiring disparity that is due to gender, and the proportion that\ncould be explained by disparity in qualification alone.)\n\nThat is, there are two paths whereby there's discrimination. Male applicants tend to get more easily hired and thus have more qualifications. However, male applicants may also be favored by the company just because they are male. We draw the following DAG:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngender_discrimination <- dagify(m ~ t,\n                                y ~ m + t,\n                                labels = c(\"m\" = \"Qualifications\",\n                                           \"t\" = \"Gender\",\n                                           \"y\" = \"Hiring\"))\ngender_discrimination %>%  tidy_dagitty(layout = \"tree\") %>% \n   ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n    geom_dag_edges() +\n    geom_dag_text(col = \"white\") +\n    geom_dag_point(alpha = 0.5) +\n    geom_dag_label_repel(aes(label = label), fill = \"dodgerblue4\",\n      col = \"white\", show.legend = FALSE, family = \"Roboto Condensed\")\n```\n\n::: {.cell-output-display}\n![](2020-08-26-causality-mediation-analysis_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nLet's say that we collect the following data:\n\n$$\n\\begin{array}{ccc}\n\\hline \\text { Gender } & \\text { Qualification } & \\text { Success Hiring } \\\\\nT & M & E(Y \\mid T=t, M=m) \\\\\n\\hline 1 & 1 & 0.80 \\\\\n1 & 0 & 0.40 \\\\\n0 & 1 & 0.30 \\\\\n0 & 0 & 0.20 \\\\\n\\hline\n\\end{array}\n$$\n\n$$\n\\begin{array}{cc}\n\\hline \\text { Gender } & \\text { Qualification } \\\\\nT & E(M \\mid T=t) \\\\\n\\hline 0 & 0.40 \\\\\n1 & 0.75 \\\\\n\\hline\n\\end{array}\n$$\nAssuming that there's no confounding, we use the **mediator formulas thus**:\n\n$$\n\\begin{aligned}\nN D E=& \\sum_{m}[E[Y \\mid T=1, M=m]-E[Y \\mid T=0, M=m]] P(M=m \\mid T=0) \\\\\n=&[E[Y \\mid T=1, M=0]-E[Y \\mid T=0, M=0]] P(M=0 \\mid T=0) \\\\\n&+[E[Y \\mid T=1, M=1]-E[Y \\mid T=0, M=1]] P(M=1 \\mid T=0) \\\\\n=&(0.4-0.2)(1-0.4)+(0.8-0.3) 0.4 \\\\\n=& 0.32 \\\\\nN I E=& \\sum_{m} E[Y \\mid T=0, M=m][P(M=m \\mid T=1)-P(M=m \\mid T=0)] \\\\\n=& E[Y \\mid T=0, M=0][P(M=0 \\mid T=1)-P(M=0 \\mid T=0)] \\\\\n&+E[Y \\mid T=0, M=1][P(M=1 \\mid T=1)-P(M=1 \\mid T=0)] \\\\\n=&(0.75-0.4)(0.3-0.2) \\\\\n=& 0.035\n\\end{aligned}\n$$\n\nTherefore, given that the direct effect is substantially larger than the indirect effect, we conclude that it is not the different qualifications in themselves, but the gender that is driving the hiring process in the company.\n\n## Conclusions\n\nMediation analysis aims to disentangle the **NDE** (which does not pass through the mediator) from the **NIE** (the part that passes through the mediator). We've seen how the correct definition of these effects requires counterfactual thinking that cannot always be empirIcally identified with either experimental or observational evidence. After having stated the required assumptions for identifiability, we practiced recognizing such assumptions with several causal models. Finally, we practiced with a numerical example out of Pearl's primer. \n\n\n",
    "supporting": [
      "2020-08-26-causality-mediation-analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}