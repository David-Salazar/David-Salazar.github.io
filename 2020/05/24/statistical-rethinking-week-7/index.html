<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.91.2" />


<title>Statistical Rethinking: Week 7 - David Salazar&#39;s blog</title>
<meta property="og:title" content="Statistical Rethinking: Week 7 - David Salazar&#39;s blog">


  <link href='https://david-salazar.github.io/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/booglee.jpeg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/David-Salazar">GitHub</a></li>
    
    <li><a href="https://david-salazar.github.io/">Posts</a></li>
    
    <li><a href="https://twitter.com/DavidSalazarVir">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">16 min read</span>
    

    <h1 class="article-title">Statistical Rethinking: Week 7</h1>

    
    <span class="article-date">2020-05-24</span>
    

    <div class="article-content">
      


<div id="statistical-rethinking-week-7" class="section level1">
<h1>Statistical Rethinking: Week 7</h1>
<p>This week paid off. All the hard work of understanding link functions, HMC flavored Monte-Carlo, and GLM allowed to study more complex models. To keep using Richard’s metaphor: it allowed us to study monsters: models with different parts made out of different models. In particular, Zero Inflated Models and Ordered Categories.</p>
</div>
<div id="homework" class="section level1">
<h1>Homework</h1>
<blockquote>
<p>In the Trolley data—data(Trolley)—we saw how education level (modeled as
an ordered category) is associated with responses. Is this association causal? One plausible confound is that education is also associated with age, through a causal process: People are older when they finish school than when they begin it.
Reconsider the Trolley data in this light. Draw a DAG that represents hypothetical causal relationships among response, education, and age. Which statical model or models do you need to evaluate the causal influence of education on responses? Fit these models to the trolley data. What do you conclude about the causal relationships among these three variables?</p>
</blockquote>
<p>Let’s begin by drawing the DAG</p>
<pre class="r"><code>dag &lt;- dagitty(&quot; dag {
              Age -&gt; Education
              Education -&gt; Response
              Age -&gt; Response
               }&quot;)
drawdag(dag)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>According to our assumptions, we cannot evaluate the causal effect of Education on response without first performing statistical adjustments on our models by including Age. Otherwise, Education will pick up some of the effect of Age on response, thereby biasing our estimates. That is, there is a backdoor leading back to Education. To close it, we must include Age in our estimates. Our computer can confirm our reasoning:</p>
<pre class="r"><code>dagitty::adjustmentSets(dag, exposure = &quot;Education&quot;, outcome = &quot;Response&quot;)</code></pre>
<pre><code>##  { Age }</code></pre>
<pre class="r"><code>data(&quot;Trolley&quot;)
trolley_data &lt;- Trolley 
glimpse(trolley_data)</code></pre>
<pre><code>## Rows: 9,930
## Columns: 12
## $ case      &lt;fct&gt; cfaqu, cfbur, cfrub, cibox, cibur, cispe, fkaqu, fkboa, f...
## $ response  &lt;int&gt; 4, 3, 4, 3, 3, 3, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, ...
## $ order     &lt;int&gt; 2, 31, 16, 32, 4, 9, 29, 12, 23, 22, 27, 19, 14, 3, 18, 1...
## $ id        &lt;fct&gt; 96;434, 96;434, 96;434, 96;434, 96;434, 96;434, 96;434, 9...
## $ age       &lt;int&gt; 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1...
## $ male      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ edu       &lt;fct&gt; Middle School, Middle School, Middle School, Middle Schoo...
## $ action    &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, ...
## $ intention &lt;int&gt; 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...
## $ contact   &lt;int&gt; 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ story     &lt;fct&gt; aqu, bur, rub, box, bur, spe, aqu, boa, box, bur, car, sp...
## $ action2   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, ...</code></pre>
<p>Let’s begin by preparing our variables:</p>
<ul>
<li>age. We will model it as a continuous parameter.</li>
</ul>
<pre class="r"><code>trolley_data %&gt;% 
  mutate(age_std = (age - mean(age))/sd(age)) -&gt; trolley_data
trolley_data %&gt;% 
  ggplot(aes(age_std)) +
  geom_histogram(binwidth = 1, color = &quot;black&quot;, alpha = 0.5) +
  hrbrthemes::theme_ipsum_rc() +
  labs(title = &quot;Age distribution in the data&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<ul>
<li>education. We will model it as an ordered category.</li>
</ul>
<pre class="r"><code>levels(trolley_data$edu)</code></pre>
<pre><code>## [1] &quot;Bachelor&#39;s Degree&quot;    &quot;Elementary School&quot;    &quot;Graduate Degree&quot;     
## [4] &quot;High School Graduate&quot; &quot;Master&#39;s Degree&quot;      &quot;Middle School&quot;       
## [7] &quot;Some College&quot;         &quot;Some High School&quot;</code></pre>
<p>However, R has read automatically order the factors in alphabetical order. Let’s order them in the order we need</p>
<pre class="r"><code>trolley_data %&gt;% 
  mutate(edu_releveled = fct_relevel(edu, c(&quot;Elementary School&quot;, &quot;Middle School&quot;, &quot;Some High School&quot;,
                                            &quot;High School Graduate&quot;, &quot;Some College&quot;, &quot;Bachelor&#39;s Degree&quot;,
                                            &quot;Master&#39;s Degree&quot;, &quot;Graduate Degree&quot;))) -&gt; trolley_data_education_releveled
levels(trolley_data_education_releveled$edu_releveled)</code></pre>
<pre><code>## [1] &quot;Elementary School&quot;    &quot;Middle School&quot;        &quot;Some High School&quot;    
## [4] &quot;High School Graduate&quot; &quot;Some College&quot;         &quot;Bachelor&#39;s Degree&quot;   
## [7] &quot;Master&#39;s Degree&quot;      &quot;Graduate Degree&quot;</code></pre>
<p>Now, we can turn them into integers and we’ll know they will be kept in the order we need them to be:</p>
<pre class="r"><code>trolley_data_education_releveled %&gt;% 
  mutate(edu_int = as.integer(edu_releveled)) -&gt; trolley_data_model
trolley_data_model %&gt;% 
  count(edu_int, edu_releveled, edu)</code></pre>
<pre><code>## # A tibble: 8 x 4
##   edu_int edu_releveled        edu                      n
##     &lt;int&gt; &lt;fct&gt;                &lt;fct&gt;                &lt;int&gt;
## 1       1 Elementary School    Elementary School       60
## 2       2 Middle School        Middle School          120
## 3       3 Some High School     Some High School       420
## 4       4 High School Graduate High School Graduate   870
## 5       5 Some College         Some College          2460
## 6       6 Bachelor&#39;s Degree    Bachelor&#39;s Degree     3540
## 7       7 Master&#39;s Degree      Master&#39;s Degree       1410
## 8       8 Graduate Degree      Graduate Degree       1050</code></pre>
<p>Before we use the model, let’s verify that we haven’t missing values:</p>
<pre class="r"><code>trolley_data_model %&gt;% 
  nrow()</code></pre>
<pre><code>## [1] 9930</code></pre>
<pre class="r"><code>trolley_data_model %&gt;% 
  drop_na(response, intention, contact, action, edu_int) %&gt;% 
  nrow()</code></pre>
<pre><code>## [1] 9930</code></pre>
<p>There are no missing obs to worry about. As a last step, let’s see what we would get if weren’t performing statistical adjustments by the type of questions nor by the education level of the respondents:</p>
<pre class="r"><code>trolley_data_model %&gt;% 
  mutate(age = cut(age, 5)) %&gt;% 
  ggplot(aes(response, fill = age)) +
  geom_bar(position = &quot;dodge&quot;) +
   hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_viridis_d() +
  labs(title = &quot;Responses across age groups&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Let’s code and fit the model:</p>
<pre class="r"><code># data 
data_list_model_age_edu &lt;- list(
  R = trolley_data_model$response,
  action = trolley_data_model$action,
  intention = trolley_data_model$intention,
  contact = trolley_data_model$contact,
  E = as.integer(trolley_data_model$edu_int),
  age = trolley_data_model$age_std,
  alpha = rep(2.1, 7)
)
# model

model_edu_age &lt;- ulam(
  alist(
    R ~ ordered_logistic(phi, kappa),
    phi &lt;- bE*sum( delta_j[1:E] ) + bA*action + BI*intention + bC*contact + bAge*age,
    BI &lt;- bI + bIC*contact + bIA*action,
    kappa ~ normal(0, 0.5),
    c(bA, bC, bE, bAge, bI, bIA, bIC) ~ normal(0, 0.5),
    vector[8]: delta_j &lt;&lt;- append_row(0, delta),
    simplex[7]: delta ~ dirichlet(alpha)
),
  data = data_list_model_age_edu,
chains = 5, cores = 5
)</code></pre>
<pre class="r"><code>traceplot_ulam(model_edu_age)</code></pre>
<pre><code>## [1] 1000
## [1] 1
## [1] 1000</code></pre>
<pre><code>## Waiting to draw page 2 of 2</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-13-1.png" width="672" /><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
<p>The chains look healthy enough; although the number of effective samples seems terribly slow for the total effect of education. Also, there’s the Stan warning message. Maybe one should try to run the model a bit longer. Note that the paths, during warmup exclusively, wander around in some chains on some presumably not typical set parts of the parameter space. However, this transient like behavior quickly stops and it is never present during sampling.</p>
<pre class="r"><code>precis(model_edu_age, depth = 2)</code></pre>
<pre><code>##                 mean         sd        5.5%       94.5%    n_eff     Rhat4
## kappa[1] -2.41079724 0.08008173 -2.53238834 -2.28186016 1433.486 1.0030241
## kappa[2] -1.71592520 0.07836372 -1.83530499 -1.58602877 1422.368 1.0029700
## kappa[3] -1.12244527 0.07669297 -1.23758989 -0.99724029 1455.166 1.0030580
## kappa[4] -0.08839179 0.07558446 -0.20361705  0.03313442 1427.881 1.0028028
## kappa[5]  0.58225959 0.07613015  0.46483650  0.70557673 1460.744 1.0025920
## kappa[6]  1.48538767 0.07845632  1.36310661  1.61289488 1476.363 1.0021155
## bIC      -1.25888478 0.09742507 -1.41615638 -1.10376950 2210.084 0.9994927
## bIA      -0.45632654 0.07806976 -0.57602685 -0.32926599 1665.499 1.0026097
## bI       -0.26786128 0.05591145 -0.35483164 -0.17542612 1631.281 1.0010035
## bAge     -0.10582460 0.02015367 -0.13776804 -0.07347821 2436.341 1.0000958
## bE        0.28686613 0.08518368  0.15441031  0.42373704 1282.070 1.0028979
## bC       -0.32117901 0.06671697 -0.42921551 -0.21520022 2012.900 1.0000935
## bA       -0.45111584 0.05161547 -0.53360470 -0.36768085 1699.345 1.0010574
## delta[1]  0.12060601 0.07358242  0.02542701  0.25650507 3481.586 0.9989493
## delta[2]  0.13535415 0.08291252  0.02854077  0.28784516 3372.311 0.9996427
## delta[3]  0.08382673 0.05398496  0.01737981  0.18252533 3506.584 0.9996750
## delta[4]  0.05773466 0.04178795  0.01092082  0.13035862 1980.567 1.0012859
## delta[5]  0.43944635 0.11196141  0.26152465  0.61318064 1775.904 1.0006125
## delta[6]  0.07497453 0.05030383  0.01673176  0.16282714 2824.446 0.9986787
## delta[7]  0.08805757 0.05491970  0.02007558  0.18931847 3484.503 0.9986829</code></pre>
<p>Compared to the model that had no adjustment by age, the Education coefficient has changed. Whereas before the coefficient was negative, here it is positive. Thus, we conclude: 1) Due to change in the coefficient, we believe that indeed there is a path between education and age. 2) Indicating that higher education leads to respond higher in the scale, indicating that they see the moral actions as more permissible. 3) Also, older people seem to respond lower in the scale and thus considering the actions less morally permisible.</p>
<p>Let’s plot the predicted differences:</p>
<pre class="r"><code>samples &lt;- extract.samples(model_edu_age)
str(samples)</code></pre>
<pre><code>## List of 9
##  $ kappa: num [1:2500, 1:6] -2.42 -2.34 -2.36 -2.37 -2.53 ...
##  $ bIC  : num [1:2500(1d)] -1.31 -1.31 -1.41 -1.3 -1.39 ...
##  $ bIA  : num [1:2500(1d)] -0.548 -0.384 -0.719 -0.36 -0.396 ...
##  $ bI   : num [1:2500(1d)] -0.181 -0.294 -0.131 -0.255 -0.32 ...
##  $ bAge : num [1:2500(1d)] -0.0995 -0.1269 -0.1047 -0.1338 -0.0924 ...
##  $ bE   : num [1:2500(1d)] 0.172 0.392 0.265 0.283 0.161 ...
##  $ bC   : num [1:2500(1d)] -0.305 -0.246 -0.319 -0.299 -0.27 ...
##  $ bA   : num [1:2500(1d)] -0.346 -0.505 -0.352 -0.474 -0.444 ...
##  $ delta: num [1:2500, 1:7] 0.1113 0.0785 0.0169 0.0538 0.1207 ...
##  - attr(*, &quot;source&quot;)= chr &quot;ulam posterior: 2500 samples from model_edu_age&quot;</code></pre>
<p>Let’s add the zero to the delta:</p>
<pre class="r"><code>samples$delta &lt;- cbind(rep(0, 2500), samples$delta)</code></pre>
<p>Now, let’s write some functions to work with the samples from the posterior:</p>
<pre class="r"><code>calculate_phi &lt;- function(action, intention, contact, E, age, samples) {
  
  number_samples &lt;- 2500
  
  BI &lt;- vector(mode=&quot;numeric&quot;, length=number_samples)
  for ( i in 1:number_samples ) {
    BI[i] = samples$bI[i] + samples$bIC[i] * contact + samples$bIA[i] * action
  }
  
  phi &lt;- vector(mode=&quot;numeric&quot;, length=number_samples)
  
  for ( i in 1:number_samples ) {
    
        phi[i] = samples$bE[i] * sum(samples$delta[i, 1:E]) + samples$bA[i] * action  + BI[i] * intention + 
          samples$bC[i] * contact + samples$bAge[i] * age
  }
  phi
}


predict_model_per_obs &lt;- function(action, intention, contact, E, age, samples) {
  
  number_samples &lt;- 2500
  
  phi &lt;- calculate_phi(action, intention, contact, E, age, samples)
  
  predicted_response &lt;-  matrix(0, nrow = number_samples, ncol = 7)
  
  for ( i in 1:number_samples ) {
    
    for (col in 1:7) {
      predicted_response[i, col] &lt;- pordlogit(col, phi = phi[i], samples$kappa[i,])
    }

  }
  predicted_response
}

simulate_model_per_obs &lt;- function(action, intention, contact, E, age, samples) {
  
  number_samples &lt;- 2500
  
  sims &lt;- vector(mode=&quot;numeric&quot;, length=number_samples)
  
  phi &lt;- calculate_phi(action, intention, contact, E, age, samples)
  
  
  for (i in 1:number_samples) {
    
    sims[i] &lt;- rordlogit(1, phi[i], samples$kappa[i,])
    
  }
  
  sims
  
}</code></pre>
<pre class="r"><code>ages &lt;- -2:2
names(ages) &lt;- -2:2

ages %&gt;% 
  map_df(~simulate_model_per_obs(action = 1, intention = 1, contact = 0, E = 5, age = .x, samples)) %&gt;% 
  cbind(data.frame(sims = 1:2500)) %&gt;% 
  pivot_longer(-sims, names_to = &quot;age&quot;, values_to = &quot;response&quot;) %&gt;% 
  mutate(age = factor(age, levels = -2:2),
         response = factor(response)) %&gt;% 
  ggplot(aes(response, fill = age)) +
  geom_bar(position = &quot;dodge&quot;) +
  hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_viridis_d() +
  labs(title = &quot;Simulated responses across age groups&quot;,
       subtitle = &quot;Older people respond lower on the scale&quot;,
       fill = &quot;s.d. away from the mean&quot;,
       caption = &quot;Question with both action and intention, but no contact&quot;) +
  theme(legend.position = &quot;bottom&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>As we gauged from the coefficient, we predict that, on average, older people respond lower lower on the response scale. Above, for an action with both intention and contact, the difference is very clear: older people respond more often with lower values of moral permissibility, whereas younger people respond more often with higher values of moral permissibility.</p>
<p>Let’s check the difference across education levels:</p>
<pre class="r"><code>education_levels &lt;- 1:8
names(education_levels) &lt;- 1:8

education_levels %&gt;% 
  map_df(~simulate_model_per_obs(action = 1, intention = 1, contact = 0, E = .x, age = 0, samples)) %&gt;% 
  cbind(data.frame(sims = 1:2500)) %&gt;% 
  pivot_longer(-sims, names_to = &quot;education_level&quot;, values_to = &quot;response&quot;) %&gt;%
  mutate(education_level = factor(education_level, labels = c(&quot;Elementary School&quot;, &quot;Middle School&quot;, &quot;Some High School&quot;,
                                            &quot;High School Graduate&quot;, &quot;Some College&quot;, &quot;Bachelor&#39;s Degree&quot;,
                                            &quot;Master&#39;s Degree&quot;, &quot;Graduate School&quot;)),
         response = factor(response)) %&gt;% 
  ggplot(aes(response, fill = education_level)) +
  geom_bar(position = &quot;dodge&quot;) +
  hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_viridis_d() +
  theme(legend.position = &quot;bottom&quot;) +
  labs(title = &quot;Simulated responses across education levels&quot;,
       subtitle = &quot;More educated people tend to respond higher levels of moral permissibility&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>To conclude the question:</p>
<ul>
<li>Older people tend to assign lower levels of moral permissibility.</li>
<li>More educated people tend to assign higher levels of moral permisibility.</li>
<li>Age and education level seem correlated. Thus, without accounting for age, education level will pick up some of the effects of age on responses.</li>
</ul>
<blockquote>
<p>Consider one more variable in the Trolley data: Gender. Suppose that gender might influence education as well as response directly. Draw the DAG now that includes response, education, age, and gender. Using only the DAG, is it possible that the inferences from Problem 1 are confounded by gender? If so,define any additional models you need to infer the causal influence of education on response. What do you conclude?</p>
</blockquote>
<pre class="r"><code>dag &lt;- dagitty(&quot; dag {
              Age -&gt; Education
              Education -&gt; Response
              Age -&gt; Response
              Gender -&gt; Education
              Gender -&gt; Response
               }&quot;)
drawdag(dag)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Yes, according to our current DAG, inferences from problem 1 are confounded. By including Education in our statistical adjustments, we are conditioning on a collider and thereby opening a backdoor: Education will pick up the effect of gender on response. Therefore, if we wish to infer the influence of education on response, we must perform a statistical adjustment with Gender.</p>
<pre class="r"><code>dagitty::adjustmentSets(dag, exposure = &quot;Education&quot;, outcome = &quot;Response&quot;)</code></pre>
<pre><code>##  { Age, Gender }</code></pre>
<p>We will include gender with an index variable:</p>
<pre class="r"><code>trolley_data_model %&gt;% 
  mutate(gender_id = factor(male + 1)) -&gt; trolley_data_model

data_list_model_age_edu &lt;- list(
  R = trolley_data_model$response,
  action = trolley_data_model$action,
  intention = trolley_data_model$intention,
  contact = trolley_data_model$contact,
  E = as.integer(trolley_data_model$edu_int),
  age = trolley_data_model$age_std,
  gender_id = trolley_data_model$gender_id,
  alpha = rep(2.1, 7)
)</code></pre>
<p>Let’s first try to gauge what we would get if we weren’t performing statistical adjustment by other covariates:</p>
<pre class="r"><code>trolley_data_model %&gt;%
  mutate(gender_id = factor(gender_id, labels = c(&quot;Women&quot;, &quot;Men&quot;))) %&gt;% 
  ggplot(aes(factor(response), fill = gender_id)) +
  geom_bar(position = &quot;dodge&quot;) +
  hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_viridis_d() +
  theme(legend.position = &quot;bottom&quot;) +
  labs(title = &quot;Distribution of responses across Men and Women&quot;,
       subtitle = &quot;Men do seem to response more often higher values&quot;,
       fill = &quot;Gender&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Now, let’s fit the model:</p>
<pre class="r"><code>model_edu_age_gender &lt;- ulam(
  alist(
    R ~ ordered_logistic(phi, kappa),
    phi &lt;- bE*sum( delta_j[1:E] ) + bA*action + BI*intention + bC*contact + bAge*age + bGender[gender_id],
    BI &lt;- bI + bIC*contact + bIA*action,
    kappa ~ normal(0, 0.5),
    c(bA, bC, bE, bAge, bI, bIA, bIC) ~ normal(0, 0.5),
    bGender[gender_id] ~ normal(0, 0.5),
    vector[8]: delta_j &lt;&lt;- append_row(0, delta),
    simplex[7]: delta ~ dirichlet(alpha)
),
  data = data_list_model_age_edu,
chains = 5, cores = 5
)</code></pre>
<p>Let’s check the traceplots of our chains:</p>
<pre class="r"><code>traceplot(model_edu_age_gender)</code></pre>
<pre><code>## [1] 1000
## [1] 1
## [1] 1000</code></pre>
<pre><code>## Waiting to draw page 2 of 2</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-25-1.png" width="672" /><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-25-2.png" width="672" /></p>
<pre class="r"><code>precis(model_edu_age_gender, depth = 2, omit = &quot;kappa&quot;)</code></pre>
<pre><code>##                   mean         sd        5.5%      94.5%     n_eff     Rhat4
## bIC        -1.26463477 0.09604795 -1.41897412 -1.1118430 1422.3087 1.0048055
## bIA        -0.44462412 0.08145432 -0.57122174 -0.3127680 1433.0599 1.0019286
## bI         -0.28647079 0.05720406 -0.37777373 -0.1961128 1208.1618 1.0051570
## bAge       -0.07306219 0.02159846 -0.10794471 -0.0398190 1525.6215 0.9993298
## bE          0.05529410 0.15282322 -0.20301174  0.2755427  844.3541 1.0034503
## bC         -0.33920229 0.06782698 -0.44925757 -0.2331210 1409.6747 1.0031678
## bA         -0.47015143 0.05431663 -0.55594746 -0.3846352 1410.2531 1.0032477
## bGender[1]  0.24894060 0.20035798 -0.07387531  0.5578567 1022.1282 1.0037941
## bGender[2]  0.81088553 0.20094705  0.48214779  1.1184397  977.5348 1.0035666
## delta[1]    0.14480014 0.08846509  0.03327050  0.3089479 2243.1085 0.9988021
## delta[2]    0.14307415 0.08821917  0.02967004  0.3035008 2800.8730 1.0014399
## delta[3]    0.13042252 0.08671126  0.02458029  0.2877414 2616.7244 0.9994532
## delta[4]    0.12011272 0.08794689  0.01962224  0.2895106 1435.2353 1.0013360
## delta[5]    0.21671365 0.15139371  0.02722828  0.4771553  824.8364 1.0027751
## delta[6]    0.11728880 0.07800550  0.02355358  0.2659605 2101.7218 1.0000965
## delta[7]    0.12758801 0.07936103  0.02748344  0.2747106 2982.1574 0.9986766</code></pre>
<p>It seems that the coefficient for men is considerably higher than the coefficient for women. That is, on the relative scale, women are more likely to give lower moral permissibility to the different situations. Interestingly, the coefficient for Education has greatly reduced, and now it encompasses zero right in the middle. Therefore, by performing statistical adjustment with gender, the Education coefficient has greatly decreased.</p>
<p>Indeed, let’s check the difference across education levels.</p>
<p>Let’s modify our functions to simulate from our model now including a gender intercept:</p>
<pre class="r"><code>calculate_phi &lt;- function(action, intention, contact, E, age, samples, gender) {
  
  number_samples &lt;- 2500
  
  BI &lt;- vector(mode=&quot;numeric&quot;, length=number_samples)
  for ( i in 1:number_samples ) {
    BI[i] = samples$bI[i] + samples$bIC[i] * contact + samples$bIA[i] * action
  }
  
  phi &lt;- vector(mode=&quot;numeric&quot;, length=number_samples)
  
  for ( i in 1:number_samples ) {
    
        phi[i] = samples$bE[i] * sum(samples$delta[i, 1:E]) + samples$bA[i] * action  + BI[i] * intention + 
          samples$bC[i] * contact + samples$bAge[i] * age + samples$bGender[i, gender]
  }
  phi
}

simulate_model_per_obs &lt;- function(action, intention, contact, E, age, samples, gender) {
  
  number_samples &lt;- 2500
  
  sims &lt;- vector(mode=&quot;numeric&quot;, length=number_samples)
  
  phi &lt;- calculate_phi(action, intention, contact, E, age, samples, gender)
  
  
  for (i in 1:number_samples) {
    
    sims[i] &lt;- rordlogit(1, phi[i], samples$kappa[i,])
    
  }
  
  sims
  
}</code></pre>
<p>Let’s extract samples:</p>
<pre class="r"><code>samples &lt;- extract.samples(model_edu_age_gender)
samples$delta &lt;- cbind(rep(0, 2500), samples$delta)</code></pre>
<p>And finally simulate:</p>
<pre class="r"><code>education_levels &lt;- 1:8
names(education_levels) &lt;- 1:8

education_levels %&gt;% 
  map_df(~simulate_model_per_obs(action = 1, intention = 1, contact = 0, E = .x, age = 0, samples, gender = 1)) %&gt;% 
  cbind(data.frame(sims = 1:2500)) %&gt;% 
  pivot_longer(-sims, names_to = &quot;education_level&quot;, values_to = &quot;response&quot;) %&gt;%
  mutate(education_level = factor(education_level, labels = c(&quot;Elementary School&quot;, &quot;Middle School&quot;, &quot;Some High School&quot;,
                                            &quot;High School Graduate&quot;, &quot;Some College&quot;, &quot;Bachelor&#39;s Degree&quot;,
                                            &quot;Master&#39;s Degree&quot;, &quot;Graduate School&quot;)),
         response = factor(response)) %&gt;% 
  ggplot(aes(response, fill = education_level)) +
  geom_bar(position = &quot;dodge&quot;) +
  hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_viridis_d() +
  theme(legend.position = &quot;bottom&quot;) +
  labs(title = &quot;Simulated responses across education levels: Women&quot;,
       subtitle = &quot;Adjusting by gender, education&#39;s influence is negligible&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>As expected, now that we are performing a statistical adjustment by Gender, the influence of education level on response has greatly reduced. In fact, it has reduced so much that our model predicts barely any difference response levels across educations. Let’s do the same plot but for men:</p>
<pre class="r"><code>education_levels %&gt;% 
  map_df(~simulate_model_per_obs(action = 1, intention = 1, contact = 0, E = .x, age = 0, samples, gender = 2)) %&gt;% 
  cbind(data.frame(sims = 1:2500)) %&gt;% 
  pivot_longer(-sims, names_to = &quot;education_level&quot;, values_to = &quot;response&quot;) %&gt;%
  mutate(education_level = factor(education_level, labels = c(&quot;Elementary School&quot;, &quot;Middle School&quot;, &quot;Some High School&quot;,
                                            &quot;High School Graduate&quot;, &quot;Some College&quot;, &quot;Bachelor&#39;s Degree&quot;,
                                            &quot;Master&#39;s Degree&quot;, &quot;Graduate School&quot;)),
         response = factor(response)) %&gt;% 
  ggplot(aes(response, fill = education_level)) +
  geom_bar(position = &quot;dodge&quot;) +
  hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_viridis_d() +
  theme(legend.position = &quot;bottom&quot;) +
  labs(title = &quot;Simulated responses across education levels: Men&quot;,
       subtitle = &quot;Adjusting by gender, education&#39;s influence is negligible&quot;,
       caption = &quot;Question with both action and intention but w/o no contact&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>It seems that Gender is driving the variation in responses in the sample. To see this, let’s simulate the differnce by gender for the most highly educated and older people in the sample:</p>
<pre class="r"><code>gender &lt;- 1:2
names(gender) &lt;- c(&quot;Women&quot;, &quot;Men&quot;)

gender %&gt;% 
  map_df(~simulate_model_per_obs(action = 1, intention = 1, contact = 0, E = 8, age = 2, samples, gender = .x)) %&gt;% 
  cbind(data.frame(sims = 1:2500)) %&gt;% 
  pivot_longer(-sims, names_to = &quot;gender&quot;, values_to = &quot;response&quot;) %&gt;% 
  mutate(gender = factor(gender)) %&gt;% 
  ggplot(aes(factor(response), fill = gender)) +
  geom_bar(position = &quot;dodge&quot;) +
  hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_viridis_d() +
  theme(legend.position = &quot;bottom&quot;) +
  labs(title = &quot;Simulated predictions across Genders&quot;,
       subtitle = &quot;Women tend to give lower responses. Men higher responses&quot;,
       caption = &quot;Question with action and intention but no contact&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>Let’s plot our simulations for yet another situation, this time a situation with both action, intent and contact:</p>
<pre class="r"><code>gender %&gt;% 
  map_df(~simulate_model_per_obs(action = 1, intention = 1, contact = 1, E = 8, age = 2, samples, gender = .x)) %&gt;% 
  cbind(data.frame(sims = 1:2500)) %&gt;% 
  pivot_longer(-sims, names_to = &quot;gender&quot;, values_to = &quot;response&quot;) %&gt;% 
  mutate(gender = factor(gender)) %&gt;% 
  ggplot(aes(factor(response), fill = gender)) +
  geom_bar(position = &quot;dodge&quot;) +
  hrbrthemes::theme_ipsum_rc(grid = &quot;Y&quot;) +
  scale_fill_viridis_d() +
  theme(legend.position = &quot;bottom&quot;) +
  labs(title = &quot;Simulated predictions across Genders&quot;,
       subtitle = &quot;Women tend to give lower responses. Men higher responses&quot;,
       caption = &quot;Question with action,intention and contact&quot;)</code></pre>
<p><img src="/post/2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Therefore, we can conclude that, among the covariates studied, the greatest variation across responses is found on gender. Regardless of education level, women, on average, regard the different acts as much less morally permissible than men.</p>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-david-salazar-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

