{
  "hash": "93cb24cbfe5339eca2d6e2b26c16cf0b",
  "result": {
    "markdown": "---\ntitle: 'Statistical Rethinking: Week 7'\nauthor: ''\ndate: '2020-05-24'\nslug: statistical-rethinking-week-7\ncategories: []\ntags: []\n---\n\n\n\n\n# Statistical Rethinking: Week 7\n\nThis week paid off. All the hard work of understanding link functions, HMC flavored Monte-Carlo, and GLM allowed to study more complex models. To keep using Richard's metaphor: it allowed us to study monsters: models with different parts made out of different models. In particular, Zero Inflated Models and Ordered Categories. \n\n# Homework\n\n> In the Trolley data—data(Trolley)—we saw how education level (modeled as\nan ordered category) is associated with responses. Is this association causal? One plausible confound is that education is also associated with age, through a causal process: People are older when they finish school than when they begin it.\nReconsider the Trolley data in this light. Draw a DAG that represents hypothetical causal relationships among response, education, and age. Which statical model or models do you need to evaluate the causal influence of education on responses? Fit these models to the trolley data. What do you conclude about the causal relationships among these three variables?\n\nLet's begin by drawing the DAG\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nAccording to our assumptions, we cannot evaluate the causal effect of Education on response without first performing statistical adjustments on our models by including Age. Otherwise, Education will pick up some of the effect of Age on response, thereby biasing our estimates. That is, there is a backdoor leading back to Education. To close it, we must include Age in our estimates. Our computer can confirm our reasoning: \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n{ Age }\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nRows: 9,930\nColumns: 12\n$ case      <fct> cfaqu, cfbur, cfrub, cibox, cibur, cispe, fkaqu, fkboa, fkbo…\n$ response  <int> 4, 3, 4, 3, 3, 3, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 3, …\n$ order     <int> 2, 31, 16, 32, 4, 9, 29, 12, 23, 22, 27, 19, 14, 3, 18, 15, …\n$ id        <fct> 96;434, 96;434, 96;434, 96;434, 96;434, 96;434, 96;434, 96;4…\n$ age       <int> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, …\n$ male      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ edu       <fct> Middle School, Middle School, Middle School, Middle School, …\n$ action    <int> 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, …\n$ intention <int> 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, …\n$ contact   <int> 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ story     <fct> aqu, bur, rub, box, bur, spe, aqu, boa, box, bur, car, spe, …\n$ action2   <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, …\n```\n:::\n:::\n\n\nLet's begin by preparing our variables: \n\n- age. We will model it as a continuous parameter. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n- education. We will model it as an ordered category. \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Bachelor's Degree\"    \"Elementary School\"    \"Graduate Degree\"     \n[4] \"High School Graduate\" \"Master's Degree\"      \"Middle School\"       \n[7] \"Some College\"         \"Some High School\"    \n```\n:::\n:::\n\n\nHowever, R has read automatically order the factors in alphabetical order. Let's order them in the order we need\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Elementary School\"    \"Middle School\"        \"Some High School\"    \n[4] \"High School Graduate\" \"Some College\"         \"Bachelor's Degree\"   \n[7] \"Master's Degree\"      \"Graduate Degree\"     \n```\n:::\n:::\n\n\nNow, we can turn them into integers and we'll know they will be kept in the order we need them to be:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n  edu_int        edu_releveled                  edu    n\n1       1    Elementary School    Elementary School   60\n2       2        Middle School        Middle School  120\n3       3     Some High School     Some High School  420\n4       4 High School Graduate High School Graduate  870\n5       5         Some College         Some College 2460\n6       6    Bachelor's Degree    Bachelor's Degree 3540\n7       7      Master's Degree      Master's Degree 1410\n8       8      Graduate Degree      Graduate Degree 1050\n```\n:::\n:::\n\n\nBefore we use the model, let's verify that we haven't missing values:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9930\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9930\n```\n:::\n:::\n\n\nThere are no missing obs to worry about. As a last step, let's see what we would get if weren't performing statistical adjustments by the type of questions nor by the education level of the respondents:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nLet's code and fit the model:\n\n\n::: {.cell hash='2020-05-24-statistical-rethinking-week-7_cache/html/unnamed-chunk-12_2c92b4e946804e440d7d9ba33f70e43f'}\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 5 parallel chains, with 1 thread(s) per chain...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 2 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 3 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 4 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 5 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 5 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 2 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 1 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 5 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 5 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 4 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 5 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 5 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 5 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 5 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 5 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 5 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 1221.1 seconds.\nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 1227.9 seconds.\nChain 5 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 1237.8 seconds.\nChain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 5 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 5 finished in 1273.5 seconds.\nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 1281.1 seconds.\n\nAll 5 chains finished successfully.\nMean chain execution time: 1248.3 seconds.\nTotal execution time: 1281.4 seconds.\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\n\nThe chains look healthy enough; although the number of effective samples seems terribly slow for the total effect of education. Also, there's the Stan warning message. Maybe one should try to run the model a bit longer. Note that the paths, during warmup exclusively, wander around in some chains on some presumably not typical set parts of the parameter space. However, this transient like behavior quickly stops and it is never present during sampling. \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n                mean         sd        5.5%       94.5%    n_eff     Rhat4\nkappa[1] -2.40980142 0.07631585 -2.53447555 -2.29064580 1209.842 1.0005148\nkappa[2] -1.71487666 0.07426259 -1.83246110 -1.59697275 1196.452 1.0004060\nkappa[3] -1.12127199 0.07296840 -1.23552065 -1.00379345 1206.023 1.0003597\nkappa[4] -0.08792258 0.07183468 -0.19972794  0.02959908 1223.252 1.0004976\nkappa[5]  0.58314558 0.07241557  0.46958480  0.69982295 1243.306 1.0004691\nkappa[6]  1.48641206 0.07499928  1.36691670  1.60971435 1294.911 1.0003917\nbIC      -1.25482654 0.09641519 -1.40823995 -1.10109895 1592.040 1.0033685\nbIA      -0.45191163 0.07873589 -0.58032757 -0.32724275 1531.498 1.0020863\nbI       -0.27130468 0.05617661 -0.36041274 -0.18256063 1375.417 1.0045916\nbAge     -0.10612173 0.01960340 -0.13762106 -0.07446687 2881.420 0.9993960\nbE        0.29021678 0.07860667  0.17066931  0.41466910 1235.761 1.0002091\nbC       -0.32300800 0.06847975 -0.43346993 -0.21317939 1783.069 1.0027797\nbA       -0.45373700 0.05189077 -0.53737928 -0.36990367 1866.863 1.0013140\ndelta[1]  0.11883917 0.07300123  0.02770316  0.25202713 3703.875 0.9998998\ndelta[2]  0.13664603 0.07902661  0.03497736  0.27997437 3296.719 0.9997046\ndelta[3]  0.08227563 0.05221710  0.01903524  0.18013100 3530.285 0.9999000\ndelta[4]  0.05681726 0.04121216  0.01066274  0.12948807 2572.711 1.0002676\ndelta[5]  0.44516349 0.10474074  0.27986451  0.60637022 2219.672 0.9985959\ndelta[6]  0.07323684 0.04816609  0.01594991  0.16075218 2587.867 0.9995390\ndelta[7]  0.08702158 0.05633486  0.01825699  0.18928007 3123.487 0.9989435\n```\n:::\n:::\n\n\nCompared to the model that had no adjustment by age, the Education coefficient has changed. Whereas before the coefficient was negative, here it is positive. Thus, we conclude: 1) Due to change in the coefficient, we believe that indeed there is a path between education and age. 2) Indicating that higher education leads to respond higher in the scale, indicating that they see the moral actions as more permissible. 3) Also, older people seem to respond lower in the scale and thus considering the actions less morally permisible. \n\nLet's plot the predicted differences:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nList of 9\n $ kappa: num [1:2500, 1:6] -2.47 -2.38 -2.52 -2.42 -2.38 ...\n $ bIC  : num [1:2500(1d)] -1.13 -1.24 -1.17 -1.19 -1.16 ...\n $ bIA  : num [1:2500(1d)] -0.391 -0.615 -0.439 -0.41 -0.531 ...\n $ bI   : num [1:2500(1d)] -0.373 -0.21 -0.328 -0.238 -0.31 ...\n $ bAge : num [1:2500(1d)] -0.131 -0.115 -0.113 -0.105 -0.132 ...\n $ bE   : num [1:2500(1d)] 0.31 0.279 0.358 0.218 0.281 ...\n $ bC   : num [1:2500(1d)] -0.346 -0.343 -0.374 -0.39 -0.316 ...\n $ bA   : num [1:2500(1d)] -0.473 -0.43 -0.49 -0.492 -0.324 ...\n $ delta: num [1:2500, 1:7] 0.065 0.1331 0.0247 0.1584 0.0516 ...\n - attr(*, \"source\")= chr \"ulam posterior: 2500 samples from object\"\n```\n:::\n:::\n\n\nLet's add the zero to the delta:\n\n\n::: {.cell}\n\n:::\n\n\nNow, let's write some functions to work with the samples from the posterior:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nAs we gauged from the coefficient, we predict that, on average, older people respond lower lower on the response scale. Above, for an action with both intention and contact, the difference is very clear: older people respond more often with lower values of moral permissibility, whereas younger people respond more often with higher values of moral permissibility. \n\nLet's check the difference across education levels:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nTo conclude the question:\n\n- Older people tend to assign lower levels of moral permissibility. \n- More educated people tend to assign higher levels of moral permisibility. \n- Age and education level seem correlated. Thus, without accounting for age, education level will pick up some of the effects of age on responses. \n\n> Consider one more variable in the Trolley data: Gender. Suppose that gender might influence education as well as response directly. Draw the DAG now that includes response, education, age, and gender. Using only the DAG, is it possible that the inferences from Problem 1 are confounded by gender? If so,define any additional models you need to infer the causal influence of education on response. What do you conclude?\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nYes, according to our current DAG, inferences from problem 1 are confounded. By including Education in our statistical adjustments, we are conditioning on a collider and thereby opening a backdoor: Education will pick up the effect of gender on response. Therefore, if we wish to infer the influence of education on response, we must perform a statistical adjustment with Gender.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n{ Age, Gender }\n```\n:::\n:::\n\n\nWe will include gender with an index variable:\n\n\n::: {.cell}\n\n:::\n\n\nLet's first try to gauge what we would get if we weren't performing statistical adjustment by other covariates:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nNow, let's fit the model:\n\n\n::: {.cell hash='2020-05-24-statistical-rethinking-week-7_cache/html/unnamed-chunk-24_2458bde99f63dd5dbeedd3249d72cf2a'}\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 5 parallel chains, with 1 thread(s) per chain...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 2 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 3 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 5 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 4 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 5 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 2 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 5 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 1 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 4 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 5 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 5 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 5 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 5 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 5 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 5 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 5 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 5 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 5 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 5 finished in 2405.7 seconds.\nChain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 2421.8 seconds.\nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 2500.8 seconds.\nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 2515.9 seconds.\nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 2541.7 seconds.\n\nAll 5 chains finished successfully.\nMean chain execution time: 2477.2 seconds.\nTotal execution time: 2542.1 seconds.\n```\n:::\n:::\n\n\nLet's check the traceplots of our chains:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n                  mean         sd        5.5%       94.5%     n_eff     Rhat4\nbIC        -1.26222698 0.09563927 -1.41074770 -1.11361000 1474.4962 1.0029517\nbIA        -0.44224902 0.07749018 -0.56902660 -0.32144160 1379.1919 1.0011014\nbI         -0.28783297 0.05548265 -0.37528620 -0.19835261 1184.6262 1.0019602\nbAge       -0.07248551 0.02178785 -0.10676978 -0.03744601 1256.6172 0.9998830\nbE          0.04806116 0.15049454 -0.20515563  0.26088915  633.9650 1.0010820\nbC         -0.34144399 0.06682613 -0.44986452 -0.23195024 1486.2202 1.0018834\nbA         -0.47192368 0.05198801 -0.55570593 -0.38783936 1430.7327 1.0002398\nbGender[1]  0.25767990 0.19853134 -0.05838659  0.57397892  873.4987 1.0006516\nbGender[2]  0.82169908 0.19885860  0.50228403  1.13746555  813.2591 1.0004183\ndelta[1]    0.14271785 0.09071624  0.02994543  0.30946166 2765.3540 0.9993168\ndelta[2]    0.14430729 0.08713521  0.03617260  0.30389157 2700.6726 0.9995506\ndelta[3]    0.13050518 0.08342718  0.03009101  0.28879109 1870.8427 1.0001615\ndelta[4]    0.12275620 0.08961734  0.02284280  0.29555093 1355.8506 0.9997193\ndelta[5]    0.21254299 0.15103173  0.02559998  0.48118750  671.0591 1.0024846\ndelta[6]    0.11936824 0.08260875  0.02197871  0.27901172 1602.1946 1.0031488\ndelta[7]    0.12780225 0.08041071  0.02754787  0.27423736 3116.7440 0.9997262\n```\n:::\n:::\n\n\nIt seems that the coefficient for men is considerably higher than the coefficient for women. That is, on the relative scale, women are more likely to give lower moral permissibility to the different situations. Interestingly, the coefficient for Education has greatly reduced, and now it encompasses zero right in the middle. Therefore, by performing statistical adjustment with gender, the Education coefficient has greatly decreased.\n\nIndeed, let's check the difference across education levels.\n\nLet's modify our functions to simulate from our model now including a gender intercept:\n\n\n::: {.cell}\n\n:::\n\n\n\nLet's extract samples:\n\n\n::: {.cell}\n\n:::\n\n\nAnd finally simulate:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nAs expected, now that we are performing a statistical adjustment by Gender, the influence of education level on response has greatly reduced. In fact, it has reduced so much that our model predicts barely any difference response levels across educations. Let's do the same plot but for men:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\nIt seems that Gender is driving the variation in responses in the sample. To see this, let's simulate the differnce by gender for the most highly educated and older people in the sample:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nLet's plot our simulations for yet another situation, this time a situation with both action, intent and contact:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2020-05-24-statistical-rethinking-week-7_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\nTherefore, we can conclude that, among the covariates studied, the greatest variation across responses is found on gender. Regardless of education level, women, on average, regard the different acts as much less morally permissible than men. \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}