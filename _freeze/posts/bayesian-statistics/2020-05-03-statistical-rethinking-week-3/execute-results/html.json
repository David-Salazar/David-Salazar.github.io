{
  "hash": "7c76ea892553b8dd565be2a721389292",
  "result": {
    "markdown": "---\ntitle: 'Statistical Rethinking: Week 3'\nauthor: ''\ndate: '2020-05-03'\nslug: statistical-rethinking-week-3\ncategories: []\ntags: []\naliases: \n  - ../../2020/05/03/statistical-rethinking-week-3/\n---\n\n\n\n\n\n# Statistical Rethinking: Week 3\n\nWeek 3 gave the most interesting discussion of multiple regression. Why isn't it enough with univariate regression? It allows us to disentagle two types of mistakes:\n\n- Spurious correlation between the predictor and independent variable.\n- A masking relationship between two explanatory variables. \n\nIt also started to introduce DAGs and how they are an incredible tool for thinking before fitting. Specially, it managed to convince me the frequent strategy of tossing everything into a multiple regression and hoping for the ebst is a recipe for disaster.  \n\n## Problems Chapter 5\n\n### Medium\n\n> Invent your own example of a spurious correlation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_real <- rnorm(1000)\n# spurious is correlated with real\nx_spur <- rnorm(1000, x_real)\n# outcome variable is only correlated with x_real\ny <- rnorm(1000, x_real)\ndata <- data.frame(y, x_real, x_spur)\n```\n:::\n\n\nThus, when we analyze the relationship between `x_spur` and `y`, it may seem as if there is a relationship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit the model\nmodel_spurious <- quap(\n  alist(\n    y ~ dnorm(mu, sigma),\n    mu <- a + b* x_spur,\n    a ~ dnorm(0, 1),\n    b ~ dnorm(0, 1),\n    sigma ~ dunif(0, 2)\n  ),\n  data = data\n)\n\n# sample from posterior\nsamples_spurious <- extract.samples(model_spurious)\n# get samples for slope\ncoefficient_spurious <- samples_spurious$b\n\nprecis(model_spurious)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             mean         sd        5.5%     94.5%\na     -0.01397705 0.03926831 -0.07673539 0.0487813\nb      0.48773043 0.02780489  0.44329284 0.5321680\nsigma  1.24242979 0.02778322  1.19802684 1.2868328\n```\n:::\n:::\n\n\nWhereas when we fit a multiple regression with both coefficients, the relationship should dissapear:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit the model\nmodel_with_real <- quap(\n  alist(\n    y ~ dnorm(mu, sigma),\n    mu <- a + b* x_spur + c* x_real ,\n    a ~ dnorm(0, 1),\n    b ~ dnorm(0, 1),\n    c ~ dnorm(0, 1),\n    sigma ~ dunif(0, 2)\n  ),\n  data = data\n)\n\n# sample from posterior\nsamples_with_real <- extract.samples(model_with_real)\n\n# get samples for slope\ncoefficient_with_real <- samples_with_real$b\n\nprecis(model_with_real)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              mean         sd        5.5%      94.5%\na     -0.003852203 0.03252227 -0.05582908 0.04812467\nb     -0.017186891 0.03297004 -0.06987938 0.03550560\nc      0.994250135 0.04646359  0.91999235 1.06850792\nsigma  1.028634063 0.02299992  0.99187575 1.06539238\n```\n:::\n:::\n\n\nTo make the comparison more obvious, let's plot a `ggridge` with the samples from the different models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(controlling_by_real = coefficient_with_real,\n           not_controlling = coefficient_spurious,\n           sample = seq(1, 10000)) %>% \n  pivot_longer(-sample) %>% \n  ggplot(aes(x = value, fill = name)) +\n    geom_histogram(color = \"black\", alpha = 0.7,\n                   binwidth = 0.01) +\n    hrbrthemes::theme_ipsum_rc(grid = \"X\") +\n    theme(legend.position = \"bottom\") +\n    scale_fill_viridis_d() +\n    labs(fill = \"\",\n         title = \"Multiple regression identifies spurious correlation\",\n         subtitle = \"Controlling and not controlling for real relationship\",\n         x = \"Slope's value\",\n         caption = \"Samples from the posterior for 2 different models. \")\n```\n\n::: {.cell-output-display}\n![](2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n> Invent your own example of a masked relationship\n\nFirst, let's simulate the data such that:\n\n- The outcome is correlated with both variables, but in opposite directions. \n- Both predictors are correlated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nx_one <- rnorm(1000)\n# relation between explanatory variables\nx_two <- rnorm(1000, x_one)\n# outcome is related to both\n# but in opposite directions\ny <- rnorm(1000, x_one - x_two)\ndata <- data.frame(y, x_one, x_two)\n```\n:::\n\n\nNow, let's fit two univariate models. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit the model that masks x_one\nmodel_mask_one <- quap(\n  alist(\n    y ~ dnorm(mu, sigma),\n    mu <- a + one* x_one,\n    a ~ dnorm(0, 1),\n    one ~ dnorm(0, 1),\n    sigma ~ dunif(0, 2)\n  ),\n  data = data\n)\n# fit the model that masks x_two\nmodel_mask_two <- quap(\n  alist(\n    y ~ dnorm(mu, sigma),\n    mu <- a + two* x_two,\n    a ~ dnorm(0, 1),\n    two ~ dnorm(0, 1),\n    sigma ~ dunif(0, 2)\n  ),\n  data = data\n)\n```\n:::\n\n\nThen, we can fit the multivariate model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_unmasking <- quap(\n  alist(\n    y ~ dnorm(mu, sigma),\n    mu <- a + one* x_one + two*x_two,\n    a ~ dnorm(0, 1),\n    one ~ dnorm(0, 1),\n    two ~ dnorm(0, 1),\n    sigma ~ dunif(0, 2)\n  ),\n  data = data\n)\n```\n:::\n\n\nLet's visualize how our estimates have changed once we have included both variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\none_masked <- extract.samples(model_mask_one)$one\none_unmasked <- extract.samples(model_unmasking)$one\n\ndata.frame(sample = 1:10000,\n           one_masked, \n           one_unmasked) %>% \n  pivot_longer(-sample) %>% \n  ggplot(aes(x = value, fill = name)) +\n    geom_histogram(color = \"black\", alpha = 0.7,\n                   binwidth = 0.01) +\n    hrbrthemes::theme_ipsum_rc(grid = \"X\") +\n    theme(legend.position = \"bottom\") +\n    scale_fill_viridis_d() +\n  labs(fill = \"\",\n       title = \"Multiple regression unmasks true relationship\",\n       caption = \"Samples from the posterior of different models.\",\n       x = \"Slope\")\n```\n\n::: {.cell-output-display}\n![](2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nWhereas the univariate regression, due to the unobserved variable's effect, cannot reliably estimate the coefficient, multiple regression does the unmasking. Once we control for the correlation between the explanatory variables, the positive relationship between the first and the outcome variable is revealed. \n\nFor the other variable, that is negatively correlated with the outcome, we expect the opposite effect:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntwo_masked <- extract.samples(model_mask_two)$two\ntwo_unmasked <- extract.samples(model_unmasking)$two\n\ndata.frame(sample = 1:10000,\n           two_masked, \n           two_unmasked) %>% \n  pivot_longer(-sample) %>% \n  ggplot(aes(x = value, fill = name)) +\n    geom_histogram(color = \"black\", alpha = 0.7,\n                   binwidth = 0.01) +\n    hrbrthemes::theme_ipsum_rc(grid = \"X\") +\n    theme(legend.position = \"bottom\") +\n    scale_fill_viridis_d() +\n  labs(fill = \"\",\n       title = \"Multiple regression unmasks true relationship\",\n       caption = \"Samples from the posterior of different models.\",\n       x = \"Slope\")\n```\n\n::: {.cell-output-display}\n![](2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nJust as expected, multiple regression helps us unmask the true relationship. Before, due to the correlation between one and two, we were underestimating the magnitude of the relationship. Once we include one in the regression, we can estimate the true effect. \n\n# Homework Week 3\n\nThe foxes data. Let's start working with the proposed DAG:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"foxes\")\n\nfoxes %>% \n  mutate(avgfood = (avgfood - mean(avgfood))/ sd(avgfood),\n         groupsize = (groupsize - mean(groupsize)) / sd(groupsize),\n         area = (area - mean(area)) / sd(area),\n         weight = (weight - mean(weight)) / sd(weight)) -> foxes_scaled\n\ndag_foxes <- dagitty(\"dag {\n                     area -> avgfood\n                     avgfood -> groupsize\n                     avgfood -> weight\n                     groupsize -> weight\n}\")\n\ndrawdag(dag_foxes)\n```\n\n::: {.cell-output-display}\n![](2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n> Use a model to infer the total causal influence of area on weight. \n\nGiven the DAG, we only need to *run an unviariate regression to infer the causal effect of area on weight*. Why? Because that there are only two connections from area to weight and none of them are backdoor connections. Thus, were we to condition on avgfood, we would \"block\" the pipe that leads towards weight, thus nullyfing the effect that area has on weight. Likewise with groupisze. That is, we would be incurring on **post-treatment bias**.\n\nWe could confirm that we do not need to control for any other variable with the `dagitty` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadjustmentSets(dag_foxes, exposure = \"area\", outcome = \"weight\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n {}\n```\n:::\n:::\n\n\n\nOnce we have thought over our model, let's posit it. \n\n$$ weight_i \\sim Normal(\\mu_i, \\sigma)$$\n$$\\mu_i = \\alpha + area_i \\beta_{area} $$\n\n$$ alpha \\sim Normal(0, 0.2) $$\n$$ \\beta_{area} \\sim Normal(0, 0.5) $$\n$$ \\sigma \\sim Uniform(0, 1) $$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_area_weight <- quap(\n  alist(\n    weight ~ dnorm(mu, sigma),\n    mu <- alpha + beta_area * area,\n    alpha ~ dnorm(0, 0.2),\n    beta_area ~ dnorm(0, 0.5),\n    sigma ~ dexp(1)\n  ),\n  data = foxes_scaled\n)\n```\n:::\n\n\nLet's do some prior predictive checks before we continue:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_area_weight <- extract.prior(model_area_weight, n = 100)\n\nprior_data <- data.frame(sim = 1:100, intercept = prior_area_weight$alpha, slope = prior_area_weight$beta_area)\n\nggplot() +\n  scale_y_continuous(limits=c(-2,2)) +\n  scale_x_continuous(limits = c(-2, 2)) +\n  geom_abline(data = prior_data, aes(slope = slope, intercept = intercept, group = sim),\n              alpha = 0.2) +\n   hrbrthemes::theme_ipsum_rc() +\n  labs(x = \"z-score area\",\n       y = \"z-score weight\",\n       title = \"Prior predictive check\")\n```\n\n::: {.cell-output-display}\n![](2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nNow, let's analyze our posterior\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprecis(model_area_weight)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   mean         sd       5.5%     94.5%\nalpha     -7.202898e-06 0.08360131 -0.1336182 0.1336038\nbeta_area  1.883496e-02 0.09088645 -0.1264191 0.1640891\nsigma      9.911604e-01 0.06464929  0.8878383 1.0944824\n```\n:::\n:::\n\n\nAccording to our DAG and our statistical fitting, there is no causal relationship between area and weight. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_area_weight_slope <- link(model_area_weight, data = data.frame(area = seq(-2.5, 2.5, length.out = 100)))\n\nmu <- apply(posterior_area_weight_slope, 2, mean)\nposterior_area_weight <- sim(model_area_weight, data = data.frame(area = seq(-2.5, 2.5, length.out = 100)))\ninterval <- apply(posterior_area_weight, 2, PI, prob = 0.75)\nleft_interval <- interval[1,]\nright_interval <- interval[2,]\n\ndata.frame(mu, interval, left_interval, right_interval,\n           area = seq(-2.5, 2.5, length.out = 100)) %>% \n  ggplot(aes(area, mu)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = left_interval,\n                  ymax = right_interval),\n              alpha = 0.1) +\n  geom_point(data = foxes_scaled,\n             mapping = aes(x = area, y = weight),\n             alpha = 0.8, color = \"dodgerblue4\") +\n  hrbrthemes::theme_ipsum_rc() +\n  labs(x = \"area\",\n       y = \"weight\",\n       title = \"Posterior predictive checking\")\n```\n\n::: {.cell-output-display}\n![](2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nAccordingly, our fit to the data is terrible. Thus, we conclude that increasing the area available to each fox won't make them heavier. \n\n> Now infer the causal impact of adding food to a territory. Would this make foxes heavier? Which covariate do you need to adjust for to estimate the total causal influence of food?\n\nGiven our DAG, there are two paths from avgfood to weight. However, none of them are a backdoor. Thus, we do not need to adjust for any other variable to identify the causal effect of avgfood on weight.  \n\nWe can confirm this using `dagitty`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadjustmentSets(dag_foxes, exposure = \"avgfood\", outcome = \"weight\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n {}\n```\n:::\n:::\n\n\nOnce we have thought over our model, let's posit it. \n\n$$ weight_i \\sim Normal(\\mu_i, \\sigma)$$\n$$ \\mu_i = \\alpha + avgfood_i \\beta_{avgfood} $$\n\n$$ alpha \\sim Normal(0, 0.2) $$\n$$ \\beta_{avgfood} \\sim Normal(0, 0.5) $$\n$$ \\sigma \\sim Uniform(0, 1) $$\nLet's fit our model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_food_weight <- quap(\n  alist(weight ~ dnorm(mu, sigma),\n        mu <- alpha + avgfood * beta_avgfood,\n        alpha ~ dnorm(0, 0.1),\n        beta_avgfood ~ dnorm(0, 0.5),\n        sigma ~ dexp(1)),\n  data = foxes_scaled\n)\nprecis(model_food_weight)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      mean         sd       5.5%     94.5%\nalpha        -3.116427e-06 0.06771658 -0.1082273 0.1082211\nbeta_avgfood -2.421115e-02 0.09088693 -0.1694660 0.1210437\nsigma         9.911655e-01 0.06466209  0.8878230 1.0945081\n```\n:::\n:::\n\n\nJust as before, given our DAG, our statistical analysis and our data, there is no causal effect of avgfood on weight. Thus, increasing the avgfood won't lead to heavier foxes. \n\nLet's plot our predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfood_data <- data.frame(avgfood = seq(min(foxes_scaled$avgfood),\n                                      max(foxes_scaled$avgfood),\n                                      length.out = 1000))\nsim_mu <- link(model_food_weight, data = food_data)\n\nmu <- apply(sim_mu, 2, mean)\n\nsim_interval <- sim(model_food_weight, data = food_data)\n\ninterval <- apply(sim_interval, 2, PI, prob = 0.75)\n\nleft_interval <- interval[1,]\nright_interval <- interval[2,]\n\ncbind(food_data, data.frame(mu),\n      left_interval, right_interval) %>% \n  ggplot(aes(avgfood, mu)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = left_interval,\n                  ymax = right_interval), \n              alpha = 0.1) +\n  geom_point(data = foxes_scaled,\n             aes(x = avgfood, y = weight),\n             color = \"dodgerblue4\") +\n  hrbrthemes::theme_ipsum_rc() +\n  labs(x = \"avgfood\",\n       y = \"weight\",\n       title = \"Posterior predictive checking\") \n```\n\n::: {.cell-output-display}\n![](2020-05-03-statistical-rethinking-week-3_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nAccordingly, our fit is terrible. \n\n> Now infer the causal impact of group size. Which covariates do you need to adjust for? Looking at the posterior distribution of the resulting model, what do you think explains these data? That is, can you explain the estimates for all three problems? How do they go together?\n\nGiven our DAG, there are two paths from groupsize to weight. And of them has a backdoor through which our estimates will be confounded. That is, given that in our bayesian network the information flows freely, if we run an univariate regression, the coefficient for groupsize will pick up the effect of avgfood on weight too. Therefore, we need to control for avgfood to close this backdoor. Let's confirm this with `dagitty`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadjustmentSets(dag_foxes, exposure = \"groupsize\", outcome = \"weight\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{ avgfood }\n```\n:::\n:::\n\n\nLet's formulate our model:\n\n$$ weight_i \\sim Normal(\\mu_i, \\sigma)$$\n$$ \\mu_i = \\alpha + avgfood_i \\beta_{avgfood} + groupsize_i \\beta_{groupsize} $$\n\n$$ alpha \\sim Normal(0, 0.2) $$\n$$ \\beta_{avgfood} \\sim Normal(0, 0.5) $$\n$$ \\beta_{groupsize} \\sim Normal(0, 0.5) $$\n\n$$ \\sigma \\sim Uniform(0, 1) $$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_gropusize_weight <- quap(\n  alist(\n    weight ~ dnorm(mu, sigma),\n    mu <- alpha + beta_avgfood * avgfood + beta_groupsize * groupsize,\n    alpha ~ dnorm(0, 0.1),\n    beta_avgfood ~ dnorm(0, 0.5),\n    beta_groupsize ~ dnorm(0, 0.5),\n    sigma ~ dexp(1)\n  ),\n  data = foxes_scaled\n)\nprecis(model_gropusize_weight)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        mean         sd       5.5%      94.5%\nalpha           1.503414e-06 0.06583598 -0.1052171  0.1052201\nbeta_avgfood    4.772644e-01 0.17912227  0.1909924  0.7635364\nbeta_groupsize -5.735414e-01 0.17914071 -0.8598429 -0.2872400\nsigma           9.420381e-01 0.06175160  0.8433471  1.0407291\n```\n:::\n:::\n\n\nGiven our DAG, statistical analysis and data, we conclude that: \n\n- Conditioning on groupsize, the average food available increases the weight of the foxes\n- The larger the groupsize, adjusting for avgfood, the lower the weight of the foxes.\n- Avgfood and area have two causal channels through which it influences the foxes' weight. It increases the food available to them, which helps them get heavier. But it also increases the groupsize. Thus, they get thinner. These effects in opposite directions end up cancelling the overall causal effect of area or avgdfood on weight. \n\n**If one were to intervene to increase the foxes' weight, one would need to increase the avgfood available to them while maintaining the groupsize constant.\n\n\n\n\n\n",
    "supporting": [
      "2020-05-03-statistical-rethinking-week-3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}