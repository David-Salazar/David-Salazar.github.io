{
  "hash": "4f36560b77730e99491612e53361dd72",
  "result": {
    "markdown": "---\ntitle: 'Bayesian Data Analysis: Week 3-> Exercises'\nauthor: ''\ndate: '2020-06-25'\nslug: bayesian-data-analysis-week-3-exercises\ncategories: []\ntags: []\naliases: \n  - ../../2020/06/25/bayesian-data-analysis-week-3-exercises/\n---\n\n\n\n\n\nBayesian Data Analysis (Gelman, Vehtari et. alter) is equals part a great introduction and THE reference for advanced Bayesian Statistics. Luckily, it's [freely available online](http://www.stat.columbia.edu/~gelman/book/). To make things even better for the online learner, Aki Vehtari (one of the authors) has a set of online lectures and homeworks that go through the basics of Bayesian Data Analysis.\n\nIn this blogpost, I'll go over a couple of the selected exercises for week 3: exercise number 2 and exercise number 3.\n\n## Exercise 2\n\nComparison of two multinomial observations: on September\n\\( 25,1988, \\) the evening of a presidential campaign debate, ABC News conducted a survey of registered voters in the United States; 639 persons were polled before the debate, and 639 different persons were polled after. Assume the surveys are independent simple random samples from the population of registered voters. Model the data with two different multinomial distributions. For \\( t=1,2, \\) let \\( \\alpha_{t} \\) be the proportion of voters who preferred Bush, out of those who had a preference for either Bush or Dukakis at the time of survey\n\\( t . \\) **Plot a histogram of the posterior density for \\( \\alpha_{2}-\\alpha_{1} . \\) What is the posterior probability that there was a shift toward Bush?**\n\nThe results of the surveys are thus:\n\n$$\n\\begin{array}{c|ccc|c}\n\\text { Survey } & \\text { Bush } & \\text { Dukakis } & \\text { No opinion/other } & \\text { Total } \\\\\n\\hline \\text { pre-debate } & 294 & 307 & 38 & 639 \\\\\n\\text { post-debate } & 288 & 332 & 19 & 639\n\\end{array}\n$$\n\n### Solution\n\nTherefore, for the pre-debate we posit a multinomial model. A multinomial model is nothing more than the extension of the binomial model to more than 2 categories. Here we have 3: Bush, Dukakis and other. For both models, **we assume that the 639 observations are independent and exchangeable**. The likelihood for each survey is thus:\n\n$$\np(y \\mid \\theta) \\propto \\prod_{j=1}^{k} \\theta_{j}^{y_{j}}\n$$\n\nWhere $\\theta_j$ is the probability of choosing the $j$ option. The conjugate prior for the distribution is a multivariate generalization of the beta distribution known as Dirichlet: \n\n$$\np(\\theta \\mid \\beta) \\propto \\prod_{j=1}^{k} \\theta_{j}^{\\beta_{j}-1}\n$$\n\nIf we set all $\\beta_j = 1$, we get an uniform distribution on the possible distributions for the $\\theta$'s. That is, **just as the beta distribution, the Dirichlet distribution is a distribution of distributions.**\n\nThe resulting posterior distribution for the $\\theta_j$'s is a Dirichlet with parameters $\\beta_j + y_j$. The question, then, is how to go from the $\\theta_j$, the proportion that favors the option $j$, to the requested $\\alpha_t$:\n\n> Proportion of voters who preferred Bush, out of those who had a preference for either Bush or Dukakis at the time of survey t. \n\nNote that given the inherent restriction on the Dirichlet, we can rewrite the distribution of the $\\theta_j$'s as $(\\theta_1, \\theta_2, 1 - \\theta_1 - \\theta_2)$. We can then perform a change of variables: $(\\alpha, \\gamma) = (\\dfrac{\\theta_1}{\\theta_1 + \\theta_2}, \\theta_1 + \\theta_2)$. Which it can be shown that $\\alpha$ is then distributed thus:\n\n$$\n\\alpha | y \\sim Beta(y_1 + \\beta_1, y_2 + \\beta_2)\n$$\n### Pre-Debate\n\nTherefore, setting an uniform prior ($\\beta_j = 1 \\ \\forall j$) on the possible distribution of the $\\theta_j$'s, the posterior distribution is:\n\n$$\n(\\theta_{bush}, \\theta_{dukakis}, \\theta_{neither}) | y \\sim Dirichlet(295, 308, 39)\n$$\nWhich then amounts that the proportion that favor Bush, out of those who had a preference for either Bush or Dukakis in the pre-debate, that is, $\\alpha_1$ is thus:\n\n$$\n\\alpha_1 | y \\sim Beta(295, 308)\n$$\nWhich we can visualize thus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha1 = rbeta(10000, 295, 308)\ndata.frame(alpha1) -> simulations_alpha1\n\nsimulations_alpha1 %>% \n  ggplot(aes(alpha1)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"dodgerblue4\", alpha = 0.7) +\n  geom_vline(aes(xintercept = 0.5), linetype = 2, color = \"red\") +\n  labs(title = TeX(\"Posterior distribution for $\\\\alpha_1$\"),\n       subtitle = \" Proportion of voters who preferred Bush, out of those who had a preference \n       for either Bush or Dukakis at pre-debate\",\n       x = TeX(\"$\\\\alpha_1$\"))\n```\n\n::: {.cell-output-display}\n![](2020-06-25-bayesian-data-analysis-week-3-exercises_files/figure-html/alpha1-1.png){width=768}\n:::\n:::\n\n\nThat is, our posterior distribution points that at the pre-debate, there was already a majority of people (among the already decided) who favored Dukakis. Indeed:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredebate <- pbeta(0.5, 295, 308)\nglue::glue(\"There's a {round(predebate, 2)*100}% posterior probability that among decided voters Dukakis had a majority in\n           the pre-debate.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThere's a 70% posterior probability that among decided voters Dukakis had a majority in\nthe pre-debate.\n```\n:::\n:::\n\n\n### Post-Debate\n\nTherefore, setting an uniform prior ($\\beta_j = 1 \\ \\forall j$) on the possible distribution of the $\\theta_j$'s, the posterior distribution is:\n\n$$\n(\\theta_{bush}, \\theta_{dukakis}, \\theta_{neither}) | y \\sim Dirichlet(289, 333, 39)\n$$\nWhich then amounts that the proportion that favor Bush, out of those who had a preference for either Bush or Dukakis in the post-debate, that is, $\\alpha_2$ is thus:\n\n$$\n\\alpha_1 | y \\sim Beta(289, 333)\n$$\n\n\nWhich we can visualize thus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha2 = rbeta(10000, 289, 333)\ndata.frame(alpha2) -> simulations_alpha2\n\nsimulations_alpha2 %>% \n  ggplot(aes(alpha2)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"dodgerblue4\", alpha = 0.7) +\n  geom_vline(aes(xintercept = 0.5), linetype = 2, color = \"red\") +\n  labs(title = TeX(\"Posterior distribution for $\\\\alpha_2$\"),\n       subtitle = \" Proportion of voters who preferred Bush, out of those who had a preference \n       for either Bush or Dukakis at post-debate\",\n       x = TeX(\"$\\\\alpha_2$\"))\n```\n\n::: {.cell-output-display}\n![](2020-06-25-bayesian-data-analysis-week-3-exercises_files/figure-html/alpha2-1.png){width=768}\n:::\n:::\n\n\nAfter the debate, Dukakis won an even larger majority among the decided voters:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npostdebeate <- pbeta(0.5, 289, 333)\nglue::glue(\"There's a {round(postdebeate, 2)*100}% posterior probability that among decided voters Dukakis had a majority in\n           the pre-debate.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThere's a 96% posterior probability that among decided voters Dukakis had a majority in\nthe pre-debate.\n```\n:::\n:::\n\n\n### A shift toward Bush?\n\nWe have the posterior probability for both $\\alpha_1$ and $\\alpha_2$. Sampling form these posteriors, we can then arrive at a posterior distribution for $\\alpha_2 - \\alpha_1$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndifference <- alpha2 - alpha1\n\ndata.frame(difference) %>% \n  ggplot(aes(difference)) +\n  geom_vline(aes(xintercept = 0), color = \"red\", linetype = 2) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"dodgerblue4\", alpha = 0.7)  +\n  labs(title = TeX(\"Posterior distribution for $\\\\alpha_2 - \\\\alpha_1$\"))\n```\n\n::: {.cell-output-display}\n![](2020-06-25-bayesian-data-analysis-week-3-exercises_files/figure-html/difference-1.png){width=768}\n:::\n:::\n\n\nThe posterior probability that there was a shift toward Bush is the probability that $\\alpha_2 - \\alpha_1 > 0$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshift <- sum(difference > 0) / length(difference)\nglue::glue(\"The posterior probability that there was a shift toward Bush is thus {round(shift, 2)*100}%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe posterior probability that there was a shift toward Bush is thus 19%\n```\n:::\n:::\n\n\n## Exercise 3\n\nEstimation from two independent experiments: an experiment was performed on the effects of magnetic fields on the flow of calcium out of chicken brains. Two groups of chickens were involved: a control group of 32 chickens and an exposed group of 36 chickens. One measurement was taken on each chicken, and the purpose of the experiment was to measure the average flow \\( \\mu_{c} \\) in untreated (control) chickens and the average flow \\( \\mu_{t} \\) in treated chickens. The 32 measurements on the control group had a sample mean of 1.013 and a sample standard deviation of \\( 0.24 . \\) The 36 measurements on the treatment group had a sample mean of 1.173 and a sample standard deviation of 0.20\n\n(a) Assuming the control measurements were taken at random from a normal distribution with mean \\( \\mu_{c} \\) and variance \\( \\sigma_{c}^{2}, \\) what is the posterior distribution of \\( \\mu_{c} ? \\) Similarly, use the treatment group measurements to determine the marginal posterior distribution of \\( \\mu_{t} . \\) Assume a uniform prior distribution on \\( \\left(\\mu_{c}, \\mu_{t}, \\log \\sigma_{c}, \\log \\sigma_{t}\\right) \\)\n\n(b) What is the posterior distribution for the difference, \\( \\mu_{t}-\\mu_{c} ? \\) To get this, you may sample from the independent \\( t \\) distributions you obtained in part(a) above. Plot a histogram of your samples and give an approximate \\( 95 \\% \\) posterior interval for \\( \\mu_{t}-\\mu_{c} \\)\n\n## Solution\n\nLet's posit two normal probability models for both the control measurements and the treatment measurements, assuming exchangeability among these two groups. \n\n### Control group\n\nTherefore:\n\n$$\ny_c | \\mu, \\sigma^2 \\sim N(\\mu_c, \\sigma_c^2) \\\\\np(\\mu_c, \\sigma_c | y) \\propto p (y | \\mu_c, \\sigma_c) p(\\mu_c, \\sigma_c)\n$$\nIf we posit an uniform prior on $(\\mu_c, log \\sigma_c)$\n\n$$\np(\\mu_c, \\sigma_c^2) \\propto (\\sigma_c^2)^{-1}\n$$\n\nThen, the marginal posterior distribution for $\\mu_c$ is a t-distribution:\n\n$$\n\\dfrac{\\mu_c  - \\bar y_c}{s_c/\\sqrt{n_c}} | y \\sim t_{n_c-1}\n$$\n\nFor the control group, we have $n_c = 32$, $\\bar y_c = 1.013$ and $s_c = 0.24$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu_c <- rtnew(10000, df = 31, mean = 1.013, scale = 0.24/sqrt(32) )\n\ndata.frame(mu_control = mu_c) %>% \n  ggplot(aes(mu_control)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"dodgerblue4\", alpha = 0.7) +\n  labs(title = TeX(\"Posterior distribution for $\\\\mu_c$\"))\n```\n\n::: {.cell-output-display}\n![](2020-06-25-bayesian-data-analysis-week-3-exercises_files/figure-html/muc-1.png){width=768}\n:::\n:::\n\n\n### Treatment Group\n\nThe same likelihood and prior are valid for the treatment measurements. Therefore, the marginal posterior for $\\mu_t$:\n\n$$\n\\dfrac{\\mu_t  - \\bar y_t}{s_t/\\sqrt{n_t}} | y \\sim t_{n_t-1}\n$$\n\nFor the treatment group, we have $n_t = 36$, $\\mu_t = 1.173$, $s_t = 0.2$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu_t <- rtnew(10000, df = 35, mean = 1.173, scale = 0.2/sqrt(36) )\n\ndata.frame(mu_treatment = mu_t) %>% \n  ggplot(aes(mu_treatment)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"dodgerblue4\", alpha = 0.7) +\n  labs(title = TeX(\"Posterior distribution for $\\\\mu_t$\"))\n```\n\n::: {.cell-output-display}\n![](2020-06-25-bayesian-data-analysis-week-3-exercises_files/figure-html/mut-1.png){width=768}\n:::\n:::\n\n\n### Posterior difference between mu_c and mu_t\n\nTo get the posterior distribution of the difference, we compare the samples from the marginal posterior of $\\mu_c, \\mu_t$. Therefore, the 95% posterior credibility interval on the different is thus\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndifferent_mu <- mu_t - mu_c\ninterval <- rethinking::PI(different_mu, prob = 0.95)\nlower <- interval[[1]]\nupper <- interval[[2]]\nglue::glue(\"The 95% posterior credibility interval for the difference is {round(lower, 2)}, {round(upper, 2)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe 95% posterior credibility interval for the difference is 0.05, 0.27\n```\n:::\n:::\n\n\nAnd the full posterior of the difference is thus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(different_mu) %>% \n  ggplot(aes(different_mu)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"dodgerblue4\", alpha = 0.7) +\n  labs(title = TeX(\"Posterior distribution for $\\\\mu_t - \\\\mu_c$\"))\n```\n\n::: {.cell-output-display}\n![](2020-06-25-bayesian-data-analysis-week-3-exercises_files/figure-html/differentmu-1.png){width=768}\n:::\n:::\n",
    "supporting": [
      "2020-06-25-bayesian-data-analysis-week-3-exercises_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}