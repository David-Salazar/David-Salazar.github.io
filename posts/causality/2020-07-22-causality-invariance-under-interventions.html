<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.262">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="">
<meta name="dcterms.date" content="2020-07-22">

<title>David Salazar - Causality: Invariance under Interventions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">David Salazar</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html">
 <span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/David-Salazar"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/DavidSalazarVir"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Causality: Invariance under Interventions</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 22, 2020</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#defining-the-causal-effect-with-the-do-operator" id="toc-defining-the-causal-effect-with-the-do-operator" class="nav-link active" data-scroll-target="#defining-the-causal-effect-with-the-do-operator">Defining the causal effect with the do-operator</a></li>
  <li><a href="#causal-graphs" id="toc-causal-graphs" class="nav-link" data-scroll-target="#causal-graphs">Causal Graphs</a></li>
  <li><a href="#interventions-eliminating-incoming-arrows" id="toc-interventions-eliminating-incoming-arrows" class="nav-link" data-scroll-target="#interventions-eliminating-incoming-arrows">Interventions: Eliminating incoming arrows</a></li>
  <li><a href="#invariant-probabilities-under-intervention" id="toc-invariant-probabilities-under-intervention" class="nav-link" data-scroll-target="#invariant-probabilities-under-intervention">Invariant probabilities under intervention</a>
  <ul class="collapse">
  <li><a href="#connecting-pre-intervention-probabilities-with-post-treament" id="toc-connecting-pre-intervention-probabilities-with-post-treament" class="nav-link" data-scroll-target="#connecting-pre-intervention-probabilities-with-post-treament">Connecting pre-intervention probabilities with post-treament</a></li>
  </ul></li>
  <li><a href="#the-adjustment-formula" id="toc-the-adjustment-formula" class="nav-link" data-scroll-target="#the-adjustment-formula">The Adjustment Formula</a></li>
  <li><a href="#an-example" id="toc-an-example" class="nav-link" data-scroll-target="#an-example">An example</a></li>
  <li><a href="#identifiable" id="toc-identifiable" class="nav-link" data-scroll-target="#identifiable">Identifiable</a></li>
  <li><a href="#addendum-rct" id="toc-addendum-rct" class="nav-link" data-scroll-target="#addendum-rct">Addendum: RCT</a></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>In the <a href="https://david-salazar.github.io/2020/07/18/causality-bayesian-networks/">last post</a> we saw how two causal models can yield the same testable implications and thus cannot be distinguished from data alone. That is, we cannot gain causal understanding from data alone. Does that mean that we cannot ever gain causal understanding? Far from it; it just means that we must have a causal model.</p>
<p><strong>Thus, causal effects cannot be estimated from the data itself without a causal story.</strong> In this blogpost, I’ll show how exactly the combination between causal models and observational data can lead us into estimating causal effects. In short, causal effects can be estimated by leveraging the invariant information that the pre-intervention distribution can provide. Doing so, we connect pre-intervention probabilities with the post-intervention probabilities that define the causal effect.</p>
<section id="defining-the-causal-effect-with-the-do-operator" class="level2">
<h2 class="anchored" data-anchor-id="defining-the-causal-effect-with-the-do-operator">Defining the causal effect with the do-operator</h2>
<p>Fundamentally, we cannot gain causal understanding with data because <strong>the data we see could have been generated by many a causal models</strong>. That is, the associations we see, <span class="math inline">\(P(Y | X)\)</span>, can be the result of many interactions; <strong>some of them causal and some purely observational</strong>. We can say that any statistically meaningful association is <em>the result of a causal relationship</em> <strong>somewhere in the system</strong>, but <em>not necessarily</em> of the causal effect of interest, <span class="math inline">\(X \rightarrow Y\)</span>.</p>
<p>To disentangle this confusion, then, let’s define a causal effect. <a href="https://fabiandablander.com/r/Causal-Inference.html">Following Pearl</a>, we will take an <strong>interventionist position</strong> and say that a variable <span class="math inline">\(X\)</span> has a causal influence on <span class="math inline">\(Y\)</span> if intervening to change <span class="math inline">\(X\)</span> leads to changes in <span class="math inline">\(Y\)</span>. Intervening on <span class="math inline">\(X\)</span> means lifting <span class="math inline">\(X\)</span> from whatever mechanism previously defined its value and now set it to a particular value <span class="math inline">\(X=x\)</span> in an exogenous way.</p>
<p>Thus, the <strong>causal effect</strong> is defined as a <em>function</em> from the values <span class="math inline">\(X\)</span> can take to the space of <em>probability distributions</em> on <span class="math inline">\(Y\)</span>. For example, if <span class="math inline">\(X := x\)</span>, then we arrive at the <strong>interventional distribution</strong> <span class="math inline">\(P(Y| \text{do}(x))\)</span>: the population distribution of <span class="math inline">\(Y\)</span> if <em>everyone</em> in the population had their <span class="math inline">\(X\)</span> value fixed at <span class="math inline">\(x\)</span>.</p>
<p>The <span class="math inline">\(\text{do}\)</span> operator defines the exogenous process through which we have intervened to set the value of <span class="math inline">\(X := x\)</span>. Finally, we derive <span class="math inline">\(P(Y| \text{do}(x))\)</span> for every possible <span class="math inline">\(x\)</span> and test whether the distribution changes as we change the value <span class="math inline">\(X\)</span> takes.</p>
<p>Therefore, to study the causal effect of <span class="math inline">\(X\)</span> is to change the system by determining the value of <span class="math inline">\(X\)</span> outside of it and seeing how the effects cascade thorough the system. However, before we change a system we must define it. How to represent the system? With a Causal Graph!</p>
</section>
<section id="causal-graphs" class="level2">
<h2 class="anchored" data-anchor-id="causal-graphs">Causal Graphs</h2>
<p>The question, then, becomes: <strong>how can we simulate the effects of intervening in the causal system?</strong>. First, however, we must define the system in question.</p>
<p>Let each node represent one of the variables of interest. We will draw an arrow from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> if there is a <strong>direct causal effect</strong> from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> for at least one individual. Alternatively, <strong>the lack of an arrow</strong> means that <em>there’s no</em> causal effect for any individual in the population. We will assume that the system is adequately written if <strong>all common causes</strong> of <em>any pair</em> of variables on the graph are <strong>themselves on the graph</strong>. Finally, we’ll say that a variable is always a cause of its descendants.</p>
<p>We will link Causal Graphs to Bayesian graphs by assuming that each variable, conditional on its parents, is independent of any variable for which it is not a cause (i.e., all its predecessors). In turn, this will imply that the <strong>Graph defines the same recursive decomposition of the joint distribution</strong> as a <em>Bayesian Graph</em>:</p>
<p><span class="math display">\[
P\left(x_{1}, \ldots, x_{n}\right)=\prod_{j} P\left(x_{j} \mid pa_j\right)
\]</span></p>
<p>Thereby, we can derive, using the d-separation criterion, <strong>testable implications</strong> of our causal models.</p>
<p>To make things more concrete, let’s work with the following fork: let’s say that a new treatment is developed to reduce cholesterol. However, women take the treatment more/less than men and have higher/lower levels of cholesterol. How to compute the causal effect of the treatment on cholesterol?</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="2020-07-22-causality-invariance-under-interventions_files/figure-html/drug, coffee-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="interventions-eliminating-incoming-arrows" class="level2">
<h2 class="anchored" data-anchor-id="interventions-eliminating-incoming-arrows">Interventions: Eliminating incoming arrows</h2>
<p>Intervening on <span class="math inline">\(X\)</span> such that <span class="math inline">\(\text{do(X = 1)}\)</span> amounts to curtailing the previous mechanism that defined <span class="math inline">\(X\)</span>. In Graph lingo: <strong>eliminate the incoming arrows into <span class="math inline">\(X\)</span></strong>: <em>gender no longer cause <span class="math inline">\(X\)</span></em>. Therefore, we eliminate the arrow from Gender into treatment. Thus, an intervention is equivalent to eliminating arrows in a Causal Graph. Let’s label this new graph <span class="math inline">\(G_m\)</span></p>
<div class="cell">
<div class="cell-output-display">
<p><img src="2020-07-22-causality-invariance-under-interventions_files/figure-html/drug-eliminated-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="invariant-probabilities-under-intervention" class="level2">
<h2 class="anchored" data-anchor-id="invariant-probabilities-under-intervention">Invariant probabilities under intervention</h2>
<p>The mutilated graph is still a Causal Graph. Thus, it implies a <em>particular decomposition of the joint probability</em> (<span class="math inline">\(P_m\)</span>) of it’s own. With respect to this post-intervention distribution, we can define the causal effect: <span class="math inline">\(P(Y=y|\text{do}(X=x)) := P_m (Y=y|X=x)\)</span>. However, this new post-intervention distribution <span class="math inline">\(P_m\)</span> is <strong>not totally disconnected</strong> from the pre-intervention distribution (<span class="math inline">\(P\)</span>) that we can study with observational data.</p>
<p>There are two <strong>invariant qualities</strong> that are the same in the <em>pre-intervention and post-intervention</em> distribution:</p>
<ul>
<li><p>Our intervention is <strong>atomic</strong>: there are no side effects that alter the way non-descendants of <span class="math inline">\(X\)</span> are determined. Thus, <span class="math inline">\(P_m(Z=z| X=x) = P(Z=z)\)</span>.</p></li>
<li><p>The conditional probability <span class="math inline">\(Y\)</span> is invariant, because the mechanism by which Y responds to <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> remains the same, <em>regardless</em> of whether <span class="math inline">\(X\)</span> <strong>changes spontaneously or by deliberate manipulation</strong>. Thus; <span class="math inline">\(P_m(Y| X=x, Z = z) = P(Y|X=x, Z=z)\)</span>.</p></li>
</ul>
<section id="connecting-pre-intervention-probabilities-with-post-treament" class="level3">
<h3 class="anchored" data-anchor-id="connecting-pre-intervention-probabilities-with-post-treament">Connecting pre-intervention probabilities with post-treament</h3>
<p>Therefore, using probability laws and our independence assumption between <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> in the mutilated graph, we define the causal effect in terms of post-intervention distribution thus:</p>
<p><span class="math display">\[
\begin{array}{l}
P(Y = y | do(X=x)) := P_m (Y=y|X=x) \\
=\sum_{z} P_{m}(Y=y \mid X=x, Z=z) P_{m}(Z=z \mid X=x) \\
=\sum_{z} P_{m}(Y=y \mid X=x, Z=z) P_{m}(Z=z)
\end{array}
\]</span> Luckily, all the terms invariant: both terms can be <strong>connected to the original pre-intervention</strong> probability distribution:</p>
<p><span class="math display">\[
P(Y=y \mid d o(X=x))=\sum_{z} P(Y=y \mid X=x, Z=z) P(Z=z)
\]</span> Therefore, we arrive at a definition of the <strong>causal effect in terms of the pre-treatment distribution</strong>. Thus, we can <strong>estimate the causal effect from observational studies</strong> without the need of <em>actually carrying out</em> the intervention.</p>
</section>
</section>
<section id="the-adjustment-formula" class="level2">
<h2 class="anchored" data-anchor-id="the-adjustment-formula">The Adjustment Formula</h2>
<p>More generally, we define the causal effect in terms of pre-intervention probability thus. Given a graph <span class="math inline">\(G\)</span> in which a set of variables <span class="math inline">\(pa\)</span> are designated as the parents of <span class="math inline">\(X\)</span>, the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is given by:</p>
<p><span class="math display">\[
P(Y=y|\text{do}(X=x)) = \sum_{z} P(Y=y | X=x, P A=z) P(pa=z)
\]</span> Therefore, we can conclude why it is necessary to have a causal story to be able to estimate the causal effect: <strong>to identify the parents of <span class="math inline">\(X\)</span> and adjust for them</strong>: first condition <span class="math inline">\(P(Y=y| X =x)\)</span> on <span class="math inline">\(PA\)</span> and then average the result, weighted the prior probability of <span class="math inline">\(pa = z\)</span>.</p>
</section>
<section id="an-example" class="level2">
<h2 class="anchored" data-anchor-id="an-example">An example</h2>
<p>Let’s follow our thought experiment with our previous graph. In the <a href="https://fabiandablander.com/r/Causal-Inference.html">experiment</a>, we observe both men and women who decide whether they take the drug or not. The results are the following:</p>
<div class="cell">
<div class="cell-output-display">

<div id="apqbwdcovh" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

:where(#apqbwdcovh) .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

:where(#apqbwdcovh) .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

:where(#apqbwdcovh) .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

:where(#apqbwdcovh) .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

:where(#apqbwdcovh) .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

:where(#apqbwdcovh) .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

:where(#apqbwdcovh) .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

:where(#apqbwdcovh) .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

:where(#apqbwdcovh) .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

:where(#apqbwdcovh) .gt_from_md > :first-child {
  margin-top: 0;
}

:where(#apqbwdcovh) .gt_from_md > :last-child {
  margin-bottom: 0;
}

:where(#apqbwdcovh) .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

:where(#apqbwdcovh) .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

:where(#apqbwdcovh) .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

:where(#apqbwdcovh) .gt_row_group_first td {
  border-top-width: 2px;
}

:where(#apqbwdcovh) .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

:where(#apqbwdcovh) .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_first_summary_row.thick {
  border-top-width: 2px;
}

:where(#apqbwdcovh) .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

:where(#apqbwdcovh) .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

:where(#apqbwdcovh) .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

:where(#apqbwdcovh) .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

:where(#apqbwdcovh) .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

:where(#apqbwdcovh) .gt_left {
  text-align: left;
}

:where(#apqbwdcovh) .gt_center {
  text-align: center;
}

:where(#apqbwdcovh) .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

:where(#apqbwdcovh) .gt_font_normal {
  font-weight: normal;
}

:where(#apqbwdcovh) .gt_font_bold {
  font-weight: bold;
}

:where(#apqbwdcovh) .gt_font_italic {
  font-style: italic;
}

:where(#apqbwdcovh) .gt_super {
  font-size: 65%;
}

:where(#apqbwdcovh) .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

:where(#apqbwdcovh) .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

:where(#apqbwdcovh) .gt_indent_1 {
  text-indent: 5px;
}

:where(#apqbwdcovh) .gt_indent_2 {
  text-indent: 10px;
}

:where(#apqbwdcovh) .gt_indent_3 {
  text-indent: 15px;
}

:where(#apqbwdcovh) .gt_indent_4 {
  text-indent: 20px;
}

:where(#apqbwdcovh) .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col">Recovered</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col">N</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col">Treatment</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col">Gender</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_right">81</td>
<td class="gt_row gt_right">87</td>
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_left">Male</td></tr>
    <tr><td class="gt_row gt_right">234</td>
<td class="gt_row gt_right">270</td>
<td class="gt_row gt_right">0</td>
<td class="gt_row gt_left">Male</td></tr>
    <tr><td class="gt_row gt_right">192</td>
<td class="gt_row gt_right">263</td>
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_left">Female</td></tr>
    <tr><td class="gt_row gt_right">55</td>
<td class="gt_row gt_right">80</td>
<td class="gt_row gt_right">0</td>
<td class="gt_row gt_left">Female</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
<p>When we study the data across genders, we find out that the patients who didn’t take the drug had a higher rate of recovery:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="2020-07-22-causality-invariance-under-interventions_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>However, once we separate the data by gender, the opposite picture arises:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="2020-07-22-causality-invariance-under-interventions_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="768"></p>
</div>
</div>
<p>We have a case of Simpson’s Paradox! Let’s use the causal knowledge embedded in our graph to estimate the true causal effect of the treatment. Given that Gender is the only parent of Treatment, we will adjust for it:</p>
<p>[ P(Y=1 d o(X=1))=+=0.832 ] while, similarly, [ P(Y=1 d o(X=0))=+=0.7818 ] Thus, comparing the effect of drug-taking ( (X=1) ) to the effect of nontaking ( (X=0), ) we obtain [ A C E=P(Y=1 d o(X=1))-P(Y=1 d o(X=0))=0.832-0.7818=0.0502 ]</p>
<p>However, if Gender had not been a parent of Treatment (i.e., if both Genders decide to take the treatment equally), our Causal effect would be different because we would adjust for Gender in the first place.</p>
</section>
<section id="identifiable" class="level2">
<h2 class="anchored" data-anchor-id="identifiable">Identifiable</h2>
<p>We’ve estimated causal effects with a pretty simple strategy: adjust for the parents of the exposure and average those effects weighted by the probability of the parents.</p>
<p>Therefore, according to our strategy, the causal effect will be <strong>identifiable</strong> whenever both <span class="math inline">\(X, Y\)</span> and the parents of <span class="math inline">\(X\)</span>, <span class="math inline">\(pa\)</span> are measured. Whenever measurements for some of them are missing, we must use other techniques to estimate the causal effect.</p>
</section>
<section id="addendum-rct" class="level2">
<h2 class="anchored" data-anchor-id="addendum-rct">Addendum: RCT</h2>
<p>Randomized Control Trials are sometimes referred to as the gold standard in causal inference. However, in our framework, they are nothing more than a <strong>different graph surgery</strong>. Whereas before we cut all the incoming arrows into treatment, now we replace all the incoming arrows with only with one arrow that signifies the randomization of the treatment:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="2020-07-22-causality-invariance-under-interventions_files/figure-html/rct-1.png" class="img-fluid" width="768"></p>
</div>
</div>
<p>Therefore, now we must simply adjust by randomization to estimate the causal effect of treatment. Does that mean that they are not useful? No, they will always have the upper hand when we are uncertain about our causal model. If there is another parent of treatment that we are not accounting for, Randomization will offer a clean solution.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>